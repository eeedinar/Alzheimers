{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4xs.hdf import h5xs,h5exp,lsh5,proc_d1merge\n",
    "from py4xs.data2d import Data2d\n",
    "from py4xs.slnxs import trans_mode\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import warnings,json\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the h5xs object for azimuthal average first\n",
    "assign the detector configuration and q-grid:\n",
    "\n",
    "  `dt0  = h5xs(\"mica.h5\", [de.detectors, qgrid2])`\n",
    "\n",
    "then do the batch processing:\n",
    "\n",
    "  `dt0.load_data()   `\n",
    "\n",
    "In general this is going to take a lot of memory. For larger datasets, run load_data(N=16) to avoid crash. This may not work on you laptop if you don't have enough memory. This step is time consuming. I recommend running this for all h5 files first. The data1d objects created from azimuthal average will be saved back to the h5 file.\n",
    "  \n",
    "## recreating the h5xs object for further processing\n",
    "\n",
    "Re-create the data1d objects from information saved in the h5 fil is a lot faster and does not require a lot of memory.\n",
    "\n",
    "  `dt0 = h5xs(\"mica.h5\", transField=\"em2_sum_all_mean_value\")` <br>\n",
    "  `dt0.load_d1s()`\n",
    "\n",
    "Then populate the *trans* attribute for all data1d objects based on the specified transfield. When calling bkg_cor() later for background subtraction, this *trans* value should be accounted for (data scaled) automatically.\n",
    "\n",
    "  `dt0.set_trans(transMode=trans_mode.external)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/bashit.a/Documents/Alzheimer/Dec-2020')      # location where your h5 and exp file are    Mar-24/BNL-Data/\n",
    "dt0  = h5xs(\"mica.h5\", transField=\"em2_sum_all_mean_value\")\n",
    "dt  = h5xs(\"2048_B8_masked.h5\", transField=\"em2_sum_all_mean_value\")\n",
    "\n",
    "dt.load_d1s()\n",
    "dt0.load_d1s()\n",
    "\n",
    "dt.set_trans(transMode=trans_mode.external)\n",
    "dt0.set_trans(transMode=trans_mode.external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d800bab29ab14b729f16ae9017297362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.76526786977064\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "(i0, rg, fit_range) = dt.d1s['2048_B8']['merged'][2080].plot_Guinier();\n",
    "print(rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84afbb322544353aa1438aa19a6e8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "f,ax = plt.subplots();\n",
    "dt.d1s['2048_B8']['merged'][2080].plot_pr(i0,rg, dmax = 800, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45131.328\n",
      "45639.848\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7283454d774d406f9ead59c580392879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dt.d1s['2048_B8']['merged'][2080].trans)\n",
    "print(dt0.d1s['mica']['merged'][10].trans)\n",
    "print(dt.d1s['2048_B8']['merged'][2080].overlaps)\n",
    "#dt0.d1s['mica']['merged'][10].plot()\n",
    "dt.d1s['2048_B8']['merged'][2080].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 9.82849867e+00, 6.45468488e+00,\n",
       "       4.46113370e+00, 3.08046540e+00, 2.15617222e+00, 1.52618740e+00,\n",
       "       1.20809589e+00, 1.00967285e+00, 7.66016009e-01, 6.47855032e-01,\n",
       "       5.45870961e-01, 4.56567354e-01, 3.69312148e-01, 3.74493540e-01,\n",
       "       2.83155068e-01, 2.68243314e-01, 2.29501601e-01, 1.90910359e-01,\n",
       "       1.73984423e-01, 1.49968235e-01, 2.01492931e-01, 1.82893342e-01,\n",
       "       1.46958039e-01, 1.63899838e-01, 1.59392855e-01, 1.46368997e-01,\n",
       "       1.17106206e-01, 1.34797025e-01, 1.21516141e-01, 1.21660631e-01,\n",
       "       1.23521731e-01, 1.08994662e-01, 1.05523566e-01, 1.00924503e-01,\n",
       "       1.02654461e-01, 1.16118315e-01, 1.04862463e-01, 1.15001720e-01,\n",
       "       1.08004264e-01, 9.63038154e-02, 1.09466217e-01, 9.35881013e-02,\n",
       "       1.03713216e-01, 9.94110874e-02, 9.39930645e-02, 1.00423459e-01,\n",
       "       9.95888678e-02, 9.52346572e-02, 9.11492838e-02, 9.04704394e-02,\n",
       "       9.39775762e-02, 9.51866195e-02, 9.26253231e-02, 9.54434228e-02,\n",
       "       8.83061606e-02, 9.17023572e-02, 9.25266529e-02, 8.44597453e-02,\n",
       "       8.82654900e-02, 8.93676897e-02, 8.79043713e-02, 8.96834615e-02,\n",
       "       9.69600054e-02, 8.75797729e-02, 8.51561094e-02, 8.98776267e-02,\n",
       "       9.02636811e-02, 7.72292158e-02, 8.89424954e-02, 8.37365318e-02,\n",
       "       8.93386682e-02, 8.54894180e-02, 8.40394131e-02, 8.31953273e-02,\n",
       "       8.01141425e-02, 8.18359764e-02, 7.99318348e-02, 8.23691677e-02,\n",
       "       7.89049142e-02, 8.39326573e-02, 8.14156758e-02, 7.87364829e-02,\n",
       "       7.60360438e-02, 7.61115626e-02, 7.83352399e-02, 7.96928643e-02,\n",
       "       7.92896266e-02, 8.03615884e-02, 7.52477236e-02, 7.66524510e-02,\n",
       "       7.79132605e-02, 7.46952975e-02, 7.87334285e-02, 7.94098636e-02,\n",
       "       7.59351912e-02, 7.35069772e-02, 7.63138484e-02, 7.95478193e-02,\n",
       "       7.74682582e-02, 7.68633466e-02, 7.59558837e-02, 7.81659911e-02,\n",
       "       7.45538652e-02, 7.89862740e-02, 7.87988978e-02, 7.56443738e-02,\n",
       "       7.92176915e-02, 4.12832380e-02, 3.96452936e-02, 3.86679779e-02,\n",
       "       4.29435571e-02, 3.79174504e-02, 4.50928891e-02, 3.54210417e-02,\n",
       "       3.80591564e-02, 4.15089131e-02, 4.08833473e-02, 4.26275115e-02,\n",
       "       3.58386192e-02, 3.84883136e-02, 3.76683419e-02, 3.47527907e-02,\n",
       "       4.03954002e-02, 7.04462290e-03, 7.09091550e-03, 6.42764042e-03,\n",
       "       6.61821737e-03, 6.45518257e-03, 7.65261288e-03, 6.53007193e-03,\n",
       "       6.84783854e-03, 6.92585614e-03, 7.20048753e-03, 6.69032443e-03,\n",
       "       7.90708873e-03, 7.75096935e-03, 7.53427906e-03, 8.44370599e-03,\n",
       "       7.05405004e-03, 6.26331034e-03, 7.47410425e-03, 7.55504353e-03,\n",
       "       6.78445629e-03, 7.16616200e-03, 6.56088493e-03, 7.30835751e-03,\n",
       "       6.21440534e-03, 7.65627320e-03, 7.17328160e-03, 6.77478587e-03,\n",
       "       6.96568118e-03, 6.93006414e-03, 6.70950170e-03, 6.70166310e-03,\n",
       "       7.88870498e-03, 7.14398206e-03, 7.28231323e-03, 7.16239690e-03,\n",
       "       7.39656633e-03, 7.43705080e-03, 6.25773399e-03, 7.22632802e-03,\n",
       "       7.59861132e-03, 7.57451854e-03, 7.08397218e-03, 6.67482123e-03,\n",
       "       7.46431258e-03, 7.91709929e-03, 7.77609156e-03, 6.80197416e-03,\n",
       "       7.73419276e-03, 7.77055687e-03, 7.81047311e-03, 7.56374325e-03,\n",
       "       7.13112456e-03, 7.98473405e-03, 7.68435314e-03, 7.03236274e-03,\n",
       "       7.52029519e-03, 7.84293461e-03, 6.57840262e-03, 7.80687058e-03,\n",
       "       7.28340045e-03, 7.03107938e-03, 8.09066147e-03, 7.29544873e-03,\n",
       "       6.77037571e-03, 7.54883040e-03, 7.10897940e-03, 7.76699176e-03,\n",
       "       7.85624468e-03, 7.34063532e-03, 8.04732479e-03, 7.36282227e-03,\n",
       "       8.30967881e-03, 7.41758259e-03, 7.84212842e-03, 7.71667012e-03,\n",
       "       7.82370664e-03, 7.86308213e-03, 8.45557289e-03, 8.04163796e-03,\n",
       "       7.55397886e-03, 8.59019022e-03, 8.22076202e-03, 8.06405469e-03,\n",
       "       8.48976094e-03, 7.28553187e-03, 8.23122356e-03, 8.15464787e-03,\n",
       "       7.87842048e-03, 8.55851186e-03, 8.24174703e-03, 8.22321262e-03,\n",
       "       7.91217893e-03, 8.78710358e-03, 8.35400851e-03, 7.92281595e-03,\n",
       "       8.40739176e-03, 8.27568168e-03, 8.05273512e-03, 8.51397583e-03,\n",
       "       8.40342390e-03, 8.32957649e-03, 8.26112704e-03, 8.24931378e-03,\n",
       "       8.55258940e-03, 8.38451935e-03, 8.16781203e-03, 8.88083141e-03,\n",
       "       8.67211624e-03, 8.24752239e-03, 8.46519322e-03, 8.62775813e-03,\n",
       "       8.43602311e-03, 8.76029877e-03, 9.20795477e-03, 8.55740261e-03,\n",
       "       9.21749961e-03, 8.68370316e-03, 8.68273717e-03, 8.97575993e-03,\n",
       "       8.84962924e-03, 8.90198781e-03, 8.52311883e-03, 9.13403804e-03,\n",
       "       8.91349318e-03, 9.20506245e-03, 8.61767333e-03, 9.23825557e-03,\n",
       "       9.20033990e-03, 9.27105173e-03, 9.06517450e-03, 9.14081409e-03,\n",
       "       9.39247214e-03, 9.27692522e-03, 9.21897235e-03, 9.19000111e-03,\n",
       "       9.13007468e-03, 9.24495673e-03, 9.42351745e-03, 9.49329322e-03,\n",
       "       9.78682723e-03, 9.58050867e-03, 9.42771541e-03, 9.59217740e-03,\n",
       "       9.77736337e-03, 9.41428839e-03, 1.00812296e-02, 9.21845285e-03,\n",
       "       9.45460124e-03, 9.83621131e-03, 1.00241736e-02, 9.65723453e-03,\n",
       "       9.56992354e-03, 9.74670722e-03, 9.95506360e-03, 9.86533656e-03,\n",
       "       1.02142289e-02, 9.98947577e-03, 9.96628679e-03, 9.72903579e-03,\n",
       "       9.98785042e-03, 1.01961185e-02, 1.01721840e-02, 1.01599254e-02,\n",
       "       1.05640149e-02, 9.58517302e-03, 1.03197897e-02, 1.01783815e-02,\n",
       "       1.03699052e-02, 1.03502489e-02, 1.06249413e-02, 1.07374384e-02,\n",
       "       1.11753213e-02, 1.04791735e-02, 1.06840280e-02, 1.08459015e-02,\n",
       "       1.09990008e-02, 1.06703139e-02, 1.03017147e-02, 1.04678400e-02,\n",
       "       1.15148401e-02, 1.07369048e-02, 1.05065523e-02, 1.05394660e-02,\n",
       "       1.10380675e-02, 1.09773726e-02, 1.09983200e-02, 1.14594914e-02,\n",
       "       1.11217568e-02, 1.13078001e-02, 1.13607681e-02, 1.18310389e-02,\n",
       "       1.15483328e-02, 1.14263345e-02, 1.17875488e-02, 1.13821746e-02,\n",
       "       1.18623851e-02, 1.17478761e-02, 1.17219364e-02, 1.19851541e-02,\n",
       "       1.27347328e-02, 1.18145738e-02, 1.22355638e-02, 1.22506371e-02,\n",
       "       1.12069182e-02, 1.18662571e-02, 1.15837795e-02, 1.16172423e-02,\n",
       "       1.15475137e-02, 1.17863919e-02, 1.13741719e-02, 1.19826192e-02,\n",
       "       1.19488272e-02, 1.21834103e-02, 1.20039933e-02, 1.23493217e-02,\n",
       "       1.18644548e-02, 1.21700819e-02, 1.22283316e-02, 1.22400973e-02,\n",
       "       1.24328404e-02, 1.25550244e-02, 1.28141552e-02, 1.26941323e-02,\n",
       "       1.26380065e-02, 1.23349066e-02, 1.25618297e-02, 1.27159755e-02,\n",
       "       1.31537737e-02, 1.28557920e-02, 1.26745689e-02, 1.28152929e-02,\n",
       "       1.24706774e-02, 1.26901467e-02, 1.29430454e-02, 1.27239943e-02,\n",
       "       1.24891458e-02, 1.26496682e-02, 1.26230389e-02, 1.29805570e-02,\n",
       "       1.27310241e-02, 1.31035425e-02, 1.28255133e-02, 1.29447650e-02,\n",
       "       1.24581815e-02, 1.30946758e-02, 1.25832018e-02, 1.28908451e-02,\n",
       "       1.35192730e-02, 1.35022539e-02, 1.27684492e-02, 1.29514952e-02,\n",
       "       1.32868474e-02, 1.28883867e-02, 1.34312544e-02, 1.28346794e-02,\n",
       "       1.27035400e-02, 1.31662730e-02, 1.34317002e-02, 1.42075598e-02,\n",
       "       1.29019385e-02, 1.28823158e-02, 1.35000282e-02, 1.33110465e-02,\n",
       "       1.33548300e-02, 1.36384332e-02, 1.31075344e-02, 1.37180827e-02,\n",
       "       1.32073220e-02, 1.34469360e-02, 1.33127921e-02, 1.36828591e-02,\n",
       "       1.37283603e-02, 1.41386442e-02, 1.43889953e-02, 1.37643360e-02,\n",
       "       1.35625355e-02, 1.34536302e-02, 1.41369989e-02, 1.43628731e-02,\n",
       "       1.39985352e-02, 1.38589720e-02, 1.37380942e-02, 1.43279991e-02,\n",
       "       1.38802752e-02, 1.43524017e-02, 1.43327989e-02, 1.39431060e-02,\n",
       "       1.45076934e-02, 1.43235652e-02, 1.48269987e-02, 1.47693011e-02,\n",
       "       1.44784088e-02, 1.42074463e-02, 1.44815112e-02, 1.46334090e-02,\n",
       "       1.41935490e-02, 1.45520420e-02, 1.50224010e-02, 1.52162220e-02,\n",
       "       1.47627340e-02, 1.52052882e-02, 1.50592234e-02, 1.56141319e-02,\n",
       "       1.56565796e-02, 1.47911148e-02, 1.47032027e-02, 1.49616008e-02,\n",
       "       1.49545747e-02, 1.49583337e-02, 1.56296061e-02, 1.55174556e-02,\n",
       "       1.54794692e-02, 1.44759759e-02, 1.55940955e-02, 1.48724699e-02,\n",
       "       1.55896494e-02, 1.57420513e-02, 1.57432392e-02, 1.55525726e-02,\n",
       "       1.57788029e-02, 1.56439900e-02, 1.58853959e-02, 1.59296583e-02,\n",
       "       1.62476905e-02, 1.58166822e-02, 1.55883453e-02, 1.58063257e-02,\n",
       "       1.60113134e-02, 1.57555940e-02, 1.52995874e-02, 1.59852335e-02,\n",
       "       1.62093139e-02, 1.59965086e-02, 1.61895153e-02, 1.58620994e-02,\n",
       "       1.55782729e-02, 1.61698044e-02, 1.56234273e-02, 1.56368478e-02,\n",
       "       1.55394171e-02, 1.59608875e-02, 1.55399929e-02, 1.62641723e-02,\n",
       "       1.55359617e-02, 1.57894518e-02, 1.60115760e-02, 1.49555307e-02,\n",
       "       1.55118067e-02, 1.51857569e-02, 1.56230917e-02, 1.57796419e-02,\n",
       "       1.57931148e-02, 1.56511431e-02, 1.56846498e-02, 1.53752346e-02,\n",
       "       1.53280863e-02, 1.59888937e-02, 1.53921019e-02, 1.53423036e-02,\n",
       "       1.60073384e-02, 1.47186416e-02, 1.56718841e-02, 1.52005724e-02,\n",
       "       1.52115087e-02, 1.51600017e-02, 1.56673121e-02, 1.55025687e-02,\n",
       "       1.53001245e-02, 1.56517849e-02, 1.51290178e-02, 1.57624785e-02,\n",
       "       1.56994350e-02, 1.53987364e-02, 1.56437615e-02, 1.57356401e-02,\n",
       "       1.53430992e-02, 1.56911859e-02, 1.61914447e-02, 1.50837915e-02,\n",
       "       1.52865449e-02, 1.56360415e-02, 1.56678141e-02, 1.61294114e-02,\n",
       "       1.60433616e-02, 1.61726061e-02, 1.59361575e-02, 1.66270095e-02,\n",
       "       1.62658696e-02, 1.59529516e-02, 1.64130764e-02, 1.67350292e-02,\n",
       "       1.66259169e-02, 1.67896049e-02, 1.63673586e-02, 1.71561173e-02,\n",
       "       1.72593607e-02, 1.74280780e-02, 1.76323584e-02, 1.81175329e-02,\n",
       "       1.73197205e-02, 1.55556905e-02, 1.65623729e-02, 1.65602098e-02,\n",
       "       1.67747889e-02, 1.69274420e-02, 1.65860357e-02, 1.69276296e-02,\n",
       "       1.69403469e-02, 1.71573824e-02, 1.71551983e-02, 1.72378904e-02,\n",
       "       1.70022737e-02, 1.72555849e-02, 1.71067519e-02, 1.68967015e-02,\n",
       "       1.70027001e-02, 1.74109496e-02, 1.72783184e-02, 1.64747062e-02,\n",
       "       1.76148727e-02, 1.77305068e-02, 1.62992305e-02, 1.75715608e-02,\n",
       "       1.69585562e-02, 1.77024837e-02, 1.75477393e-02, 1.65438703e-02,\n",
       "       1.74707340e-02, 1.73040573e-02, 1.71527674e-02, 1.76824317e-02,\n",
       "       1.77740325e-02, 1.71124204e-02, 1.78004793e-02, 1.63427490e-02,\n",
       "       1.66825400e-02, 1.74557983e-02, 1.67770334e-02, 1.69465665e-02,\n",
       "       1.72627192e-02, 1.69107635e-02, 1.72573634e-02, 1.66197435e-02,\n",
       "       1.72237290e-02, 1.77902507e-02, 1.70953743e-02, 1.68531197e-02,\n",
       "       1.75115500e-02, 1.65267551e-02, 1.73621695e-02, 1.64484882e-02,\n",
       "       1.69048643e-02, 1.76448418e-02, 1.78358821e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.d1s['2048_B8']['merged'][2223].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uid': '3c321f80-c026-4776-953a-37ffbe730b8f',\n",
       " 'time': 1608093495.3446026,\n",
       " 'proc_path': '/nsls2/xf16id1/experiments/2020-3/308074/306605/',\n",
       " 'subdir': None,\n",
       " 'CRL': {'state': [1, 1, 1, 0, 1, 1, 1, 0, 0],\n",
       "  'x1': -0.17103125,\n",
       "  'y1': 6.45796875,\n",
       "  'x2': 0.12896875000000002,\n",
       "  'z': 650.0000000000001},\n",
       " 'det_pos': {'saxs': {'x': 454.09625,\n",
       "   'y': 755.15509375,\n",
       "   'z': 499.88945000000217},\n",
       "  'waxs1': {'x': -2.29, 'y': -1.1600660000000005, 'z': 846.0620595},\n",
       "  'waxs2': {'x': 60.000043299999994,\n",
       "   'y': -145.0000521,\n",
       "   'z': 34.99999759999997}},\n",
       " 'BPM': {'stage position': {'x': 6.104998999999999, 'y': -0.08199999999999999},\n",
       "  'beam position': {'x': 0.004462539485698518, 'y': -0.011241976628202352}},\n",
       " 'run_id': '306605',\n",
       " 'group': 'lix',\n",
       " 'owner': 'LY',\n",
       " 'optics': {'wbm_y': 0.32030000000000003,\n",
       "  'wbm_pitch': 1.7778301999999995,\n",
       "  'dcm_y2': -16.5094,\n",
       "  'mono_x': 0.004,\n",
       "  'hfm_x1': -0.1525,\n",
       "  'hfm_x2': -3.1925,\n",
       "  'vfm_y1': -0.7305,\n",
       "  'vfm_y2': 2.4395000000000002},\n",
       " 'proposal_id': '308074',\n",
       " 'data_path': '/nsls2/xf16id1/data/2020-3/308074/306605/',\n",
       " 'slits': {'DDA': {'x': -0.3799996740000001,\n",
       "   'y': 0.6799954539999966,\n",
       "   'dx': 0.3750102860000001,\n",
       "   'dy': 0.20001188400000003},\n",
       "  'Sg': {'x': 0.6049997359999963,\n",
       "   'y': -0.22999843599999892,\n",
       "   'dx': 0.300014692,\n",
       "   'dy': 0.29998811599999975}},\n",
       " 'energy': {'mono_bragg': 6.561308600000001,\n",
       "  'energy': 17299.89981118474,\n",
       "  'gap': 6299.936},\n",
       " 'sample_name': '2048_B8',\n",
       " 'pilatus': {},\n",
       " 'scan_id': 2440,\n",
       " 'beamline_id': 'LIX',\n",
       " 'plan_type': 'generator',\n",
       " 'plan_name': 'grid_scan',\n",
       " 'detectors': ['pil', 'em1', 'em2'],\n",
       " 'motors': ['ss_sz', 'ss_sx'],\n",
       " 'num_points': 4941,\n",
       " 'num_intervals': 4940,\n",
       " 'plan_args': {'detectors': [\"LiXPilatusDetectors(prefix='XF:16IDC-DT', name='pil', read_attrs=['pil1M', 'pil1M.file', 'pil1M.file.file_path', 'pil1M.file.file_number', 'pil1M.file.file_name', 'pil1M.file.file_template', 'pilW1', 'pilW1.file', 'pilW1.file.file_path', 'pilW1.file.file_number', 'pilW1.file.file_name', 'pilW1.file.file_template', 'pilW2', 'pilW2.file', 'pilW2.file.file_path', 'pilW2.file.file_number', 'pilW2.file.file_name', 'pilW2.file.file_template'], configuration_attrs=['pil1M', 'pil1M.cam', 'pil1M.cam.acquire_period', 'pil1M.cam.acquire_time', 'pil1M.cam.image_mode', 'pil1M.cam.manufacturer', 'pil1M.cam.model', 'pil1M.cam.num_exposures', 'pil1M.cam.trigger_mode', 'pil1M.file', 'pilW1', 'pilW1.cam', 'pilW1.cam.acquire_period', 'pilW1.cam.acquire_time', 'pilW1.cam.image_mode', 'pilW1.cam.manufacturer', 'pilW1.cam.model', 'pilW1.cam.num_exposures', 'pilW1.cam.trigger_mode', 'pilW1.file', 'pilW2', 'pilW2.cam', 'pilW2.cam.acquire_period', 'pilW2.cam.acquire_time', 'pilW2.cam.image_mode', 'pilW2.cam.manufacturer', 'pilW2.cam.model', 'pilW2.cam.num_exposures', 'pilW2.cam.trigger_mode', 'pilW2.file'])\",\n",
       "   \"NSLS_EM1(prefix='XF:16IDC-ES{NSLS_EM:1}', name='em1', read_attrs=['current1', 'current1.mean_value', 'current2', 'current2.mean_value', 'current3', 'current3.mean_value', 'current4', 'current4.mean_value', 'sum_all', 'sum_all.mean_value'], configuration_attrs=['current1', 'current2', 'current3', 'current4', 'sum_all'])\",\n",
       "   \"NSLS_EM1(prefix='XF:16IDC-ES{NSLS_EM:2}', name='em2', read_attrs=['current1', 'current1.mean_value', 'current2', 'current2.mean_value', 'current3', 'current3.mean_value', 'current4', 'current4.mean_value', 'sum_all', 'sum_all.mean_value'], configuration_attrs=['current1', 'current2', 'current3', 'current4', 'sum_all'])\"],\n",
       "  'args': [\"EpicsMotor(prefix='XF:16IDC-ES:Scan2-Gonio{Ax:sZ}Mtr', name='ss_sz', settle_time=0.0, timeout=None, read_attrs=['user_readback', 'user_setpoint'], configuration_attrs=['user_offset', 'user_offset_dir', 'velocity', 'acceleration', 'motor_egu'])\",\n",
       "   4.8,\n",
       "   5.2,\n",
       "   81,\n",
       "   \"EpicsMotor(prefix='XF:16IDC-ES:Scan2-Gonio{Ax:sX}Mtr', name='ss_sx', settle_time=0.0, timeout=None, read_attrs=['user_readback', 'user_setpoint'], configuration_attrs=['user_offset', 'user_offset_dir', 'velocity', 'acceleration', 'motor_egu'])\",\n",
       "   -3.85,\n",
       "   -3.55,\n",
       "   61,\n",
       "   True],\n",
       "  'per_step': 'None'},\n",
       " 'hints': {'gridding': 'rectilinear',\n",
       "  'dimensions': [[['ss_sz'], 'primary'], [['ss_sx'], 'primary']]},\n",
       " 'shape': [81, 61],\n",
       " 'extents': [[4.8, 5.2], [-3.85, -3.55]],\n",
       " 'snaking': [False, True],\n",
       " 'plan_pattern': 'outer_product',\n",
       " 'plan_pattern_args': {'args': [\"EpicsMotor(prefix='XF:16IDC-ES:Scan2-Gonio{Ax:sZ}Mtr', name='ss_sz', settle_time=0.0, timeout=None, read_attrs=['user_readback', 'user_setpoint'], configuration_attrs=['user_offset', 'user_offset_dir', 'velocity', 'acceleration', 'motor_egu'])\",\n",
       "   4.8,\n",
       "   5.2,\n",
       "   81,\n",
       "   \"EpicsMotor(prefix='XF:16IDC-ES:Scan2-Gonio{Ax:sX}Mtr', name='ss_sx', settle_time=0.0, timeout=None, read_attrs=['user_readback', 'user_setpoint'], configuration_attrs=['user_offset', 'user_offset_dir', 'velocity', 'acceleration', 'motor_egu'])\",\n",
       "   -3.85,\n",
       "   -3.55,\n",
       "   61,\n",
       "   True]},\n",
       " 'plan_pattern_module': 'bluesky.plan_patterns'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scan header\n",
    "#header['snaking']\n",
    "\n",
    "dt  = h5xs(\"2048_B8.h5\", transField=\"em2_sum_all_mean_value\")\n",
    "#print(dt['2048_B8'].attrs['start'])\n",
    "header = json.loads(dt.fh5[dt.samples[0]].attrs['start'])\n",
    "Height, Width = header['shape']\n",
    "#print(header['shape'])\n",
    "print(Width, Height)\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e8732ff80d4440b49a7fa7dd4961ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1281baf40>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(10,6))\n",
    "\n",
    "xpos = dt.fh5[f\"{dt.samples[0]}/primary/data/ss_sx\"][...]\n",
    "ypos = dt.fh5[f\"{dt.samples[0]}/primary/data/ss_sz\"][...]\n",
    "\n",
    "ax1.plot(xpos, np.arange(len(xpos)) )\n",
    "ax2.plot(np.arange(len(xpos)), ypos )\n",
    "ax3.plot(xpos, ypos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background subtraction: 2048_B8mergedf02080 - 2048_B8mergedf02223\n",
      "using scaling factor of 0.995547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0edcc0e6644a30ab66c3177905f41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# transmitted beam intensity is defined externally: 45131.328000: 45131.328000 \n",
      "# background subtraction using the following set, scaled by 0.995547 (trans):\n",
      "## transmitted beam intensity is defined externally: 45333.208000: 45333.208000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "d1 = dt.d1s['2048_B8']['merged'][2080].bkg_cor(dt.d1s['2048_B8']['merged'][2223], plot_data=False, debug=True, show_eb=False )\n",
    "#d1.plot()\n",
    "print(d1.comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def unpack_d1(data, qgrid, label, trans_value):\n",
    "    \"\"\" utility function to creat a Data1d object from hdf dataset\n",
    "        sepatately given data[intensity and error], qgrid, label, and trans  \n",
    "        works for a dataset that include a list of 1d data as well\n",
    "        transMode is set to trans_mode.external\n",
    "    \"\"\"\n",
    "    #print('data shape', data.shape)\n",
    "    if len(data.shape)>2:\n",
    "        if np.isscalar(trans_value): # this should only happen when intentionally setting trans to 0  ### always true for our case\n",
    "            trans_value = np.zeros(len(data))    # 3721 zeros \n",
    "        return [unpack_d1(d, qgrid, label+(\"f%05d\" % i), t) for i,(d,t) in enumerate(zip(data,trans_value))]   # d --> (2,690) t--> 0 data --> (3721,2,690) trans_value --> 3721,\n",
    "        '''\n",
    "        for i,(d,t) in enumerate(zip(data,trans_value)):\n",
    "            unpack_d1(d, qgrid, label+(\"f%05d\" % i), t)  \n",
    "        '''\n",
    "        # executes when data --> (2,690)\n",
    "    else:\n",
    "        ret = Data1d()\n",
    "        ret.qgrid = qgrid\n",
    "        ret.data = data[0]\n",
    "        ret.err = data[1]\n",
    "        ret.label = label\n",
    "        ret.trans = trans_value\n",
    "        ret.transMode = trans_mode.external\n",
    "        return ret\n",
    "\n",
    "def lsh5(hd, prefix='', top_only=False, silent=False):\n",
    "    \"\"\" list the content of a HDF5 file\n",
    "        \n",
    "        hd: a handle returned by h5py.File()\n",
    "        prefix: use to format the output when lsh5() is called recursively\n",
    "        top_only: returns the names of the top-level groups\n",
    "        silent: suppress printouts if True\n",
    "    \"\"\"\n",
    "    if top_only:\n",
    "        tp_grps = list(hd.keys())\n",
    "        if not silent:\n",
    "            print(tp_grps)\n",
    "        return tp_grps\n",
    "    for k in list(hd.keys()):\n",
    "        print(prefix, k)\n",
    "        if isinstance(hd[k], h5py.Group):\n",
    "            print(list(hd[k].attrs.items()))\n",
    "            lsh5(hd[k], prefix+\"=\")\n",
    "\n",
    "            \n",
    "font_size_list = ['xx-small', 'x-small', 'small', 'medium', 'large', 'x-large', 'xx-large']\n",
    "def get_font_size(size_index):\n",
    "    \"\"\" \"medium\" has size_index of 0\n",
    "        the size_index is negative for smaller fonts and possitive for larger ones  \n",
    "    \"\"\"\n",
    "    if size_index in font_size_list:\n",
    "        i = font_size_list.index(size_index)\n",
    "    else:\n",
    "        i = int(size_index)+3\n",
    "        if i<0:\n",
    "            i = 0\n",
    "        elif i>=len(font_size_list):\n",
    "            i = len(font_size_list)-1\n",
    "    return i-3,font_size_list[i]\n",
    "\n",
    "class Data1d:\n",
    "    def __init__(self, trandMode=None):\n",
    "        self.comments = \"\"\n",
    "        self.label = \"data\"\n",
    "        self.overlaps = []\n",
    "        self.raw_data = {}\n",
    "        self.timestamp = None\n",
    "        self.trans = 0\n",
    "        \n",
    "    def set_trans(self, trans=-1, ref_trans=-1, transMode=None, \n",
    "                  q_start=1.85, q_end=2.15, debug=False):\n",
    "        \"\"\"\n",
    "        normalize intensity, from trans to ref_trans\n",
    "        trans can be either from the beam center or water scattering\n",
    "        this operation should be performed after SAXS/WAXS merge, because\n",
    "        1. SAXS and WAXS should have the same trans\n",
    "        2. if trans_mode is TRNAS_FROM_WAXS, the trans value needs to be calculated from WAXS data\n",
    "        \"\"\"\n",
    "        if transMode is not None:\n",
    "            self.transMode = transMode\n",
    "        if self.transMode == trans_mode.from_waxs:\n",
    "            # get trans for the near the maximum in the WAXS data\n",
    "            # for solution scattering, hopefully this reflect the intensity of water scattering\n",
    "            idx = (self.qgrid > q_start) & (self.qgrid < q_end)  # & (self.data>0.5*np.max(self.data))\n",
    "            if len(self.qgrid[idx]) < 5:\n",
    "                print(\"not enough data points under the water peak, consider using a different trans_mode.\")\n",
    "                #raise Exception()\n",
    "            \n",
    "            # trying to narrow down the peak range turns out to be a bad idea\n",
    "            # the width then could vary between datasets, creating artificial fluctuation in trans \n",
    "            #idx1 = idx & (self.data >= 0.95*np.max(self.data[idx]))\n",
    "\n",
    "            if (self.data[idx]<WAXS_THRESH).all() and debug!='quiet':\n",
    "                print(\"the data points for trans calculation are below WAXS_THRESH: \", \n",
    "                      np.max(self.data[idx]), WAXS_THRESH)                \n",
    "            self.trans = np.sum(self.data[idx])\n",
    "            qavg = np.average(self.qgrid[idx])\n",
    "            if self.trans<1.0:\n",
    "                print('caluclated trans is %f, setting it artifically to WAXS_THRESH.' % self.trans)\n",
    "                self.trans = WAXS_THRESH\n",
    "            if debug==True:\n",
    "                print(\"using data near the high q end (q~%f)\" % qavg, end=' ')\n",
    "            self.comments += \"# transmitted beam intensity from WAXS (q~%.2f)\" % qavg\n",
    "        elif self.transMode == trans_mode.external:\n",
    "            if trans > 0:\n",
    "                self.comments += \"# transmitted beam intensity is defined externally: %f\"%trans\n",
    "                self.trans = trans\n",
    "            elif self.trans<0:\n",
    "                print(\"trans_mode is TRANS_EXTERNAL but a valid trans value is not provided\")\n",
    "                raise Exception()\n",
    "        else:\n",
    "            raise Exception(\"invalid transmode: \", self.tMode)\n",
    "\n",
    "        self.comments += \": %f \\n\" % self.trans\n",
    "        if debug==True:\n",
    "            print(\"trans for %s set to %f\" % (self.label, self.trans))\n",
    "\n",
    "        if ref_trans > 0:\n",
    "            self.comments += \"# scattering intensity normalized to ref_trans = %f \\n\" % ref_trans\n",
    "            self.data *= ref_trans / self.trans\n",
    "            self.err *= ref_trans / self.trans\n",
    "            for ov in self.overlaps:\n",
    "                ov['raw_data1'] *= ref_trans / self.trans\n",
    "                ov['raw_data2'] *= ref_trans / self.trans\n",
    "            self.trans = ref_trans\n",
    "            if debug==True:\n",
    "                print(\"normalized to %f\" % ref_trans)\n",
    "\n",
    "    \n",
    "class h5xs():\n",
    "    \"\"\" Scattering data in transmission geometry\n",
    "        Transmitted beam intensity can be set either from the water peak (sol), or from intensity monitor.\n",
    "        Data processing can be done either in series, or in parallel. Serial processing can be forced.\n",
    "        \n",
    "    \"\"\"    \n",
    "    def __init__(self, fn, exp_setup=None, transField='', save_d1=True):\n",
    "        \"\"\" exp_setup: [detectors, qgrid]\n",
    "            transField: the intensity monitor field packed by suitcase from databroker\n",
    "            save_d1: save newly processed 1d data back to the h5 file\n",
    "        \"\"\"\n",
    "        self.d1s = {}\n",
    "        self.detectors = None\n",
    "        self.samples = []\n",
    "        self.attrs = {}\n",
    "        # name of the dataset that contains transmitted beam intensity, e.g. em2_current1_mean_value\n",
    "        self.transField = None  \n",
    "\n",
    "        self.fn = fn\n",
    "        self.save_d1 = save_d1\n",
    "        self.fh5 = h5py.File(self.fn, \"r+\")   # file must exist\n",
    "        if exp_setup==None:     # assume the h5 file will provide the detector config\n",
    "            self.qgrid = self.read_detectors()\n",
    "        else:\n",
    "            self.detectors, self.qgrid = exp_setup\n",
    "            self.save_detectors()\n",
    "        self.list_samples(quiet=True)\n",
    "        # find out what are the fields corresponding to the 2D detectors\n",
    "        # at LiX there are two possibilities\n",
    "        data_fields = list(self.fh5[self.samples[0]+'/primary/data'])\n",
    "        self.det_name = None\n",
    "        # these are the detectors that are present in the data\n",
    "        d_dn = [d.extension for d in self.detectors]\n",
    "        '''\n",
    "        det_names = [{\"_SAXS\": \"pil1M_image\",\n",
    "                      \"_WAXS1\": \"pilW1_image\",\n",
    "                      \"_WAXS2\": \"pilW2_image\"}, \n",
    "                     {\"_SAXS\": \"pil1M_ext_image\",\n",
    "                      \"_WAXS1\": \"pilW1_ext_image\",\n",
    "                      \"_WAXS2\": \"pilW2_ext_image\"}]\n",
    "        '''\n",
    "        for det_name in det_names:\n",
    "            for k in set(det_name.keys()).difference(d_dn):\n",
    "                del det_name[k]\n",
    "            if set(det_name.values()).issubset(data_fields):\n",
    "                self.det_name = det_name\n",
    "                break\n",
    "        if self.det_name is None:\n",
    "            print('fields in the h5 file: ', data_fields)\n",
    "            raise Exception(\"Could not find the data corresponding to the detectors.\")\n",
    "        if transField=='':\n",
    "            # \"2,\" --> self.transField = '' and self.transMode = trans_mode.from_waxs\n",
    "            if 'trans' in self.fh5.attrs:\n",
    "                [v, self.transField] = self.fh5.attrs['trans'].split(',')\n",
    "                self.transMode = trans_mode(int(v))\n",
    "                return\n",
    "            else:\n",
    "                self.transMode = trans_mode.from_waxs\n",
    "                self.transField = ''\n",
    "        elif transField not in data_fields:\n",
    "            print(\"invalid filed for transmitted intensity: \", transField)\n",
    "            raise Exception()\n",
    "        else:\n",
    "            self.transField = transField\n",
    "            self.transMode = trans_mode.external\n",
    "        self.fh5.attrs['trans'] = ','.join([str(self.transMode.value), self.transField])  # \"0,em2_sum_all_mean_value\"\n",
    "        self.fh5.flush()\n",
    "            \n",
    "    def save_detectors(self):\n",
    "        dets_attr = [det.pack_dict() for det in self.detectors]\n",
    "        self.fh5.attrs['detectors'] = json.dumps(dets_attr)\n",
    "        self.fh5.attrs['qgrid'] = list(self.qgrid)\n",
    "        self.fh5.flush()\n",
    "    \n",
    "    def read_detectors(self):\n",
    "        dets_attr = self.fh5.attrs['detectors']\n",
    "        qgrid = self.fh5.attrs['qgrid']\n",
    "        self.detectors = [create_det_from_attrs(attrs) for attrs in json.loads(dets_attr)]  \n",
    "        return np.asarray(qgrid)\n",
    "    \n",
    "    def list_samples(self, quiet=False):\n",
    "        self.samples = lsh5(self.fh5, top_only=True, silent=True)\n",
    "        if not quiet:\n",
    "            print(self.samples)\n",
    "    \n",
    "    def load_d1s(self, sn=None):\n",
    "        \"\"\" load the processed 1d data saved in the hdf5 file into memory \n",
    "            for each sample\n",
    "                 attribute \"selected\": which raw data are included in average\n",
    "                 attribute \"sc_factor\": scaling factor used for buffer subtraction\n",
    "            raw data: from each detector, and 'merged'\n",
    "            averaged data: averaged from multiple frames\n",
    "            corrected data: subtracted for buffer scattering\n",
    "            buffer data will be recreated based on buffer assignment \n",
    "        \"\"\"        \n",
    "        print(sn)\n",
    "        if sn==None:\n",
    "            self.list_samples(quiet=True)\n",
    "            for sn in self.samples:\n",
    "                print('Recursion is going to call now')\n",
    "                self.load_d1s(sn)\n",
    "                print(f'sm is {sn} and Recursion is returned')  \n",
    "        \n",
    "        fh5 = self.fh5\n",
    "        if \"processed\" not in lsh5(fh5[sn], top_only=True, silent=True): \n",
    "            print('Hey no processed')\n",
    "            return\n",
    "        \n",
    "        print('Attributes list in the constructor object', list(self.attrs.keys()))\n",
    "        if sn not in list(self.attrs.keys()):\n",
    "            self.d1s[sn] = {}\n",
    "            self.attrs[sn] = {}\n",
    "        grp = fh5[sn+'/processed']\n",
    "        print('processed attrs', grp.attrs.keys())\n",
    "        for k in list(grp.attrs.keys()):\n",
    "            self.attrs[sn][k] = grp.attrs[k]   \n",
    "        for k in lsh5(grp, top_only=True, silent=True):   # k is '_SAXS', '_WAXS2' and 'merged'\n",
    "            print(f'{k} is executing')\n",
    "            if 'trans' in grp[k].attrs.keys():\n",
    "                tvs = grp[k].attrs['trans']\n",
    "            else:\n",
    "                tvs = 0\n",
    "            #print(grp[k].shape)\n",
    "            #print(len(grp[k]))\n",
    "            self.d1s[sn][k] = unpack_d1(grp[k], self.qgrid, sn+k, tvs)\n",
    "        print(f'Finally recursion call is completed sn is {sn}')\n",
    "        \n",
    "    def set_trans(self, sn=None, transMode=None, interpolate=False, gf_sigma=5):\n",
    "        \"\"\" set the transmission values for the merged data\n",
    "            the trans values directly from the raw data (water peak intensity or monitor counts)\n",
    "            but this value is changed if the data is scaled\n",
    "            the trans value for all processed 1d data are saved as attrubutes of the dataset\n",
    "        \"\"\"\n",
    "        if transMode is not None:\n",
    "            self.transMode = transMode\n",
    "        if self.transMode==None:\n",
    "            raise Exception(\"a valid transmited intensity mode must be specified.\")\n",
    "\n",
    "        if sn is None:\n",
    "            samples = self.samples\n",
    "        else:\n",
    "            samples = [sn]\n",
    "\n",
    "        for s in samples:\n",
    "            if transMode==trans_mode.external:\n",
    "                if self.transField in self.fh5[f'{s}/primary/data/']:\n",
    "                    trans_data = self.fh5[f'{s}/primary/data/{self.transField}'][...]\n",
    "                    ts = self.fh5[f'{s}/primary/timestamps/{self.transField}'][...]\n",
    "                elif self.transField in self.fh5[f'{s}']:\n",
    "                    trans_data = self.fh5[f'{s}/{self.transField}/data/{self.transField}'][...]\n",
    "                    ts = self.fh5[f'{s}/{self.transField}/timestamps/{self.transField}'][...]\n",
    "                else:\n",
    "                    raise Exception(f\"could not find transmission data from {self.transField}.\")\n",
    "            if interpolate:  ## smoothing really\n",
    "                spl = UnivariateSpline(ts, gaussian_filter(trans_data, gf_sigma))\n",
    "                ts0 = self.fh5[f'{s}/primary/timestamps/{list(self.det_name.values())[0]}'][...]\n",
    "                trans_data = spl(ts0)\n",
    "\n",
    "            # these are the datasets that needs updated trans values\n",
    "            print('d1s keys ', self.d1s[s].keys())\n",
    "            if 'merged' not in self.d1s[s].keys():\n",
    "                continue\n",
    "            t_values = []\n",
    "            print('loop length ',len(self.d1s[s]['merged']))\n",
    "            for i in range(len(self.d1s[s]['merged'])):\n",
    "                if self.transMode==trans_mode.external:\n",
    "                    self.d1s[s]['merged'][i].set_trans(trans_data[i], transMode=self.transMode)\n",
    "                else:\n",
    "                    self.d1s[s]['merged'][i].set_trans(transMode=self.transMode)\n",
    "                t_values.append(self.d1s[s]['merged'][i].trans)\n",
    "            if 'averaged' not in self.d1s[s].keys():\n",
    "                continue\n",
    "            self.d1s[s]['averaged'].trans = np.average(t_values)\n",
    "            \n",
    "    def bkg_cor(self, dbak, sc_factor=1., plot_data=False, ax=None, \n",
    "                inplace=False, check_overlap=False, show_eb=True, debug=False, fontsize='large'):\n",
    "        \"\"\"\n",
    "        background subtraction\n",
    "        \"\"\"\n",
    "        dset = None\n",
    "        if inplace:\n",
    "            dset = self\n",
    "        else:\n",
    "            dset = copy.deepcopy(self)\n",
    "        i_fs = get_font_size(fontsize)[0]\n",
    "\n",
    "        if debug==True:\n",
    "            print(\"background subtraction: %s - %s\" % (dset.label, dbak.label))\n",
    "        if not (dbak.qgrid == dset.qgrid).all():\n",
    "            print(\"background subtraction failed: qgrid mismatch\")\n",
    "            sys.exit()\n",
    "        if dset.trans < 0 or dbak.trans <= 0:\n",
    "            print(\"WARNING: trans value not assigned to data or background, assuming normalized intensity.\")\n",
    "            sc = 1.\n",
    "        else:\n",
    "            sc = dset.trans / dbak.trans\n",
    "\n",
    "        # need to include raw data\n",
    "        if plot_data:\n",
    "            if ax is None:\n",
    "                plt.figure()\n",
    "                plt.subplots_adjust(bottom=0.15)\n",
    "                ax = plt.gca()\n",
    "            ax.set_xlabel(\"$q (\\AA^{-1})$\", fontsize=get_font_size(i_fs)[1])\n",
    "            ax.set_ylabel(\"$I$\", fontsize=get_font_size(i_fs)[1])\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_yscale('log')\n",
    "            ax.xaxis.set_tick_params(labelsize=get_font_size(i_fs-1)[1])\n",
    "            ax.yaxis.set_tick_params(labelsize=get_font_size(i_fs-1)[1])\n",
    "            idx = (dset.data > 0) & (dbak.data > 0)\n",
    "            ax.plot(dset.qgrid[idx], dset.data[idx], label=self.label)\n",
    "            ax.plot(dbak.qgrid[idx], dbak.data[idx], label=dbak.label)\n",
    "            ax.plot(dbak.qgrid[idx], dbak.data[idx] * sc * sc_factor, label=dbak.label + \", scaled\")\n",
    "\n",
    "        if len(dset.overlaps) != len(dbak.overlaps):\n",
    "            if check_overlap:\n",
    "                raise Exception(\"Background subtraction failed: overlaps mismatch.\")\n",
    "        else:\n",
    "            for i in range(len(dset.overlaps)):\n",
    "                dset.overlaps[i]['raw_data1'] -= dbak.overlaps[i]['raw_data1'] * sc_factor * sc\n",
    "                dset.overlaps[i]['raw_data2'] -= dbak.overlaps[i]['raw_data2'] * sc_factor * sc\n",
    "                if plot_data:\n",
    "                    ax.plot(dset.overlaps[i]['q_overlap'], dset.overlaps[i]['raw_data1'], \"v\")\n",
    "                    ax.plot(dset.overlaps[i]['q_overlap'], dset.overlaps[i]['raw_data2'], \"^\")\n",
    "        if plot_data:\n",
    "            leg = ax.legend(loc='upper right', frameon=False)\n",
    "            for t in leg.get_texts():\n",
    "                t.set_fontsize(get_font_size(i_fs-2)[1])\n",
    "\n",
    "        if debug==True:\n",
    "            print(\"using scaling factor of %f\" % (sc * sc_factor))\n",
    "        dset.data -= dbak.data * sc * sc_factor\n",
    "        dset.err += dbak.err * sc * sc_factor\n",
    "        if plot_data:\n",
    "            if show_eb:\n",
    "                ax.errorbar(dset.qgrid, dset.data, dset.err)\n",
    "            else:\n",
    "                ax.plot(dset.qgrid, dset.data)\n",
    "\n",
    "        dset.comments += \"# background subtraction using the following set, scaled by %f (trans):\\n\" % sc\n",
    "        if not sc_factor == 1.:\n",
    "            dset.comments += \"# with addtional scaling factor of: %f\\n\" % sc_factor\n",
    "        dset.comments += dbak.comments.replace(\"# \", \"## \")\n",
    "\n",
    "        return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1934_B8\n",
      "Attributes list in the constructor object []\n",
      "processed attrs <KeysViewHDF5 []>\n",
      "_SAXS is executing\n",
      "_WAXS2 is executing\n",
      "merged is executing\n",
      "Finally recursion call is completed sn is 1934_B8\n",
      "d1s keys  dict_keys(['_SAXS', '_WAXS2', 'merged'])\n",
      "loop length  4141\n"
     ]
    }
   ],
   "source": [
    "from py4xs.detector_config import create_det_from_attrs\n",
    "import numpy as np\n",
    "from py4xs.local import det_names\n",
    "from py4xs.slnxs import Data1d, trans_mode\n",
    "from py4xs.hdf import h5exp\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.interpolate import UnivariateSpline \n",
    "import h5py\n",
    "\n",
    "# import os\n",
    "# os.chdir('../')\n",
    "# os.getcwd()\n",
    "\n",
    "dt  = h5xs(\"1934_B8.h5\", transField=\"em2_sum_all_mean_value\")  # transField=\"em2_sum_all_mean_value\"\n",
    "dt.load_d1s(sn='1934_B8')\n",
    "dt.set_trans(transMode=trans_mode.external)\n",
    "dt.d1s['1934_B8'].keys()\n",
    "\n",
    "de = h5exp(\"exp.h5\")\n",
    "qgrid2 = np.hstack([np.arange(0.005, 0.0499, 0.001), np.arange(0.05, 0.099, 0.002), np.arange(0.1, 3.2, 0.005)])\n",
    "#dt  = h5xs(\"2048_B8.h5\", [de.detectors, qgrid2])\n",
    "#dt  = h5xs(\"2048_B8.h5\", )  # transField=\"em2_sum_all_mean_value\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        , 486.29711395, 317.26634722,\n",
       "       213.80951055, 147.46624926, 104.06895486,  77.06820181,\n",
       "        57.78208289,  44.79722541,  34.49038235,  26.5114945 ,\n",
       "        21.51251749,  17.85763242,  14.16029503,  11.67647489,\n",
       "         9.90668536,   8.38696173,   7.15036163,   6.1334319 ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.d1s['1934_B8']['merged'][10].data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.        , 486.29711395, 317.26634722,\n",
       "       213.80951055, 147.46624926, 104.06895486,  77.06820181,\n",
       "        57.78208289,  44.79722541,  34.49038235,  26.5114945 ,\n",
       "        21.51251749,  17.85763242,  14.16029503,  11.67647489,\n",
       "         9.90668536,   8.38696173,   7.15036163,   6.1334319 ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.d1s['1934_B8']['merged'][10].data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['detectors', 'qgrid', 'trans']>\n",
      "dict_keys(['1934_B8'])\n",
      "True\n",
      "[[[ 1.15306894  0.52084053 -1.54221988]\n",
      "  [-0.22893785  0.04423111 -0.11368222]]\n",
      "\n",
      " [[ 0.63413091  0.4111231   0.72615947]\n",
      "  [ 0.3043701   1.39430244 -0.97664551]]\n",
      "\n",
      " [[ 1.23098884  0.24173566  1.29827319]\n",
      "  [ 0.08480775 -0.17242967  0.0825077 ]]\n",
      "\n",
      " [[-0.75485361  0.02189807 -0.78059705]\n",
      "  [-0.49986895 -0.84057312  1.69403602]]\n",
      "\n",
      " [[ 1.46941499 -0.08485839 -1.06355841]\n",
      "  [ 1.18274751  0.06231947  0.22100816]]]\n",
      "[0. 0. 0. 0. 0.]\n",
      "i = 0, d = [[ 1.15306894  0.52084053 -1.54221988]\n",
      " [-0.22893785  0.04423111 -0.11368222]], t = 0.0\n",
      "i = 1, d = [[ 0.63413091  0.4111231   0.72615947]\n",
      " [ 0.3043701   1.39430244 -0.97664551]], t = 0.0\n",
      "i = 2, d = [[ 1.23098884  0.24173566  1.29827319]\n",
      " [ 0.08480775 -0.17242967  0.0825077 ]], t = 0.0\n",
      "i = 3, d = [[-0.75485361  0.02189807 -0.78059705]\n",
      " [-0.49986895 -0.84057312  1.69403602]], t = 0.0\n",
      "i = 4, d = [[ 1.46941499 -0.08485839 -1.06355841]\n",
      " [ 1.18274751  0.06231947  0.22100816]], t = 0.0\n"
     ]
    }
   ],
   "source": [
    "print(dt.fh5.attrs.keys())\n",
    "print(dt.attrs.keys())\n",
    "print(np.isscalar('Pr'))\n",
    "\n",
    "# testing unpack function\n",
    "data = np.random.randn(5,2,3)   # --> SAXS /WAXS/merged 3721, 2, 690\n",
    "print(data)\n",
    "trans_value = np.zeros(len(data)) \n",
    "print(trans_value)\n",
    "for i,(d,t) in enumerate(zip(data,trans_value)):\n",
    "    print(f'i = {i}, d = {d}, t = {t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.799873 4.800101 4.804741 4.804733 4.804735 4.804723 4.804719 4.804718\n",
      " 4.804702 4.804711]\n"
     ]
    }
   ],
   "source": [
    "print(ypos[60:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
