{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "harmful-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from essential_func import *\n",
    "qgrid2 = np.hstack([np.arange(0.005, 0.0499, 0.001), np.arange(0.05, 0.099, 0.002), np.arange(0.1, 3.2, 0.005)])\n",
    "os.chdir('/Users/bashit.a/Documents/Alzheimer/Dec-15/')     # location where your h5 and exp file are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "thousand-steering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixalated Sum WAXS shape =  (1043, 981) Mean = 13452.854182 Min. = -9882.000000 Max. = 5767807176.000000\n"
     ]
    }
   ],
   "source": [
    "## Load file before WAXS thresholding (Requires to run the folliwing cell only) - should not take more than 3 min to load for M1 macbook\n",
    "\n",
    "file = '2048_B8.h5'\n",
    "with h5py.File(file,'r') as hdf:\n",
    "    dset_waxs = np.array(hdf.get(f'{h5_top_group(file)}/primary/data/pilW2_image'))         # waxs data read from h5 file\n",
    "    dset_waxs_sum = np.sum(dset_waxs,axis=0)                                # summing all the frame values\n",
    "    print('Pixalated Sum WAXS shape = ', dset_waxs_sum.shape , 'Mean = {:02f}'.format(dset_waxs_sum.mean()) ,'Min. = {:02f}'.format(dset_waxs_sum.min()), 'Max. = {:02f}'.format(dset_waxs_sum.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "powerful-leave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c894107086f4d479a8185adeca19120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=13452.854181510053, continuous_update=False, description='a_max', layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## WAXS thresholding and loading\n",
    "## specs/Slider Properties\n",
    "AMIN_DEFAULT_VALUE = 0       # minimum value for the pixalated sum\n",
    "AMAX_DEFAULT_VALUE = dset_waxs_sum.mean() ; AMAX_MIN_VALUE = dset_waxs_sum.mean() ; AMAX_MAX_VALUE = 60000;  AMAX_SLIDER_STEP = 100;    # maximum values for the pixalated sum\n",
    "# valid_range_min, valid_range_max = (0,10)   # just for WAXS Display purpose\n",
    "\n",
    "\n",
    "def waxs_thresholding(a_min, a_max, thr, frame):\n",
    "    %matplotlib widget\n",
    "    \n",
    "    args = (dset_waxs_sum, a_min, a_max, thr)\n",
    "    dset_waxs_thr, gray_img, thr_fr_img = threshold_patch_one_frame(dset_waxs[frame], args = args)\n",
    "    \n",
    "    #### plot thresholded pixalated sum\n",
    "    f, axs = plt.subplots(nrows=2,ncols=2,figsize=(12,8),num=f'{file}')\n",
    "    im = axs[0,0].imshow(dset_waxs_thr, cmap = 'rainbow')       #plt.colorbar(im, fraction=0.046, pad=0.04)  \n",
    "    show_colorbar(im,f,axs[0,0])\n",
    "    axs[0,0].set_title('Pixelated Sum')\n",
    "    #### plot global thresholding  \n",
    "    im = axs[0,1].imshow(gray_img, cmap='gray')       \n",
    "    axs[0,1].set_title(f'Binary Threshold = {thr}')\n",
    "\n",
    "    patching(file, frame, qgrid2, args=args, axes = (f,[axs[1,0], axs[1,1]]), method = 'thresholding',  )\n",
    "    \n",
    "    print('a_min = ', a_min, 'a_max = {:0.2f}'.format(a_max), 'thr = ', thr)\n",
    "\n",
    "frame = ipywidgets.IntSlider(value=0, min=0, max=len(dset_waxs), step=1, continuous_update=False, layout=ipywidgets.Layout(width='50%'))\n",
    "a_min = ipywidgets.fixed(value=AMIN_DEFAULT_VALUE)\n",
    "a_max = ipywidgets.FloatSlider(value=AMAX_DEFAULT_VALUE, min=AMAX_MIN_VALUE,     max=AMAX_MAX_VALUE, step=AMAX_SLIDER_STEP, continuous_update=False, layout=ipywidgets.Layout(width='50%'))\n",
    "thr   = ipywidgets.IntSlider(value=a_min.value,          min=AMIN_DEFAULT_VALUE, max=AMAX_MAX_VALUE, step=AMAX_SLIDER_STEP, continuous_update=False, layout=ipywidgets.Layout(width='50%'))\n",
    "ipywidgets.jslink((a_max,'value'),(thr,'max'))           # make sure threshold's maximum value doesn't exceed a_max value\n",
    "\n",
    "ipywidgets.interactive(waxs_thresholding, a_min=a_min, a_max=a_max, thr=thr, frame=frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wicked-worker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706bcefcab594e71b412bf7e653b31e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb0c44e8e9c4627aeb323f5fcc45e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Frame', layout=Layout(width='50…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## ---- Test performance of thresholded vs original 1-D plot ---- ######## (parameters depends on 3rd cell)\n",
    "%matplotlib widget\n",
    "file = '2048_B8.h5'\n",
    "\n",
    "Iq_S = read_Iq(file,'_WAXS2')\n",
    "Width, Height = width_height(file)    # considering the fact that width and height is same for source and masked file\n",
    "n_patterns = Width*Height \n",
    "\n",
    "f,ax = plt.subplots()\n",
    "def update_plot(frame):\n",
    "    ax.clear()\n",
    "    # source plot\n",
    "    ax.plot(qgrid2, Iq_S[frame], label = f'Source - {frame}')\n",
    "    \n",
    "    # masked frame\n",
    "    args = dset_waxs_sum, a_min.value, a_max.value, thr.value\n",
    "    Iq_M = patching(file, frame, qgrid2, args=args, method = 'thresholding')\n",
    "    ax.plot(qgrid2, Iq_M, label = f'Masked - {frame}')\n",
    "    \n",
    "    ax.set(xlabel = \"$q (\\AA^{-1})$\", ylabel = \"$I$\", xscale='linear', yscale = 'log' ); \n",
    "    ax.legend()\n",
    "\n",
    "frame = ipywidgets.IntSlider(min=0, max=n_patterns-1, value=0, step=1, description = \"Frame\", continuous_update=False, layout=ipywidgets.Layout(width='50%'))\n",
    "ipywidgets.interactive(update_plot, frame=frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "transparent-celtic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048_B8_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Mar-24 ...\n",
      "2048_B8_masked.h5 copy is done\n",
      "2048_B8_masked.h5 Loading data into a numpy array started \n",
      "2048_B8_masked.h5 Loading data into a numpy array finished in 64.95390291700005 seconds\n",
      "2048_B8_masked.h5 Patching Started \n",
      "2048_B8_masked.h5 Patching finished in 45.25096725000003 seconds\n",
      "2048_B8_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "2048_B8_masked.h5 patched pilW2_image dataset creation finished in 114.97170037499995 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=2048_B8, fr1=0\n",
      "data received: sn=2048_B8, fr1=617\n",
      "data received: sn=2048_B8, fr1=1234\n",
      "data received: sn=2048_B8, fr1=1851\n",
      "data received: sn=2048_B8, fr1=2468\n",
      "data received: sn=2048_B8, fr1=3085\n",
      "data received: sn=2048_B8, fr1=3702\n",
      "data received: sn=2048_B8, fr1=4319\n",
      "2048_B8_masked.h5 total 1-d averaging time 541.735027042 seconds\n"
     ]
    }
   ],
   "source": [
    "##### --------- 1-d averaging after thresholding for one file  --------- ##### (Independent Cell)\n",
    "### spec\n",
    "source_file = \"2048_B8.h5\"\n",
    "args =  0, 27152, 25200   # manually can set args = (a_min.value, a_max.value, thr.value) = 0, 30000, 16000 or Get values from 3rd cell print output\n",
    "\n",
    "### computation\n",
    "masked_file = circ_avg_from_patches(source_file, qgrid2, args=args, method = 'thresholding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pediatric-rainbow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame information extraction completes with _SAXS shape (1, 1043, 981) _WAXS shape (1, 1043, 981)...\n",
      "Circular averaging starts now ... \n",
      "2048_B8_masked_2223.h5 total 1-d averaging time 0.44504058299992266 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bashit.a/Documents/Alzheimer/Codes/py4xs/data2d.py:350: RuntimeWarning: invalid value encountered in sqrt\n",
      "  dI = np.sqrt(Iq2-Iq*Iq)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5f3a2bf3a54273b0a80e98304a8f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############### -------- configure patch size and copy the pathces tuplte to the next cell for computing 1-d averaging for all frames ------------- ################### (Independent Cell)\n",
    "%matplotlib widget\n",
    "frame = 2223         # possible_bkg frame\n",
    "file = '2048_B8.h5'\n",
    "patches = patches = [\n",
    "                             [[800, 0], [960, 120]],\n",
    "                             [[0, 0], [960, 120]],\n",
    "                             [[590, 220], [610, 240]],\n",
    "                             [[0, 590], [45, 615]],\n",
    "                             [[315, 740], [345, 765]],\n",
    "                             [[630, 900], [655, 920]],\n",
    "                             [[20, 955], [70, 985]],\n",
    "                             [[890, 375], [920, 400]],\n",
    "                             [[865, 990], [985, 1030]],\n",
    "                             [[310, 420], [330, 435]]\n",
    "                    ]\n",
    "\n",
    "patching(file, frame, qgrid2, args=patches, method = 'rec_circ_patch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "primary-repeat",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2302_EC-roi2_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Mar-24/Sample-2 ...\n",
      "2302_EC-roi2_masked.h5 copy is done\n",
      "2302_EC-roi2_masked.h5 Loading data into a numpy array started \n",
      "2302_EC-roi2_masked.h5 Loading data into a numpy array finished in 56.88684691599997 seconds\n",
      "2302_EC-roi2_masked.h5 Patching Started \n",
      "2302_EC-roi2_masked.h5 Patching Finished\n",
      "2302_EC-roi2_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "2302_EC-roi2_masked.h5 patched pilW2_image dataset creation finished in 90.95033787500006 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=2302_EC-roi2, fr1=0\n",
      "data received: sn=2302_EC-roi2, fr1=480\n",
      "data received: sn=2302_EC-roi2, fr1=960\n",
      "data received: sn=2302_EC-roi2, fr1=1440\n",
      "data received: sn=2302_EC-roi2, fr1=1920\n",
      "data received: sn=2302_EC-roi2, fr1=2400\n",
      "data received: sn=2302_EC-roi2, fr1=2880\n",
      "data received: sn=2302_EC-roi2, fr1=3360\n",
      "2302_EC-roi2_masked.h5 total 1-d averaging time 482.8924838329999 seconds\n",
      "Successfully created 2302_EC-roi2.h5 ---> 2302_EC-roi2_masked.h5\n"
     ]
    }
   ],
   "source": [
    "# 1-d averaging after rectangular and/or circular patches for one file  (Independent Cell)\n",
    "### spec\n",
    "source_file = \"2048_B8.h5\"\n",
    "patches = [\n",
    "#                              [[800, 0], [980, 150]],\n",
    "#                              [[245, 0], [385, 130]],\n",
    "          ]\n",
    "\n",
    "### computation\n",
    "masked_file = circ_avg_from_patches(source_file, qgrid2, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "handmade-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 30000, 16000]\n"
     ]
    }
   ],
   "source": [
    "## patching information retrival from _masked.h5 file    (Independent Cell)\n",
    "#specs\n",
    "file = \"2048_B8_masked.h5\"\n",
    "# computation\n",
    "try: patches = get_patch_attributes(f'{file}'); print(patches)\n",
    "except: print(f'{file} does not have patches information on the processed folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intended-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check config.json file integrity     (Independent Cell)\n",
    "No_error_no_prb = get_json_str_data('config-dec-15.json');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blank-review",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1934_B8_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "1934_B8_masked.h5 copy is done\n",
      "1934_B8_masked.h5 Loading data into a numpy array started \n",
      "1934_B8_masked.h5 Loading data into a numpy array finished in 64.04968554099923 seconds\n",
      "1934_B8_masked.h5 Patching Started \n",
      "1934_B8_masked.h5 Patching Finished\n",
      "1934_B8_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "1934_B8_masked.h5 patched pilW2_image dataset creation finished in 97.23200600000018 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=1934_B8, fr1=0\n",
      "data received: sn=1934_B8, fr1=517\n",
      "data received: sn=1934_B8, fr1=1034\n",
      "data received: sn=1934_B8, fr1=1551\n",
      "data received: sn=1934_B8, fr1=2068\n",
      "data received: sn=1934_B8, fr1=2585\n",
      "data received: sn=1934_B8, fr1=3102\n",
      "data received: sn=1934_B8, fr1=3619\n",
      "1934_B8_masked.h5 total 1-d averaging time 461.931534542 seconds\n",
      "DID not PATCH 1934_SN_masked.h5 already exists - did not copy, \n",
      "1-D Averaging is NOT performed as 1934_SN_masked.h5 already exist \n",
      "TO do patching on 1934_SN_masked.h5 delete the file first manually and run this cell again\n",
      "1934_SNa_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "1934_SNa_masked.h5 copy is done\n",
      "1934_SNa_masked.h5 Loading data into a numpy array started \n",
      "1934_SNa_masked.h5 Loading data into a numpy array finished in 86.02877995800009 seconds\n",
      "1934_SNa_masked.h5 Patching Started \n",
      "1934_SNa_masked.h5 Patching Finished\n",
      "1934_SNa_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "1934_SNa_masked.h5 patched pilW2_image dataset creation finished in 115.14621054100007 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=1934_SNa, fr1=0\n",
      "data received: sn=1934_SNa, fr1=620\n",
      "data received: sn=1934_SNa, fr1=1240\n",
      "data received: sn=1934_SNa, fr1=1860\n",
      "data received: sn=1934_SNa, fr1=2480\n",
      "data received: sn=1934_SNa, fr1=3100\n",
      "data received: sn=1934_SNa, fr1=3720\n",
      "data received: sn=1934_SNa, fr1=4340\n",
      "1934_SNa_masked.h5 total 1-d averaging time 748.6320774579999 seconds\n",
      "1943_B1_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "1943_B1_masked.h5 copy is done\n",
      "1943_B1_masked.h5 Loading data into a numpy array started \n",
      "1943_B1_masked.h5 Loading data into a numpy array finished in 58.01090099999965 seconds\n",
      "1943_B1_masked.h5 Patching Started \n",
      "1943_B1_masked.h5 Patching Finished\n",
      "1943_B1_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "1943_B1_masked.h5 patched pilW2_image dataset creation finished in 84.45361483299985 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=1943_B1, fr1=0\n",
      "data received: sn=1943_B1, fr1=465\n",
      "data received: sn=1943_B1, fr1=930\n",
      "data received: sn=1943_B1, fr1=1395\n",
      "data received: sn=1943_B1, fr1=1860\n",
      "data received: sn=1943_B1, fr1=2325\n",
      "data received: sn=1943_B1, fr1=2790\n",
      "data received: sn=1943_B1, fr1=3255\n",
      "1943_B1_masked.h5 total 1-d averaging time 625.8132990409995 seconds\n",
      "1943_B1a_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "1943_B1a_masked.h5 copy is done\n",
      "1943_B1a_masked.h5 Loading data into a numpy array started \n",
      "1943_B1a_masked.h5 Loading data into a numpy array finished in 57.414790249999896 seconds\n",
      "1943_B1a_masked.h5 Patching Started \n",
      "1943_B1a_masked.h5 Patching Finished\n",
      "1943_B1a_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "1943_B1a_masked.h5 patched pilW2_image dataset creation finished in 85.42142420799973 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=1943_B1a, fr1=0\n",
      "data received: sn=1943_B1a, fr1=465\n",
      "data received: sn=1943_B1a, fr1=930\n",
      "data received: sn=1943_B1a, fr1=1395\n",
      "data received: sn=1943_B1a, fr1=1860\n",
      "data received: sn=1943_B1a, fr1=2325\n",
      "data received: sn=1943_B1a, fr1=2790\n",
      "data received: sn=1943_B1a, fr1=3255\n",
      "1943_B1a_masked.h5 total 1-d averaging time 558.3871160829995 seconds\n",
      "2016_B8_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "2016_B8_masked.h5 copy is done\n",
      "2016_B8_masked.h5 Loading data into a numpy array started \n",
      "2016_B8_masked.h5 Loading data into a numpy array finished in 54.66960316699988 seconds\n",
      "2016_B8_masked.h5 Patching Started \n",
      "2016_B8_masked.h5 Patching Finished\n",
      "2016_B8_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "2016_B8_masked.h5 patched pilW2_image dataset creation finished in 82.13355812500049 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=2016_B8, fr1=0\n",
      "data received: sn=2016_B8, fr1=465\n",
      "data received: sn=2016_B8, fr1=930\n",
      "data received: sn=2016_B8, fr1=1395\n",
      "data received: sn=2016_B8, fr1=1860\n",
      "data received: sn=2016_B8, fr1=2325\n",
      "data received: sn=2016_B8, fr1=2790\n",
      "data received: sn=2016_B8, fr1=3255\n",
      "2016_B8_masked.h5 total 1-d averaging time 555.4630613750014 seconds\n",
      "2016_B8a_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "2016_B8a_masked.h5 copy is done\n",
      "2016_B8a_masked.h5 Loading data into a numpy array started \n",
      "2016_B8a_masked.h5 Loading data into a numpy array finished in 56.689507875000345 seconds\n",
      "2016_B8a_masked.h5 Patching Started \n",
      "2016_B8a_masked.h5 Patching Finished\n",
      "2016_B8a_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "2016_B8a_masked.h5 patched pilW2_image dataset creation finished in 79.32993754200106 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=2016_B8a, fr1=0\n",
      "data received: sn=2016_B8a, fr1=465\n",
      "data received: sn=2016_B8a, fr1=930\n",
      "data received: sn=2016_B8a, fr1=1395\n",
      "data received: sn=2016_B8a, fr1=1860\n",
      "data received: sn=2016_B8a, fr1=2325\n",
      "data received: sn=2016_B8a, fr1=2790\n",
      "data received: sn=2016_B8a, fr1=3255\n",
      "2016_B8a_masked.h5 total 1-d averaging time 546.4479217080006 seconds\n",
      "2016_B8b_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "2016_B8b_masked.h5 copy is done\n",
      "2016_B8b_masked.h5 Loading data into a numpy array started \n",
      "2016_B8b_masked.h5 Loading data into a numpy array finished in 55.668586167001195 seconds\n",
      "2016_B8b_masked.h5 Patching Started \n",
      "2016_B8b_masked.h5 Patching Finished\n",
      "2016_B8b_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "2016_B8b_masked.h5 patched pilW2_image dataset creation finished in 78.98257179100074 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=2016_B8b, fr1=0\n",
      "data received: sn=2016_B8b, fr1=465\n",
      "data received: sn=2016_B8b, fr1=930\n",
      "data received: sn=2016_B8b, fr1=1395\n",
      "data received: sn=2016_B8b, fr1=1860\n",
      "data received: sn=2016_B8b, fr1=2325\n",
      "data received: sn=2016_B8b, fr1=2790\n",
      "data received: sn=2016_B8b, fr1=3255\n",
      "2016_B8b_masked.h5 total 1-d averaging time 561.3367208330001 seconds\n",
      "2016_B8c_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "2016_B8c_masked.h5 copy is done\n",
      "2016_B8c_masked.h5 Loading data into a numpy array started \n",
      "2016_B8c_masked.h5 Loading data into a numpy array finished in 11.243966916999852 seconds\n",
      "2016_B8c_masked.h5 Patching Started \n",
      "2016_B8c_masked.h5 Patching Finished\n",
      "2016_B8c_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "2016_B8c_masked.h5 patched pilW2_image dataset creation finished in 24.427414583000427 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=2016_B8c, fr1=0\n",
      "data received: sn=2016_B8c, fr1=160\n",
      "data received: sn=2016_B8c, fr1=320\n",
      "data received: sn=2016_B8c, fr1=480\n",
      "data received: sn=2016_B8c, fr1=640\n",
      "data received: sn=2016_B8c, fr1=800\n",
      "data received: sn=2016_B8c, fr1=960\n",
      "data received: sn=2016_B8c, fr1=1120\n",
      "2016_B8c_masked.h5 total 1-d averaging time 149.06409229200108 seconds\n",
      "2047_B1_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "2047_B1_masked.h5 copy is done\n",
      "2047_B1_masked.h5 Loading data into a numpy array started \n",
      "2047_B1_masked.h5 Loading data into a numpy array finished in 76.93876420800007 seconds\n",
      "2047_B1_masked.h5 Patching Started \n",
      "2047_B1_masked.h5 Patching Finished\n",
      "2047_B1_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "2047_B1_masked.h5 patched pilW2_image dataset creation finished in 115.99929129200063 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=2047_B1, fr1=0\n",
      "data received: sn=2047_B1, fr1=620\n",
      "data received: sn=2047_B1, fr1=1240\n",
      "data received: sn=2047_B1, fr1=1860\n",
      "data received: sn=2047_B1, fr1=2480\n",
      "data received: sn=2047_B1, fr1=3100\n",
      "data received: sn=2047_B1, fr1=3720\n",
      "data received: sn=2047_B1, fr1=4340\n",
      "2047_B1_masked.h5 total 1-d averaging time 895.1585223330003 seconds\n",
      "2047_B1a_masked.h5 is being created in /Users/bashit.a/Documents/Alzheimer/Dec-15 ...\n",
      "2047_B1a_masked.h5 copy is done\n",
      "2047_B1a_masked.h5 Loading data into a numpy array started \n",
      "2047_B1a_masked.h5 Loading data into a numpy array finished in 90.5852302910007 seconds\n",
      "2047_B1a_masked.h5 Patching Started \n",
      "2047_B1a_masked.h5 Patching Finished\n",
      "2047_B1a_masked.h5 patched pilW2_image dataset creation staring ... \n",
      "2047_B1a_masked.h5 patched pilW2_image dataset creation finished in 137.5599122499989 seconds\n",
      "Circular averaging starts now ... \n",
      "data received: sn=2047_B1a, fr1=0\n",
      "data received: sn=2047_B1a, fr1=722\n",
      "data received: sn=2047_B1a, fr1=1444\n",
      "data received: sn=2047_B1a, fr1=2166\n",
      "data received: sn=2047_B1a, fr1=2888\n",
      "data received: sn=2047_B1a, fr1=3610\n",
      "data received: sn=2047_B1a, fr1=4332\n",
      "data received: sn=2047_B1a, fr1=5054\n",
      "2047_B1a_masked.h5 total 1-d averaging time 1061.761105042 seconds\n",
      "DID not PATCH 2048_B16_masked.h5 already exists - did not copy, \n",
      "1-D Averaging is NOT performed as 2048_B16_masked.h5 already exist \n",
      "TO do patching on 2048_B16_masked.h5 delete the file first manually and run this cell again\n",
      "DID not PATCH 2048_B16a_masked.h5 already exists - did not copy, \n",
      "1-D Averaging is NOT performed as 2048_B16a_masked.h5 already exist \n",
      "TO do patching on 2048_B16a_masked.h5 delete the file first manually and run this cell again\n",
      "DID not PATCH 2048_B16b_masked.h5 already exists - did not copy, \n",
      "1-D Averaging is NOT performed as 2048_B16b_masked.h5 already exist \n",
      "TO do patching on 2048_B16b_masked.h5 delete the file first manually and run this cell again\n",
      "DID not PATCH 2048_B6_masked.h5 already exists - did not copy, \n",
      "1-D Averaging is NOT performed as 2048_B6_masked.h5 already exist \n",
      "TO do patching on 2048_B6_masked.h5 delete the file first manually and run this cell again\n",
      "DID not PATCH 2048_B8_masked.h5 already exists - did not copy, \n",
      "1-D Averaging is NOT performed as 2048_B8_masked.h5 already exist \n",
      "TO do patching on 2048_B8_masked.h5 delete the file first manually and run this cell again\n",
      "Successfully created (source file, masked file) \n",
      "\n",
      "\n",
      "1934_B8.h5 ---> 1934_B8_masked.h5\n",
      "1934_SN.h5 ---> None\n",
      "1934_SNa.h5 ---> 1934_SNa_masked.h5\n",
      "1943_B1.h5 ---> 1943_B1_masked.h5\n",
      "1943_B1a.h5 ---> 1943_B1a_masked.h5\n",
      "2016_B8.h5 ---> 2016_B8_masked.h5\n",
      "2016_B8a.h5 ---> 2016_B8a_masked.h5\n",
      "2016_B8b.h5 ---> 2016_B8b_masked.h5\n",
      "2016_B8c.h5 ---> 2016_B8c_masked.h5\n",
      "2047_B1.h5 ---> 2047_B1_masked.h5\n",
      "2047_B1a.h5 ---> 2047_B1a_masked.h5\n",
      "2048_B16.h5 ---> None\n",
      "2048_B16a.h5 ---> None\n",
      "2048_B16b.h5 ---> None\n",
      "2048_B6.h5 ---> None\n",
      "2048_B8.h5 ---> None\n"
     ]
    }
   ],
   "source": [
    "# 1-d averaging after patches for ALL files in the current directory   (Independent Cell)\n",
    "\n",
    "data = get_json_str_data(\"config-dec-15.json\")\n",
    "### do masking and 1-d averaging (Lin Yang's code by BNL used here for 1-d averaging)\n",
    "files = []\n",
    "for file in data['files']:\n",
    "    source_file , patches = file['name'], file['patches']\n",
    "    try: masked_file = circ_avg_from_patches(source_file, qgrid2, patches)\n",
    "    except: continue\n",
    "    files.append((source_file, masked_file))\n",
    "\n",
    "print(f'Successfully created (source file, masked file) \\n\\n')\n",
    "[print(s, '--->' ,t) for s,t in files]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "under-opening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da21adbb15e14d5ba14596c37e452740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecca04b52c84668b741351d29f75732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Frame', max=4940), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 1d circularly averaged data for masked file \n",
    "%matplotlib widget\n",
    "import ipywidgets   # from IPython.display import display; display(amp)\n",
    "\n",
    "# specs \n",
    "source_file = \"2048_B8.h5\"          # None to avoid plotting\n",
    "masked_file = \"2048_B8_masked.h5\"   # None to avoid plotting\n",
    "scattering = '_WAXS2'\n",
    "\n",
    "# semi-specs\n",
    "file = masked_file \n",
    "\n",
    "# computation\n",
    "if source_file is not None:\n",
    "    Iq_S = read_Iq(source_file, scattering)     \n",
    "if masked_file is not None:\n",
    "    Iq_M = read_Iq(masked_file, scattering)     \n",
    "    \n",
    "Width, Height = width_height(file)    # considering the fact that width and height is same for source and masked file\n",
    "n_patterns = Width*Height \n",
    "\n",
    "f,ax = plt.subplots()\n",
    "def update_plot(frame):\n",
    "    ax.clear()\n",
    "    ax.set_yscale('log')\n",
    "    if source_file is not None:\n",
    "        ax.plot(qgrid2, Iq_S[frame], label = f'Source - {frame}')\n",
    "    if masked_file is not None:\n",
    "        ax.plot(qgrid2, Iq_M[frame], label = f'Masked - {frame}')\n",
    "    ax.legend()\n",
    "\n",
    "frame = ipywidgets.IntSlider(min=0, max=n_patterns-1, value=0, description = \"Frame\")\n",
    "ipywidgets.interactive(update_plot, frame=frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pediatric-madness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6263121f9294c7da7e3781c82f63907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low valid idx = 2, low valid Q = 0.007, high valid idx = 124 , high valid Q = 0.370\n",
      "low valid idx = 109, low valid Q = 0.295, high valid idx = 578 , high valid Q = 2.640\n",
      "Task Finished. Figure Number =  1\n"
     ]
    }
   ],
   "source": [
    "### show heat map for any file\n",
    "%matplotlib widget\n",
    "\n",
    "file = '2048_B8_masked.h5'\n",
    "#file = masked_file    \n",
    "scatterings = ('_SAXS', '_WAXS2')\n",
    "\n",
    "#plot_one_heat_maps(file, scatterings)\n",
    "f = plot_heat_map_from_file(file, qgrid2, scatterings = scatterings)\n",
    "print('Task Finished. Figure Number = ' , f.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "agreed-criminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e350326032fa449d9a1290e1cacc6043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='File : ', options=('2048_B8.h5', '2048_B8_masked.h5', 'exp.h5'), v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function essential_func.file_polyfit_heatmap_plot(file, indices, qgrid2)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# --------- Find Q range to plot heat maps --------- #################\n",
    "%matplotlib widget\n",
    "import ipywidgets         # from IPython.display import display; display(amp)\n",
    "from ipywidgets import fixed\n",
    "\n",
    "# semi-specs\n",
    "qgrid2 = np.hstack([np.arange(0.005, 0.0499, 0.001), np.arange(0.05, 0.099, 0.002), np.arange(0.1, 3.2, 0.005)])\n",
    "\n",
    "### q_low, q_high, q_low - idx[2] and q_high + idx[2] for poly fit, number of points\n",
    "indices = ((0.115, 0.16, 13,   48, '_SAXS' , 'bumpy'),      # 72, 81\n",
    "           (1.48,  1.57, 10, 4.15, '_WAXS2', 'paraffin'),   # 345, 355\n",
    "           (1.30,  1.38, 10,  4.7, '_WAXS2', 'amyloid'),    # 309, 323\n",
    "           (1.89,  1.93,  7,  3.2, '_WAXS2', 'mica')        # 427, 433\n",
    "          )\n",
    "\n",
    "## polyhit with heatmap from drop down list\n",
    "files = cwd_files_search_with('.h5')\n",
    "dropdown = ipywidgets.Dropdown(options=files, value = files[0],description='File : ', disabled=False)\n",
    "ipywidgets.interact(file_polyfit_heatmap_plot, file = dropdown, indices = fixed(indices), qgrid2 = fixed(qgrid2))\n",
    "\n",
    "## polyhit with heatmap for one file\n",
    "# file = '2048_B8.h5'\n",
    "# file_polyfit_heatmap_plot(file, indices, qgrid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "encouraging-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location /Users/bashit.a/Documents/Alzheimer/Dec-15\n",
      "Changing to /Users/bashit.a/Documents/Alzheimer/Dec-15//PDF directory \n",
      "result.pdf file written successfully\n",
      "Back to root directory  /Users/bashit.a/Documents/Alzheimer/Dec-15\n"
     ]
    }
   ],
   "source": [
    "### Merge all PDFs in the directory specified\n",
    "### you can put all your pdfs that you want to merge to the PDF folder\n",
    "from essential_func import *\n",
    "pdfs_merging(directory = '/PDF', output = 'result.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "diagnostic-doubt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bashit.a/Documents/Alzheimer/Mar-24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bee5950fe24eebaceb75baaaa0a4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low valid idx = 2, low valid Q = 0.007, high valid idx = 124 , high valid Q = 0.370\n",
      "low valid idx = 109, low valid Q = 0.295, high valid idx = 578 , high valid Q = 2.640\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7afb352a13468ea73ffe21ed581821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor, 45131.328/45333.208 = 0.9955467523939625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e929f4e5eb4d7e9bfabe1213556914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.         527.69596259 355.4387128  240.5995019  169.68693625\n",
      " 123.96353014  93.57119693  72.89987768  56.8460686 ]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from essential_func import *\n",
    "from py4xs.hdf import h5xs\n",
    "from py4xs.slnxs import trans_mode\n",
    "\n",
    "print(f'{os.getcwd()}')\n",
    "\n",
    "# specs\n",
    "# file = '1934_SN_masked.h5'  \n",
    "# frames = (4518, 3687, 3045)     # amyloid, mica, dark  ---> frames can be choosen from SAXS heat map\n",
    "\n",
    "file = '2048_B8_masked.h5'\n",
    "frames = (2080, 1358, 2223, )     # amyloid, mica, dark\n",
    "show_eb = False                  # show errorbar in the plot\n",
    "\n",
    "## semi-spec\n",
    "qgrid2 = np.hstack([np.arange(0.005, 0.0499, 0.001), np.arange(0.05, 0.099, 0.002), np.arange(0.1, 3.2, 0.005)])\n",
    "\n",
    "# creating objects\n",
    "dt  = h5xs(f'{file}', transField=\"em2_sum_all_mean_value\")\n",
    "sn = h5_top_group(file)\n",
    "dt.load_d1s(sn=sn)\n",
    "\n",
    "## heat map from file\n",
    "scatterings = ('_SAXS', '_WAXS2')\n",
    "f = plot_heat_map_from_file(file, qgrid2, scatterings = scatterings)\n",
    "\n",
    "### 1-d plot for bright, moderate and dark frames\n",
    "scatterings = ('_SAXS',          '_WAXS2',        'merged',    )\n",
    "colors =      (('r','b','g'), ('r','b','g'), ('r+','bo','g--'),)\n",
    "f, axs = plt.subplots(1, 3, figsize=(15,5), num=f'{file}')\n",
    "xscale = 'linear'\n",
    "yscale = 'log'\n",
    "\n",
    "for i, (scattering, color) in enumerate(zip(scatterings,colors)):\n",
    "    axs[i].plot(dt.qgrid, dt.d1s[sn][scattering][frames[0]].data, color[0], label = f'bright {frames[0]}')\n",
    "    axs[i].plot(dt.qgrid, dt.d1s[sn][scattering][frames[1]].data, color[1], label = f'moderate {frames[1]}')\n",
    "    axs[i].plot(dt.qgrid, dt.d1s[sn][scattering][frames[2]].data, color[2], label = f'dark {frames[2]}')\n",
    "    axs[i].set(title = f'{scattering} {file}', xscale= xscale, yscale= yscale)\n",
    "    axs[i].legend()\n",
    "\n",
    "## background correction calculations\n",
    "sc_factor=1.\n",
    "\n",
    "dset = dt.d1s[sn][scattering][frames[0]]\n",
    "dbak = dt.d1s[sn][scattering][frames[2]]\n",
    "\n",
    "dt.set_trans(transMode=trans_mode.external)\n",
    "sc  = dset.trans / dbak.trans\n",
    "print(f'Scaling factor, {dset.trans}/{dbak.trans} = {sc}')\n",
    "Iq  = dset.data - dbak.data * sc * sc_factor\n",
    "dI  = dset.err  + dbak.err * sc * sc_factor\n",
    "idx = (dset.data > 0) & (dbak.data > 0)\n",
    "\n",
    "## plotting settings\n",
    "f, axs = plt.subplots(1,2,figsize=(16,4))\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "axs[0].plot(dbak.qgrid[idx], dset.data[idx], color[0], label = f'bright {frames[0]}')\n",
    "axs[0].plot(dbak.qgrid[idx], dbak.data[idx], color[2], label = f'dark-bcg {frames[2]}')\n",
    "\n",
    "if show_eb:\n",
    "    axs[0].errorbar(dbak.qgrid[idx], Iq[idx], dI[idx])\n",
    "    axs[1].errorbar(dbak.qgrid[idx], Iq[idx], dI[idx], label = f'{frames[0]} bcor')\n",
    "else:\n",
    "    axs[0].plot(dbak.qgrid[idx], Iq[idx], label = 'bcor')\n",
    "    axs[1].plot(dbak.qgrid[idx], Iq[idx], label = f'{frames[0]} bcor')\n",
    "\n",
    "\n",
    "axs[0].set(xlabel = \"$q (\\AA^{-1})$\", ylabel = \"$I$\", title = f'Background correction {file} errorbar = {show_eb}', xscale = xscale, yscale = yscale, )\n",
    "axs[1].set(xscale = xscale, yscale = yscale, title = f'Final Background Subtracted {file} errorbar = {show_eb}' , )\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "print(Iq[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "divided-communist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 2, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### learn this part of the code\n",
    "def flatten(x):\n",
    "    \"\"\"\n",
    "    l = [2,[[1,2]],1]\n",
    "    list(flatten(l))\n",
    "    \"\"\"\n",
    "    for item in x:\n",
    "        if type(item) in [list]:\n",
    "            for num in flatten(item):\n",
    "                yield(num)\n",
    "        else:\n",
    "            yield(item)\n",
    "\n",
    "flatten=lambda l: sum(map(flatten,l),[]) if isinstance(l,list) else [l]\n",
    "l = [2,[[1,2]],1]\n",
    "flatten(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dedicated-pocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285667cedb04407ebab1ca1fd55c0442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0b0f18aa524988b4dc97cd650282f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Cursor:\n",
    "    def __init__(self, ax):\n",
    "        self.ax = ax\n",
    "        self.lx = ax.axhline(color='k')  # the horiz line\n",
    "        self.ly = ax.axvline(color='k')  # the vert line\n",
    "\n",
    "        # text location in axes coords\n",
    "        self.txt = ax.text(0.7, 0.9, '', transform=ax.transAxes)\n",
    "\n",
    "    def mouse_move(self, event):\n",
    "        if not event.inaxes:\n",
    "            return\n",
    "\n",
    "        x, y = event.xdata, event.ydata\n",
    "        # update the line positions\n",
    "        self.lx.set_ydata(y)\n",
    "        self.ly.set_xdata(x)\n",
    "\n",
    "        self.txt.set_text('x=%1.2f, y=%1.2f' % (x, y))\n",
    "        self.ax.figure.canvas.draw()\n",
    "\n",
    "\n",
    "class SnaptoCursor:\n",
    "    \"\"\"\n",
    "    Like Cursor but the crosshair snaps to the nearest x, y point.\n",
    "    For simplicity, this assumes that *x* is sorted.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ax, x, y):\n",
    "        self.ax = ax\n",
    "        self.lx = ax.axhline(color='k')  # the horiz line\n",
    "        self.ly = ax.axvline(color='k')  # the vert line\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        # text location in axes coords\n",
    "        self.txt = ax.text(0.7, 0.9, '', transform=ax.transAxes)\n",
    "\n",
    "    def mouse_move(self, event):\n",
    "        if not event.inaxes:\n",
    "            return\n",
    "\n",
    "        x, y = event.xdata, event.ydata\n",
    "        indx = min(np.searchsorted(self.x, x), len(self.x) - 1)\n",
    "        x = self.x[indx]\n",
    "        y = self.y[indx]\n",
    "        # update the line positions\n",
    "        self.lx.set_ydata(y)\n",
    "        self.ly.set_xdata(x)\n",
    "\n",
    "        self.txt.set_text('x=%1.2f, y=%1.2f' % (x, y))\n",
    "        print('x=%1.2f, y=%1.2f' % (x, y))\n",
    "        self.ax.figure.canvas.draw()\n",
    "\n",
    "\n",
    "t = np.arange(0.0, 1.0, 0.01)\n",
    "s = np.sin(2 * 2 * np.pi * t)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, s, 'o')\n",
    "cursor = Cursor(ax)\n",
    "fig.canvas.mpl_connect('motion_notify_event', cursor.mouse_move)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, s, 'o')\n",
    "snap_cursor = SnaptoCursor(ax, t, s)\n",
    "fig.canvas.mpl_connect('motion_notify_event', snap_cursor.mouse_move)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "danish-startup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cd8c4234ea4e0785498f37f661bb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width    species\n",
      "0             5.1          3.5           1.4          0.2     setosa\n",
      "1             4.9          3.0           1.4          0.2     setosa\n",
      "2             4.7          3.2           1.3          0.2     setosa\n",
      "3             4.6          3.1           1.5          0.2     setosa\n",
      "4             5.0          3.6           1.4          0.2     setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  virginica\n",
      "146           6.3          2.5           5.0          1.9  virginica\n",
      "147           6.5          3.0           5.2          2.0  virginica\n",
      "148           6.2          3.4           5.4          2.3  virginica\n",
      "149           5.9          3.0           5.1          1.8  virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e920e41414a464281a214213924be46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x126fb50a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('iris')\n",
    "sns.pairplot(df,kind='reg',) #markers=[\"o\",\"s\",\"D\"])\n",
    "plt.show()\n",
    "print(df)\n",
    "plt.figure()\n",
    "plt.scatter(df['sepal_width'], df['sepal_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dried-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235568e0d11641dc9c85547e9e2dea23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff_patt_idx_before snaking: \n",
      " [[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]] \n",
      "\n",
      " Diff_patt_before snaking: \n",
      " [[13 14  7  3  3  4]\n",
      " [18  5 11 19 12  9]\n",
      " [ 6 12  4  6 17 10]] \n",
      "\n",
      " X,Y coordinates_after_snaking: \n",
      " [[12 13 14 15 16 17]\n",
      " [11 10  9  8  7  6]\n",
      " [ 0  1  2  3  4  5]] \n",
      "\n",
      " Diff_patt_after snaking: \n",
      " [[ 6 12  4  6 17 10]\n",
      " [ 9 12 19 11  5 18]\n",
      " [13 14  7  3  3  4]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### -------- py4xs version --------\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "Height = 3\n",
    "Width = 6\n",
    "X = np.random.randint(1, 20, size=(Height, Width))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X, interpolation = 'none', origin='upper', extent=[0,Width,0,Height],aspect='equal')\n",
    "\n",
    "def snaking( Width, Height, X=None,):\n",
    "    if X is None:\n",
    "        X_coor = np.arange(Height*Width).reshape(Height,Width)\n",
    "    else:\n",
    "        X_coor = X\n",
    "    output = np.zeros_like(X_coor)           # \n",
    "    temp = np.flipud(X_coor)                # flipud matrix\n",
    "    idx_odd = np.arange(1,Height,2)                # Get odd indices to fliplr\n",
    "    output[idx_odd,:]  = np.fliplr(temp[idx_odd])   # flipping odd indices\n",
    "    idx_even = np.arange(0,Height,2)               # Get odd indices to leave to as it is\n",
    "    output[idx_even,:] = temp[idx_even]             # leaving as it is\n",
    "    return output\n",
    "\n",
    "frame_cor = snaking(Width, Height)\n",
    "diff_patterns = snaking(Width, Height, X)\n",
    "\n",
    "print('Diff_patt_idx_before snaking: \\n', np.arange(Height*Width).reshape(Height,Width), '\\n\\n',\n",
    "      'Diff_patt_before snaking: \\n', X, '\\n\\n', \n",
    "      'X,Y coordinates_after_snaking: \\n', frame_cor, '\\n\\n',\n",
    "      'Diff_patt_after snaking: \\n', diff_patterns, '\\n\\n',)\n",
    "\n",
    "numrows, numcols = X.shape\n",
    "def format_coord(x, y):\n",
    "    col = int(x)\n",
    "    row = int(y)\n",
    "    if 0 <= col < numcols and 0 <= row < numrows:\n",
    "        z = np.flipud(frame_cor)[row, col]\n",
    "        return 'x=%1.4f, y=%1.4f, FRAME=%d' % (x, y, z)\n",
    "    else:\n",
    "        return 'x=%1.4f, y=%1.4f' % (x, y)\n",
    "\n",
    "ax.format_coord = format_coord\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "proved-invitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45131.328\n",
      "45639.848\n"
     ]
    }
   ],
   "source": [
    "### Finding Radius of gyration\n",
    "from py4xs.hdf import h5xs,h5exp,lsh5,proc_d1merge\n",
    "from py4xs.data2d import Data2d\n",
    "from py4xs.slnxs import trans_mode\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import warnings,json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dt0  = h5xs(\"mica.h5\", transField=\"em2_sum_all_mean_value\")\n",
    "dt  = h5xs(\"2048_B8.h5\", transField=\"em2_sum_all_mean_value\")\n",
    "\n",
    "dt.load_d1s()\n",
    "dt0.load_d1s()\n",
    "\n",
    "dt.set_trans(transMode=trans_mode.external)\n",
    "dt0.set_trans(transMode=trans_mode.external)\n",
    "\n",
    "print(dt.d1s['2048_B8']['merged'][2080].trans)\n",
    "print(dt0.d1s['mica']['merged'][10].trans)\n",
    "#print(dt.d1s['2048_B8']['merged'][2080].overlaps)\n",
    "#dt0.d1s['mica']['merged'][10].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eleven-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = np.vstack((dt.qgrid, dt.d1s['2048_B8']['merged'][2080].data))\n",
    "qs = 0.007\n",
    "qe = 10\n",
    "rg = 15\n",
    "# td = td[:, td[0, :] >= qs]     # find td for  greater than q=0.007\n",
    "# td = td[:, td[0, :] <= qe]     # find td for smaller than q=1.3/1.5=0.086\n",
    "# td[0, :] = td[0, :] * td[0, :]\n",
    "# td[1, :] = np.log(td[1, :])\n",
    "# rg, i0 = np.polyfit(td[0, :], td[1, :], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sustainable-newport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.08666666666666667 -831.264016704801 20.377926211495332\n",
      "1 0.026032341584365102 -6234.912831830037 281.9576616244667\n",
      "2 0.026032341584365102 -6234.912831830037 281.9576616244667\n",
      "3 0.026032341584365102 -6234.912831830037 281.9576616244667\n",
      "4 0.026032341584365102 -6234.912831830037 281.9576616244667\n",
      "5 0.026032341584365102 -6234.912831830037 281.9576616244667\n",
      "6 0.026032341584365102 -6234.912831830037 281.9576616244667\n",
      "7 0.026032341584365102 -6234.912831830037 281.9576616244667\n",
      "8 0.026032341584365102 -6234.912831830037 281.9576616244667\n",
      "9 0.026032341584365102 -6234.912831830037 281.9576616244667\n",
      "136.76526786977064\n"
     ]
    }
   ],
   "source": [
    "from numpy.polynomial import polynomial as P\n",
    "cnt = 0\n",
    "while cnt < 10:\n",
    "    if qe > 1.3/rg and 1.3/rg > qs+0.004: \n",
    "        qe = 1.3/rg\n",
    "    td = np.vstack((dt.qgrid, dt.d1s['2048_B8']['merged'][2080].data))\n",
    "    td = td[:, td[0, :] >= qs]     # find td for  greater than q=0.007\n",
    "    td = td[:, td[0, :] <= qe]     # find td for smaller than q=1.3/1.5=0.086\n",
    "    td[0, :] = td[0, :] * td[0, :]\n",
    "    td[1, :] = np.log(td[1, :])\n",
    "    rg, i0 = np.polyfit(td[0, :], td[1, :], 1)\n",
    "    i0 = np.exp(i0)\n",
    "    \n",
    "    print(cnt, qe, rg, i0)\n",
    "    \n",
    "    if rg<0:\n",
    "        rg = np.sqrt(-rg * 3.)\n",
    "    else:\n",
    "        rg = 1e-6   # \n",
    "        print(\"likely strong inter-particle interaction ...\")\n",
    "        break\n",
    "    cnt += 1\n",
    "print(rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "suffering-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "qmax = 5;\n",
    "dmax=200.;\n",
    "\n",
    "if dt.qgrid[-1] < qmax: \n",
    "    qmax = dt.qgrid[-1]\n",
    "\n",
    "tqgrid = np.arange(0, qmax, qmax / len(dt.qgrid))\n",
    "tint = np.interp(tqgrid, dt.qgrid, dt.d1s['2048_B8']['merged'][2080].data)\n",
    "print(tint.shape)\n",
    "tint[tqgrid * rg < 1.] = i0 * np.exp(-(tqgrid[tqgrid * rg < 1.] * rg) ** 2 / 3.)\n",
    "#print(tint)\n",
    "\n",
    "# tint -= tint[-10:].sum()/10\n",
    "# Hanning window for reducing fringes in p(r)\n",
    "tw = np.hanning(2 * len(tqgrid) + 1)[len(tqgrid):-1]\n",
    "\n",
    "# plotting hanning window\n",
    "tmp = np.hanning(2 * len(tqgrid) + 1)\n",
    "#plt.plot(np.arange(0,len(tint[tqgrid * rg < 1.])), tint[tqgrid * rg < 1.])\n",
    "#plt.yscale('log')\n",
    "tint *= tw\n",
    "#plt.show()\n",
    "\n",
    "trgrid = np.arange(0, dmax, 1.)\n",
    "kern = np.asmatrix([[rj ** 2 * np.sinc(qi * rj / np.pi) for rj in trgrid] for qi in tqgrid])\n",
    "tt = np.asmatrix(tint * tqgrid ** 2).T\n",
    "tpr = np.reshape(np.array((kern.T * tt).T), len(trgrid))\n",
    "tpr /= tpr.sum()\n",
    "print(tpr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "literary-affiliate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00463043, 0.00926087, 0.0138913 , 0.01852174,\n",
       "       0.02315217, 0.02778261, 0.03241304, 0.03704348, 0.04167391])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqgrid = np.arange(0, qmax, qmax / len(dt.qgrid))\n",
    "tint = np.interp(tqgrid, dt.qgrid, dt.d1s['2048_B8']['merged'][2080].data)\n",
    "tqgrid[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
