{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confirmed-wealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python directory is set to load samples from : July-sorted\n"
     ]
    }
   ],
   "source": [
    "#### load packages, *.h5 folder and exp.h5 file location\n",
    "%matplotlib widget\n",
    "\n",
    "from essential_func import *\n",
    "from analysis_data import *\n",
    "\n",
    "qgrid2 = np.hstack([np.arange(0.005, 0.0499, 0.001), np.arange(0.05, 0.099, 0.002), np.arange(0.1, 3.2, 0.005)])\n",
    "\n",
    "default_sample_dir = 'July-sorted' #'July-sorted'  # '20-Dec' # 'July-2021-Sample#6'\n",
    "csv_and_code_abs_directory = '/Users/bashit.a/Documents/Alzheimer/Codes/'\n",
    "samples_csv = 'data_directory.csv'\n",
    "\n",
    "dropdown_name_list, cwd, exp_folder = change_python_path(dropdown_name = default_sample_dir, csv_file_location = csv_and_code_abs_directory, samples_csv = samples_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extraordinary-carter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bashit.a/miniforge3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/bashit.a/miniforge3/envs/py38/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cd141122d04d32ac1ce81fcef7e181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bashit.a/Documents/Alzheimer/Codes/analysis_data.py:336: RuntimeWarning: divide by zero encountered in log\n",
      "  axs[0,1].plot(self.qgrid, np.log(self.IqBS[self.input_fr,:].flatten()))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Data_Analysis' object has no attribute 'scaling_for'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2e03432ce0ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                     \u001b[0mseek_mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseek_mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmf_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmf_max\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                     window_size=window_size, show_result=False);\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_minQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_maxQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m### kernal sliding and getting background frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Alzheimer/Codes/analysis_data.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, ax, plot_minQ, plot_maxQ)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;31m# saxs_diff_image(self.file, self.input_fr, f=f, ax=axs[1,1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         ax.plot(self.qgrid[idx_start:idx_end], self.scaling_for[idx_start:idx_end] - self.mf*self.scaling_by[idx_start:idx_end], \\\n\u001b[0m\u001b[1;32m    345\u001b[0m             label='Fr(' + str(self.input_fr) + ') - Fr(' + str(self.bkg_frame) + \") - \" + str(round(self.mf,2)) + \"*(\" + 'Fr(' +str(self.tissue_fr) + ') - Fr(' + str(self.bkg_frame) + \"))\")\n\u001b[1;32m    346\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling_for\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m            \u001b[0;34m'Fr('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fr\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m') - Fr('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbkg_frame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Data_Analysis' object has no attribute 'scaling_for'"
     ]
    }
   ],
   "source": [
    "### background subtraction\n",
    "%matplotlib widget\n",
    "\n",
    "file = '2029_Dentate_gyrus-roi0_masked.h5'\n",
    "QSearchStart, QSearchEnd = 1.55, 1.8        # scaling regions 295,310 or may be 290,370\n",
    "frame = 6430 #7048                          # amyloid frame    2428, 3101, 3923, 2190,  691, 1134, 458\n",
    "tissue_frames = [6296,]                      # tissue frame, \n",
    "bkg_frame = [6000, 6001, 6002, 6003 ] # 973               # background frame\n",
    "seek_mf = (-12,12,0.01)        #gray          # mf goes from -8 to +8 by 0.01\n",
    "window_size = 5                             # window size for moving average filter\n",
    "kernal_size = 7;\n",
    "area_minQ = 1.0\n",
    "area_maxQ = 1.45\n",
    "mf_max = 2.5           #  mf must be less than this value\n",
    "mf_min = 1.0           #  mf must be greater than this value\n",
    "\n",
    "#\t[6280, 6320, 6154]\n",
    "### Tissue scaled background subtraction\n",
    "data = Data_Analysis(file, qgrid2, directory=os.getcwd())\n",
    "Iq   = data.bkg_sub(bkg_frame = bkg_frame)\n",
    "mf, area, _ , _ = data.tissue_sub(frame, tissue_frames, scale_method = 'MSE', return_alg = 'one_tissue-fr' , \\\n",
    "                                                    area_minQ= area_minQ, area_maxQ = area_maxQ, mf_Qindices = (QSearchStart, QSearchEnd), \\\n",
    "                                                    seek_mf = seek_mf, mf_min=mf_min, mf_max=mf_max , \\\n",
    "                                                    window_size=window_size, show_result=False);\n",
    "data.plot(plot_minQ=0.5, plot_maxQ=3)\n",
    "\n",
    "### kernal sliding and getting background frames\n",
    "Width, Height = width_height(file)\n",
    "fr_idx = Snaking_frames_search(Width, Height)\n",
    "tissue_frames = np.array(fr_idx.frame_idx_to_kernal_frames(kernal_size, frame))\n",
    "print('kernal tissue frames - ',tissue_frames)\n",
    "\n",
    "length = len(tissue_frames)\n",
    "mf = {}; area = {'value':np.zeros(length)}\n",
    "for i,tissue_frame in enumerate(tissue_frames):\n",
    "    mf[i], area['value'][i],_,_ = data.tissue_sub(frame, tissue_frames, scale_method = 'MSE', return_alg = 'one_tissue-fr' , \\\n",
    "                                                    area_minQ= area_minQ, area_maxQ = area_maxQ, mf_Qindices = (QSearchStart, QSearchEnd), \\\n",
    "                                                    seek_mf = seek_mf, mf_min=mf_min, mf_max=mf_max , \\\n",
    "                                                    window_size=window_size, show_result=False);\n",
    "\n",
    "print('descending order tissue frames')\n",
    "tissue_frames_sorted = tissue_frames[np.argsort(area['value'],axis= None, kind='stable')[::-1] ] # descending order\n",
    "print(tissue_frames_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funky-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load all frames mf, and area data\n",
    "\n",
    "sc_data = {}; sc_data['mf'] = np.zeros(data.n_patterns); sc_data['area'] = np.zeros(data.n_patterns)\n",
    "for frame in range(data.n_patterns):\n",
    "    sc_data['mf'][frame] , sc_data['area'][frame]   =  data.scaling_frame(frame, tissue_frames_sorted[0], mf_Qindices = (QSearchStart, QSearchEnd), seek_mf = seek_mf, window_size=window_size, show_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "listed-beaver",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d1fece59094d3a97d5328933e228f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fr- 2264 value:  0.00052844\n",
      "Fr- 6548 value:  0.00049938\n",
      "Fr- 677 value:  0.00049892\n",
      "Fr- 6547 value:  0.0004633\n",
      "Fr- 6556 value:  0.00042698\n",
      "Fr- 6430 value:  0.0004251\n",
      "Fr- 6546 value:  0.00040213\n",
      "Fr- 2953 value:  0.00040124\n",
      "Fr- 6555 value:  0.00038972\n",
      "Fr- 6421 value:  0.0003875\n",
      "Fr- 6672 value:  0.00038701\n",
      "Fr- 1641 value:  0.0003768\n",
      "Fr- 2002 value:  0.00037513\n",
      "Fr- 6422 value:  0.00037433\n",
      "Fr- 6429 value:  0.0003711\n",
      "Fr- 1862 value:  0.0003566\n",
      "Fr- 1759 value:  0.00035455\n",
      "Fr- 6682 value:  0.00034807\n",
      "Fr- 7309 value:  0.00034662\n",
      "Fr- 6673 value:  0.00034253\n",
      "Fr- 1760 value:  0.0003405\n",
      "Fr- 3145 value:  0.00033697\n",
      "Fr- 2381 value:  0.00033518\n",
      "Fr- 7310 value:  0.00033406\n",
      "Fr- 6431 value:  0.00033243\n",
      "Fr- 5805 value:  0.00033181\n",
      "Fr- 3646 value:  0.00032153\n",
      "Fr- 6174 value:  0.00031985\n",
      "Fr- 6173 value:  0.00031618\n",
      "Fr- 6308 value:  0.00031284\n",
      "Fr- 7556 value:  0.00031103\n",
      "Fr- 493 value:  0.00030781\n",
      "Fr- 122 value:  0.00030748\n",
      "Fr- 4405 value:  0.00030705\n",
      "Fr- 5534 value:  0.00030697\n",
      "Fr- 2744 value:  0.00030659\n",
      "Fr- 7308 value:  0.00030641\n",
      "Fr- 514 value:  0.00030601\n",
      "Fr- 7431 value:  0.0003053\n",
      "Fr- 7432 value:  0.00030509\n",
      "Fr- 5915 value:  0.00030501\n",
      "Fr- 1272 value:  0.00030388\n",
      "Fr- 755 value:  0.00030377\n",
      "Fr- 5912 value:  0.00030306\n",
      "Fr- 2281 value:  0.0003024\n",
      "Fr- 1398 value:  0.00030144\n",
      "Fr- 1275 value:  0.0003005\n",
      "Fr- 8 value:  0.00029861\n",
      "Fr- 2526 value:  0.00029792\n",
      "Fr- 2514 value:  0.00029709\n"
     ]
    }
   ],
   "source": [
    "### Draw heat map depending on background subtracted descending area \n",
    "%matplotlib widget\n",
    "\n",
    "file = file\n",
    "sort_by = sc_data['area']\n",
    "\n",
    "sorted_idx  = np.argsort(sort_by, kind='stable')[::-1][:50] # sc_data['area'].shape = (4941,)  # first 50 area sorted descending\n",
    "\n",
    "diff_patterns = np.zeros(len(sort_by))\n",
    "diff_patterns[sorted_idx] = sort_by[sorted_idx]\n",
    "Width, Height = width_height(file)\n",
    "img_orig = snaking(Width, Height, diff_patterns)\n",
    "\n",
    "f,ax = plt.subplots()\n",
    "plot_heat_map_from_data(img_orig, Width, Height, args = (f, ax), title= f'Heat Map {file}')\n",
    "[print('Fr-',idx, 'value: ' , np.round(diff_patterns[idx],8)) for idx in sorted_idx]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "familiar-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum, Maximum Iq : 0.0192, 0.0473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9040ea9c80504cea98ea74d34e13cdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters =  40\n",
      "label 1: [7807, 7690, 7680, 7681, 7565]\n",
      "label 2: [7556, 7557, 7438, 7437, 7436, 7435, 7429, 7430, 7431, 7432, 7311, 7310, 7309, 7308, 7306]\n",
      "label 3: [7048, 7049, 6937, 6936, 6935, 6922, 6923]\n",
      "label 4: [7055, 6930]\n",
      "label 5: [6798, 6799, 6800, 6684, 6683, 6682, 6681, 6671, 6672, 6673, 6674, 6558, 6557, 6556, 6555, 6546, 6547, 6548, 6431, 6430, 6429, 6420, 6421, 6422, 6304, 6303]\n",
      "label 6: [6174, 6173, 6048, 6047]\n",
      "label 7: [5931, 5930, 5912, 5913, 5806, 5805, 5785, 5680, 5679, 5659, 5660, 5554, 5553, 5552, 5533, 5534, 5535, 5428, 5427, 5426, 5408, 5409, 5301]\n",
      "label 8: [5802]\n",
      "label 9: [5058, 5057]\n",
      "label 10: [4798, 4797, 4778]\n",
      "label 11: [4677]\n",
      "label 12: [4415, 4404]\n",
      "label 13: [4278, 4279, 4280, 4163, 4162, 4161, 4152, 4153, 4154, 4037, 4036]\n",
      "label 14: [4149, 4040]\n",
      "label 15: [4156]\n",
      "label 16: [3911, 3910, 3900, 3901, 3785, 3784, 3783, 3782]\n",
      "label 17: [3749, 3750, 3685, 3684, 3683]\n",
      "label 18: [3639, 3640, 3542]\n",
      "label 19: [3287, 3286]\n",
      "label 20: [3260]\n",
      "label 21: [3271, 3154, 3153, 3145, 3146]\n",
      "label 22: [2890]\n",
      "label 23: [2800, 2799, 2798, 2743, 2744, 2745, 2675, 2674]\n",
      "label 24: [2507, 2406, 2405, 2380, 2381, 2382, 2383, 2280, 2279, 2278]\n",
      "label 25: [2286, 2249, 2250, 2160, 2159]\n",
      "label 26: [2026, 2025, 2024, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 1905, 1904, 1903, 1902, 1901, 1900, 1875, 1876]\n",
      "label 27: [2018, 2017, 2016, 2013, 2014, 2015, 1892, 1891, 1890]\n",
      "label 28: [1916, 1909, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1792, 1791, 1790, 1789, 1786, 1785, 1784]\n",
      "label 29: [1896]\n",
      "label 30: [1885, 1768, 1767, 1759, 1760, 1761, 1642, 1641, 1640, 1633, 1634]\n",
      "label 31: [1531, 1492, 1406, 1365, 1280]\n",
      "label 32: [1481, 1482, 1416, 1415, 1414, 1355, 1356, 1357, 1289, 1288]\n",
      "label 33: [1499]\n",
      "label 34: [1401, 1400, 1370, 1371, 1372, 1373, 1374, 1275, 1274, 1273, 1272, 1271, 1244, 1245, 1246, 1247, 1248, 1148, 1147, 1146, 1145, 1119, 1120, 1121, 1022, 1021, 1020, 993, 994, 995, 895, 894]\n",
      "label 35: [1385, 1260, 1258]\n",
      "label 36: [1107, 1035, 1034, 980, 981, 982, 908, 907]\n",
      "label 37: [885, 878, 879, 880, 759, 758, 757, 756, 754, 755, 630, 629]\n",
      "label 38: [620, 514, 513, 492, 493, 390, 389, 365, 366, 264, 239]\n",
      "label 39: [253, 252, 250, 251, 127, 126, 125]\n",
      "label 40: [116, 117, 9, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "### Produce heatmap and cluster frames by thresholding\n",
    "%matplotlib widget\n",
    "\n",
    "# spec\n",
    "file = '2029_Dentate_gyrus-roi0_masked.h5'\n",
    "scattering = '_WAXS2'\n",
    "scattering_max = 0.0361\n",
    "thr            = 0.034\n",
    "scattering_inc = 0.001\n",
    "\n",
    "\n",
    "# computation\n",
    "Width, Height = width_height(file)\n",
    "img_orig =  discritize_scattering(file, qgrid2, scattering, data_binning=True, bins=np.fromiter(drange(0, scattering_max, scattering_inc), float), directory=os.getcwd() )\n",
    "gray_img,_ = global_thresholding(img_orig, thr, binary_inv = False)\n",
    "\n",
    "# plot\n",
    "f,axs = plt.subplots(nrows=1, ncols=2)\n",
    "plot_heat_map_from_data(img_orig, Width, Height, args = (f, axs[0]), title= f'Heat Map {scattering}', cmap=\"jet\")\n",
    "plot_heat_map_from_data(gray_img, Width, Height, args = (f, axs[1]), title= f'Heat Map Thr at {thr}', cmap=\"jet\")\n",
    "plt.suptitle(f'{file}')\n",
    "plt.tight_layout()\n",
    "\n",
    "labeled_array, num_features = label(gray_img, np.ones((3,3)))\n",
    "print('Total clusters = ', num_features)\n",
    "\n",
    "Width, Height = labeled_array.shape[1], labeled_array.shape[0]\n",
    "sna = snaking(Width, Height , np.arange(0, Width*Height))\n",
    "\n",
    "\n",
    "dict_label = {}\n",
    "for i in np.unique(labeled_array):\n",
    "    if i!=0:\n",
    "        dict_label[i] = sna[labeled_array==i]\n",
    "        print(f'label {i}: {list(dict_label[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regional-bicycle",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_area_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-34562fbd9a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mipywidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msorted_area_idx\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Frame:'\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mdisabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mipywidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_dropdown_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_area_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_area_idx' is not defined"
     ]
    }
   ],
   "source": [
    "#### check generated heat maps collected frame data\n",
    "%matplotlib widget\n",
    "def exec_dropdown_value(frame):\n",
    "    \n",
    "    mf,area =  data.scaling_frame(frame, tissue_frame, mf_Qindices = (QSearchStart, QSearchEnd), seek_mf = seek_mf, window_size=window_size, show_result=True)\n",
    "    data.plot()\n",
    "    \n",
    "frame = ipywidgets.Dropdown(options= sorted_area_idx,  description='Frame:',    disabled=False, continuous_update=False)\n",
    "ipywidgets.interact(exec_dropdown_value, frame=frame)\n",
    "print(sorted_area_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "agricultural-montana",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]/Users/bashit.a/Documents/Alzheimer/Codes/essential_func.py:832: RuntimeWarning: divide by zero encountered in log\n",
      "  IqQ = np.log(IqBS*qgrid)                            # background subtracted Iq\n",
      "  5%|â–Œ         | 2/40 [00:00<00:02, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2067, 1958, 1326, 2080, 1358, 2428, 2068, 4374, 2197, 2199, 4373, 1357, 2427, 2079, 1957, 2452, 2198, 1327, 4912, 2200, 1325, 4223, 2558, 4913, 4723, 2066, 4848, 4911, 1359, 4847, 2437, 2081, 2323, 4222, 2322, 2196, 1959, 2320, 2438, 2453]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–Ž        | 5/40 [00:00<00:01, 19.54it/s]/Users/bashit.a/Documents/Alzheimer/Codes/essential_func.py:832: RuntimeWarning: invalid value encountered in log\n",
      "  IqQ = np.log(IqBS*qgrid)                            # background subtracted Iq\n",
      "/Users/bashit.a/Documents/Alzheimer/Codes/essential_func.py:859: RuntimeWarning: invalid value encountered in sqrt\n",
      "  df.loc[idx,f'Rxc-{i+1}'] = np.round(np.sqrt(-df.loc[idx,f'slope-{i+1}']*2),4)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 21.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 22.18it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e00d01e81d14b82a4390a3f449303ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### generate Radius of gyration\n",
    "%matplotlib widget\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# specs\n",
    "file = '2048_B8_masked.h5'\n",
    "Nsplits  = 2                                        # number of lines to fit\n",
    "StartIdx = 4                                        # including start index\n",
    "LastIdx  = 52                                       # Excluding last index\n",
    "frame    = 2223\n",
    "max_frames = 40                                    # first 100 frame values\n",
    "Rxc_str = ['Rxc-1', 'Rxc-2',]\n",
    "\n",
    "# new part\n",
    "data = Data_Analysis(file, qgrid2)\n",
    "IqBS = data.bkg_sub(bkg_frame = 2223)\n",
    "\n",
    "df_IqBS = pd.DataFrame(IqBS)    # convert to dataframe\n",
    "list_max_frames = df_IqBS.sort_values(5,ascending=False)[:max_frames].index.to_list()   # 5-->th column values sorted in descending order and taking max 40 frames intensity to fit lines except are zero\n",
    "print(list_max_frames)\n",
    "Rxc = {}\n",
    "n_patterns = len(IqBS)\n",
    "\n",
    "for rxc_str in Rxc_str:\n",
    "    Rxc[rxc_str] = np.zeros(n_patterns)     # except list_max_frames all values are zero\n",
    "\n",
    "    for frame in tqdm(list_max_frames):\n",
    "        df = optimize_best_lines(IqBS[frame], qgrid2, Nsplits, LastIdx, StartIdx,)   # get dataframe for the optimized one\n",
    "        try:\n",
    "            Rxc[rxc_str][frame] = df.iloc[df['rsq'].idxmax()][rxc_str]    \n",
    "        except:\n",
    "            print(f'Frame = {frame} {rxc_str} optimization failed - setting it to zero')\n",
    "            Rxc[rxc_str][frame] = 0                 # set to zero in nan is found in try section\n",
    "        \n",
    "# plot heat maps\n",
    "Width, Height = width_height(file)\n",
    "f, axs = plt.subplots(1, len(Rxc_str), num=f'{file} Heat maps', figsize=(10,5))\n",
    "for i, rxc_str in enumerate(Rxc_str):\n",
    "    diff_patterns = Rxc[rxc_str]\n",
    "    img_orig = snaking(Width, Height, diff_patterns)\n",
    "    \n",
    "    plot_heat_map_from_data(img_orig, Width, Height, args = (f, axs[i]), title= f'{file}- {rxc_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "german-ending",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Combinations = 45\n",
      "\n",
      "Summary of results Rsq -- \n",
      " 0               4.0000\n",
      "1              18.0000\n",
      "2              18.0000\n",
      "3              52.0000\n",
      "Tpoints-1      14.0000\n",
      "qgridL-1        0.0090\n",
      "qgridH-1        0.0230\n",
      "slope-1     -4833.9374\n",
      "Rxc-1          98.3254\n",
      "I(0)-1          0.9474\n",
      "rsq-1           0.9472\n",
      "std_err-1     329.6247\n",
      "Tpoints-2      34.0000\n",
      "qgridL-2        0.0230\n",
      "qgridH-2        0.0640\n",
      "slope-2      -698.0548\n",
      "Rxc-2          37.3646\n",
      "I(0)-2         -1.2604\n",
      "rsq-2           0.9421\n",
      "std_err-2      30.5975\n",
      "rsq             1.8893\n",
      "Name: 12, dtype: float64\n",
      "More Summary of results Rsq -- \n",
      "     0   1   2   3  Tpoints-1  qgridL-1  qgridH-1     slope-1     Rxc-1  \\\n",
      "0   4   6   6  52          2     0.009     0.011 -12982.1460  161.1344   \n",
      "1   4   7   7  52          3     0.009     0.012 -11530.7305  151.8600   \n",
      "2   4   8   8  52          4     0.009     0.013 -10360.3461  143.9468   \n",
      "3   4   9   9  52          5     0.009     0.014  -9429.4692  137.3279   \n",
      "4   4  10  10  52          6     0.009     0.015  -8636.6298  131.4278   \n",
      "5   4  11  11  52          7     0.009     0.016  -7878.8447  125.5296   \n",
      "6   4  12  12  52          8     0.009     0.017  -7300.9062  120.8380   \n",
      "7   4  13  13  52          9     0.009     0.018  -6807.7529  116.6855   \n",
      "8   4  14  14  52         10     0.009     0.019  -6297.4656  112.2271   \n",
      "9   4  15  15  52         11     0.009     0.020  -5884.7404  108.4872   \n",
      "10  4  16  16  52         12     0.009     0.021  -5497.3718  104.8558   \n",
      "11  4  17  17  52         13     0.009     0.022  -5129.8891  101.2906   \n",
      "12  4  18  18  52         14     0.009     0.023  -4833.9374   98.3254   \n",
      "13  4  19  19  52         15     0.009     0.024  -4551.6071   95.4108   \n",
      "14  4  20  20  52         16     0.009     0.025  -4299.3684   92.7294   \n",
      "15  4  21  21  52         17     0.009     0.026  -4035.5228   89.8390   \n",
      "16  4  22  22  52         18     0.009     0.027  -3802.7774   87.2098   \n",
      "17  4  23  23  52         19     0.009     0.028  -3607.0252   84.9356   \n",
      "18  4  24  24  52         20     0.009     0.029  -3415.0613   82.6446   \n",
      "19  4  25  25  52         21     0.009     0.030  -3233.6960   80.4201   \n",
      "20  4  26  26  52         22     0.009     0.031  -3061.2786   78.2468   \n",
      "21  4  27  27  52         23     0.009     0.032  -2907.2194   76.2525   \n",
      "22  4  28  28  52         24     0.009     0.033  -2762.8279   74.3348   \n",
      "23  4  29  29  52         25     0.009     0.034  -2640.9576   72.6768   \n",
      "24  4  30  30  52         26     0.009     0.035  -2525.2988   71.0676   \n",
      "25  4  31  31  52         27     0.009     0.036  -2407.8450   69.3952   \n",
      "26  4  32  32  52         28     0.009     0.037  -2305.7556   67.9081   \n",
      "27  4  33  33  52         29     0.009     0.038  -2213.4033   66.5343   \n",
      "28  4  34  34  52         30     0.009     0.039  -2122.1030   65.1476   \n",
      "29  4  35  35  52         31     0.009     0.040  -2035.1943   63.7996   \n",
      "30  4  36  36  52         32     0.009     0.041  -1958.8126   62.5909   \n",
      "31  4  37  37  52         33     0.009     0.042  -1884.3387   61.3896   \n",
      "32  4  38  38  52         34     0.009     0.043  -1811.1284   60.1852   \n",
      "33  4  39  39  52         35     0.009     0.044  -1751.1680   59.1805   \n",
      "34  4  40  40  52         36     0.009     0.045  -1691.6870   58.1668   \n",
      "35  4  41  41  52         37     0.009     0.046  -1631.3051   57.1193   \n",
      "36  4  42  42  52         38     0.009     0.047  -1580.3010   56.2192   \n",
      "37  4  43  43  52         39     0.009     0.048  -1527.9266   55.2798   \n",
      "38  4  44  44  52         40     0.009     0.049  -1480.3178   54.4117   \n",
      "39  4  45  45  52         41     0.009     0.050  -1434.3151   53.5596   \n",
      "40  4  46  46  52         42     0.009     0.052  -1389.9891   52.7255   \n",
      "41  4  47  47  52         43     0.009     0.054  -1338.4086   51.7380   \n",
      "42  4  48  48  52         44     0.009     0.056  -1281.9462   50.6349   \n",
      "44  4  50  50  52         46     0.009     0.060  -1167.0592   48.3127   \n",
      "\n",
      "    I(0)-1   rsq-1  std_err-1  Tpoints-2  qgridL-2  qgridH-2   slope-2  \\\n",
      "0   1.9181  1.0000     0.0000         46     0.011     0.064 -983.3921   \n",
      "1   1.7911  0.9954   783.0259         45     0.012     0.064 -951.5458   \n",
      "2   1.6805  0.9908   707.4576         44     0.013     0.064 -921.5366   \n",
      "3   1.5856  0.9869   626.9592         43     0.014     0.064 -893.2780   \n",
      "4   1.4986  0.9828   570.7240         42     0.015     0.064 -866.6187   \n",
      "5   1.4093  0.9761   551.1112         41     0.016     0.064 -840.9667   \n",
      "6   1.3361  0.9733   493.7115         40     0.017     0.064 -817.0807   \n",
      "7   1.2693  0.9709   445.6174         39     0.018     0.064 -794.8459   \n",
      "8   1.1953  0.9642   429.2031         38     0.019     0.064 -772.9985   \n",
      "9   1.1313  0.9607   396.8797         37     0.020     0.064 -752.8977   \n",
      "10  1.0673  0.9559   373.3956         36     0.021     0.064 -733.6226   \n",
      "11  1.0027  0.9497   355.9882         35     0.022     0.064 -714.7376   \n",
      "12  0.9474  0.9472   329.6247         34     0.023     0.064 -698.0548   \n",
      "13  0.8914  0.9432   309.8308         33     0.024     0.064 -682.0476   \n",
      "14  0.8383  0.9399   290.6596         32     0.025     0.064 -667.4792   \n",
      "15  0.7796  0.9324   280.5523         31     0.026     0.064 -651.5978   \n",
      "16  0.7248  0.9266   267.6282         30     0.027     0.064 -636.6583   \n",
      "17  0.6762  0.9236   251.5548         29     0.028     0.064 -624.0797   \n",
      "18  0.6259  0.9189   239.2048         28     0.029     0.064 -611.0553   \n",
      "19  0.5759  0.9135   228.3190         27     0.030     0.064 -597.8430   \n",
      "20  0.5258  0.9073   218.7434         26     0.031     0.064 -583.8328   \n",
      "21  0.4789  0.9026   208.4133         25     0.032     0.064 -570.6534   \n",
      "22  0.4327  0.8976   198.9086         24     0.033     0.064 -556.9150   \n",
      "23  0.3918  0.8957   187.9585         23     0.034     0.064 -546.5473   \n",
      "24  0.3511  0.8932   178.2830         22     0.035     0.064 -536.2734   \n",
      "25  0.3080  0.8882   170.8241         21     0.036     0.064 -522.4522   \n",
      "26  0.2687  0.8856   162.5643         20     0.037     0.064 -511.3942   \n",
      "27  0.2316  0.8838   154.4533         19     0.038     0.064 -502.3705   \n",
      "28  0.1934  0.8807   147.6193         18     0.039     0.064 -490.8473   \n",
      "29  0.1554  0.8772   141.3769         17     0.040     0.064 -477.7724   \n",
      "30  0.1206  0.8756   134.7872         16     0.041     0.064 -468.6312   \n",
      "31  0.0853  0.8731   128.9971         15     0.042     0.064 -457.0721   \n",
      "32  0.0492  0.8696   123.9618         14     0.043     0.064 -440.4903   \n",
      "33  0.0184  0.8696   118.0679         13     0.044     0.064 -435.6950   \n",
      "34 -0.0132  0.8684   112.9400         12     0.045     0.064 -428.4336   \n",
      "35 -0.0466  0.8656   108.6469         11     0.046     0.064 -412.4261   \n",
      "36 -0.0759  0.8654   103.8624         10     0.047     0.064 -410.9108   \n",
      "37 -0.1070  0.8635    99.8574          9     0.048     0.064 -399.5851   \n",
      "38 -0.1364  0.8626    95.8406          8     0.049     0.064 -396.7139   \n",
      "39 -0.1658  0.8613    92.1536          7     0.050     0.064 -393.9793   \n",
      "40 -0.1950  0.8598    88.7418          6     0.052     0.064 -391.1507   \n",
      "41 -0.2313  0.8561    85.7131          5     0.054     0.064 -388.3417   \n",
      "42 -0.2733  0.8505    82.9359          4     0.056     0.064 -377.2669   \n",
      "44 -0.3653  0.8386    77.1957          2     0.060     0.064 -612.3362   \n",
      "\n",
      "      Rxc-2  I(0)-2   rsq-2  std_err-2     rsq  \n",
      "0   44.3484 -0.6160  0.8508    62.0763  1.8508  \n",
      "1   43.6244 -0.6852  0.8621    58.0375  1.8575  \n",
      "2   42.9310 -0.7508  0.8726    54.3384  1.8634  \n",
      "3   42.2677 -0.8131  0.8823    50.9652  1.8692  \n",
      "4   41.6322 -0.8723  0.8912    47.8814  1.8740  \n",
      "5   41.0114 -0.9297  0.9000    44.8855  1.8761  \n",
      "6   40.4248 -0.9836  0.9078    42.2534  1.8811  \n",
      "7   39.8709 -1.0342  0.9144    39.9717  1.8853  \n",
      "8   39.3192 -1.0843  0.9214    37.6173  1.8856  \n",
      "9   38.8046 -1.1309  0.9272    35.6586  1.8879  \n",
      "10  38.3046 -1.1760  0.9327    33.8078  1.8886  \n",
      "11  37.8084 -1.2206  0.9383    31.9132  1.8880  \n",
      "12  37.3646 -1.2604  0.9421    30.5975  1.8893  \n",
      "13  36.9337 -1.2990  0.9455    29.3996  1.8887  \n",
      "14  36.5371 -1.3346  0.9479    28.5723  1.8878  \n",
      "15  36.0998 -1.3737  0.9517    27.2614  1.8841  \n",
      "16  35.6836 -1.4109  0.9549    26.1455  1.8815  \n",
      "17  35.3293 -1.4426  0.9562    25.6910  1.8798  \n",
      "18  34.9587 -1.4758  0.9580    25.0986  1.8769  \n",
      "19  34.5787 -1.5099  0.9600    24.4195  1.8735  \n",
      "20  34.1711 -1.5464  0.9628    23.4159  1.8701  \n",
      "21  33.7832 -1.5813  0.9652    22.5979  1.8678  \n",
      "22  33.3741 -1.6180  0.9683    21.4802  1.8659  \n",
      "23  33.0620 -1.6462  0.9688    21.3939  1.8645  \n",
      "24  32.7498 -1.6744  0.9692    21.3790  1.8624  \n",
      "25  32.3250 -1.7128  0.9726    20.1285  1.8608  \n",
      "26  31.9811 -1.7440  0.9738    19.7695  1.8594  \n",
      "27  31.6976 -1.7698  0.9736    20.0698  1.8574  \n",
      "28  31.3320 -1.8032  0.9750    19.6457  1.8557  \n",
      "29  30.9119 -1.8417  0.9780    18.5230  1.8552  \n",
      "30  30.6147 -1.8690  0.9780    18.8055  1.8536  \n",
      "31  30.2348 -1.9040  0.9796    18.3011  1.8527  \n",
      "32  29.6813 -1.9550  0.9869    14.6447  1.8565  \n",
      "33  29.5193 -1.9700  0.9857    15.8211  1.8553  \n",
      "34  29.2723 -1.9930  0.9851    16.6755  1.8535  \n",
      "35  28.7202 -2.0446  0.9914    12.8117  1.8570  \n",
      "36  28.6674 -2.0496  0.9898    14.7595  1.8552  \n",
      "37  28.2696 -2.0872  0.9912    14.1984  1.8547  \n",
      "38  28.1679 -2.0969  0.9890    17.0658  1.8516  \n",
      "39  28.0706 -2.1063  0.9852    21.5958  1.8465  \n",
      "40  27.9697 -2.1160  0.9771    29.9151  1.8369  \n",
      "41  27.8690 -2.1260  0.9615    44.8418  1.8176  \n",
      "42  27.4688 -2.1659  0.9258    75.5226  1.7763  \n",
      "44  34.9953 -1.2785  1.0000     0.0000  1.8386  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b306c0d8052348399a5027046a7d0ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dcc0996227434683964f368a6b5492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3  Tpoints-1  qgridL-1  qgridH-1     slope-1     Rxc-1  \\\n",
      "0   4   6   6  52          2     0.009     0.011 -12982.1460  161.1344   \n",
      "1   4   7   7  52          3     0.009     0.012 -11530.7305  151.8600   \n",
      "2   4   8   8  52          4     0.009     0.013 -10360.3461  143.9468   \n",
      "3   4   9   9  52          5     0.009     0.014  -9429.4692  137.3279   \n",
      "4   4  10  10  52          6     0.009     0.015  -8636.6298  131.4278   \n",
      "5   4  11  11  52          7     0.009     0.016  -7878.8447  125.5296   \n",
      "6   4  12  12  52          8     0.009     0.017  -7300.9062  120.8380   \n",
      "7   4  13  13  52          9     0.009     0.018  -6807.7529  116.6855   \n",
      "8   4  14  14  52         10     0.009     0.019  -6297.4656  112.2271   \n",
      "9   4  15  15  52         11     0.009     0.020  -5884.7404  108.4872   \n",
      "10  4  16  16  52         12     0.009     0.021  -5497.3718  104.8558   \n",
      "11  4  17  17  52         13     0.009     0.022  -5129.8891  101.2906   \n",
      "12  4  18  18  52         14     0.009     0.023  -4833.9374   98.3254   \n",
      "13  4  19  19  52         15     0.009     0.024  -4551.6071   95.4108   \n",
      "14  4  20  20  52         16     0.009     0.025  -4299.3684   92.7294   \n",
      "15  4  21  21  52         17     0.009     0.026  -4035.5228   89.8390   \n",
      "16  4  22  22  52         18     0.009     0.027  -3802.7774   87.2098   \n",
      "17  4  23  23  52         19     0.009     0.028  -3607.0252   84.9356   \n",
      "18  4  24  24  52         20     0.009     0.029  -3415.0613   82.6446   \n",
      "19  4  25  25  52         21     0.009     0.030  -3233.6960   80.4201   \n",
      "20  4  26  26  52         22     0.009     0.031  -3061.2786   78.2468   \n",
      "21  4  27  27  52         23     0.009     0.032  -2907.2194   76.2525   \n",
      "22  4  28  28  52         24     0.009     0.033  -2762.8279   74.3348   \n",
      "23  4  29  29  52         25     0.009     0.034  -2640.9576   72.6768   \n",
      "24  4  30  30  52         26     0.009     0.035  -2525.2988   71.0676   \n",
      "25  4  31  31  52         27     0.009     0.036  -2407.8450   69.3952   \n",
      "26  4  32  32  52         28     0.009     0.037  -2305.7556   67.9081   \n",
      "27  4  33  33  52         29     0.009     0.038  -2213.4033   66.5343   \n",
      "28  4  34  34  52         30     0.009     0.039  -2122.1030   65.1476   \n",
      "29  4  35  35  52         31     0.009     0.040  -2035.1943   63.7996   \n",
      "30  4  36  36  52         32     0.009     0.041  -1958.8126   62.5909   \n",
      "31  4  37  37  52         33     0.009     0.042  -1884.3387   61.3896   \n",
      "32  4  38  38  52         34     0.009     0.043  -1811.1284   60.1852   \n",
      "33  4  39  39  52         35     0.009     0.044  -1751.1680   59.1805   \n",
      "34  4  40  40  52         36     0.009     0.045  -1691.6870   58.1668   \n",
      "35  4  41  41  52         37     0.009     0.046  -1631.3051   57.1193   \n",
      "36  4  42  42  52         38     0.009     0.047  -1580.3010   56.2192   \n",
      "37  4  43  43  52         39     0.009     0.048  -1527.9266   55.2798   \n",
      "38  4  44  44  52         40     0.009     0.049  -1480.3178   54.4117   \n",
      "39  4  45  45  52         41     0.009     0.050  -1434.3151   53.5596   \n",
      "40  4  46  46  52         42     0.009     0.052  -1389.9891   52.7255   \n",
      "41  4  47  47  52         43     0.009     0.054  -1338.4086   51.7380   \n",
      "42  4  48  48  52         44     0.009     0.056  -1281.9462   50.6349   \n",
      "43  4  49  49  52         45     0.009     0.058  -1223.3778   49.4647   \n",
      "44  4  50  50  52         46     0.009     0.060  -1167.0592   48.3127   \n",
      "\n",
      "    I(0)-1   rsq-1  std_err-1  Tpoints-2  qgridL-2  qgridH-2   slope-2  \\\n",
      "0   1.9181  1.0000     0.0000         46     0.011     0.064 -983.3921   \n",
      "1   1.7911  0.9954   783.0259         45     0.012     0.064 -951.5458   \n",
      "2   1.6805  0.9908   707.4576         44     0.013     0.064 -921.5366   \n",
      "3   1.5856  0.9869   626.9592         43     0.014     0.064 -893.2780   \n",
      "4   1.4986  0.9828   570.7240         42     0.015     0.064 -866.6187   \n",
      "5   1.4093  0.9761   551.1112         41     0.016     0.064 -840.9667   \n",
      "6   1.3361  0.9733   493.7115         40     0.017     0.064 -817.0807   \n",
      "7   1.2693  0.9709   445.6174         39     0.018     0.064 -794.8459   \n",
      "8   1.1953  0.9642   429.2031         38     0.019     0.064 -772.9985   \n",
      "9   1.1313  0.9607   396.8797         37     0.020     0.064 -752.8977   \n",
      "10  1.0673  0.9559   373.3956         36     0.021     0.064 -733.6226   \n",
      "11  1.0027  0.9497   355.9882         35     0.022     0.064 -714.7376   \n",
      "12  0.9474  0.9472   329.6247         34     0.023     0.064 -698.0548   \n",
      "13  0.8914  0.9432   309.8308         33     0.024     0.064 -682.0476   \n",
      "14  0.8383  0.9399   290.6596         32     0.025     0.064 -667.4792   \n",
      "15  0.7796  0.9324   280.5523         31     0.026     0.064 -651.5978   \n",
      "16  0.7248  0.9266   267.6282         30     0.027     0.064 -636.6583   \n",
      "17  0.6762  0.9236   251.5548         29     0.028     0.064 -624.0797   \n",
      "18  0.6259  0.9189   239.2048         28     0.029     0.064 -611.0553   \n",
      "19  0.5759  0.9135   228.3190         27     0.030     0.064 -597.8430   \n",
      "20  0.5258  0.9073   218.7434         26     0.031     0.064 -583.8328   \n",
      "21  0.4789  0.9026   208.4133         25     0.032     0.064 -570.6534   \n",
      "22  0.4327  0.8976   198.9086         24     0.033     0.064 -556.9150   \n",
      "23  0.3918  0.8957   187.9585         23     0.034     0.064 -546.5473   \n",
      "24  0.3511  0.8932   178.2830         22     0.035     0.064 -536.2734   \n",
      "25  0.3080  0.8882   170.8241         21     0.036     0.064 -522.4522   \n",
      "26  0.2687  0.8856   162.5643         20     0.037     0.064 -511.3942   \n",
      "27  0.2316  0.8838   154.4533         19     0.038     0.064 -502.3705   \n",
      "28  0.1934  0.8807   147.6193         18     0.039     0.064 -490.8473   \n",
      "29  0.1554  0.8772   141.3769         17     0.040     0.064 -477.7724   \n",
      "30  0.1206  0.8756   134.7872         16     0.041     0.064 -468.6312   \n",
      "31  0.0853  0.8731   128.9971         15     0.042     0.064 -457.0721   \n",
      "32  0.0492  0.8696   123.9618         14     0.043     0.064 -440.4903   \n",
      "33  0.0184  0.8696   118.0679         13     0.044     0.064 -435.6950   \n",
      "34 -0.0132  0.8684   112.9400         12     0.045     0.064 -428.4336   \n",
      "35 -0.0466  0.8656   108.6469         11     0.046     0.064 -412.4261   \n",
      "36 -0.0759  0.8654   103.8624         10     0.047     0.064 -410.9108   \n",
      "37 -0.1070  0.8635    99.8574          9     0.048     0.064 -399.5851   \n",
      "38 -0.1364  0.8626    95.8406          8     0.049     0.064 -396.7139   \n",
      "39 -0.1658  0.8613    92.1536          7     0.050     0.064 -393.9793   \n",
      "40 -0.1950  0.8598    88.7418          6     0.052     0.064 -391.1507   \n",
      "41 -0.2313  0.8561    85.7131          5     0.054     0.064 -388.3417   \n",
      "42 -0.2733  0.8505    82.9359          4     0.056     0.064 -377.2669   \n",
      "43 -0.3192  0.8440    80.2176          3     0.058     0.064 -342.0102   \n",
      "44 -0.3653  0.8386    77.1957          2     0.060     0.064 -612.3362   \n",
      "\n",
      "      Rxc-2  I(0)-2   rsq-2  std_err-2     rsq  \n",
      "0   44.3484 -0.6160  0.8508    62.0763  1.8508  \n",
      "1   43.6244 -0.6852  0.8621    58.0375  1.8575  \n",
      "2   42.9310 -0.7508  0.8726    54.3384  1.8634  \n",
      "3   42.2677 -0.8131  0.8823    50.9652  1.8692  \n",
      "4   41.6322 -0.8723  0.8912    47.8814  1.8740  \n",
      "5   41.0114 -0.9297  0.9000    44.8855  1.8761  \n",
      "6   40.4248 -0.9836  0.9078    42.2534  1.8811  \n",
      "7   39.8709 -1.0342  0.9144    39.9717  1.8853  \n",
      "8   39.3192 -1.0843  0.9214    37.6173  1.8856  \n",
      "9   38.8046 -1.1309  0.9272    35.6586  1.8879  \n",
      "10  38.3046 -1.1760  0.9327    33.8078  1.8886  \n",
      "11  37.8084 -1.2206  0.9383    31.9132  1.8880  \n",
      "12  37.3646 -1.2604  0.9421    30.5975  1.8893  \n",
      "13  36.9337 -1.2990  0.9455    29.3996  1.8887  \n",
      "14  36.5371 -1.3346  0.9479    28.5723  1.8878  \n",
      "15  36.0998 -1.3737  0.9517    27.2614  1.8841  \n",
      "16  35.6836 -1.4109  0.9549    26.1455  1.8815  \n",
      "17  35.3293 -1.4426  0.9562    25.6910  1.8798  \n",
      "18  34.9587 -1.4758  0.9580    25.0986  1.8769  \n",
      "19  34.5787 -1.5099  0.9600    24.4195  1.8735  \n",
      "20  34.1711 -1.5464  0.9628    23.4159  1.8701  \n",
      "21  33.7832 -1.5813  0.9652    22.5979  1.8678  \n",
      "22  33.3741 -1.6180  0.9683    21.4802  1.8659  \n",
      "23  33.0620 -1.6462  0.9688    21.3939  1.8645  \n",
      "24  32.7498 -1.6744  0.9692    21.3790  1.8624  \n",
      "25  32.3250 -1.7128  0.9726    20.1285  1.8608  \n",
      "26  31.9811 -1.7440  0.9738    19.7695  1.8594  \n",
      "27  31.6976 -1.7698  0.9736    20.0698  1.8574  \n",
      "28  31.3320 -1.8032  0.9750    19.6457  1.8557  \n",
      "29  30.9119 -1.8417  0.9780    18.5230  1.8552  \n",
      "30  30.6147 -1.8690  0.9780    18.8055  1.8536  \n",
      "31  30.2348 -1.9040  0.9796    18.3011  1.8527  \n",
      "32  29.6813 -1.9550  0.9869    14.6447  1.8565  \n",
      "33  29.5193 -1.9700  0.9857    15.8211  1.8553  \n",
      "34  29.2723 -1.9930  0.9851    16.6755  1.8535  \n",
      "35  28.7202 -2.0446  0.9914    12.8117  1.8570  \n",
      "36  28.6674 -2.0496  0.9898    14.7595  1.8552  \n",
      "37  28.2696 -2.0872  0.9912    14.1984  1.8547  \n",
      "38  28.1679 -2.0969  0.9890    17.0658  1.8516  \n",
      "39  28.0706 -2.1063  0.9852    21.5958  1.8465  \n",
      "40  27.9697 -2.1160  0.9771    29.9151  1.8369  \n",
      "41  27.8690 -2.1260  0.9615    44.8418  1.8176  \n",
      "42  27.4688 -2.1659  0.9258    75.5226  1.7763  \n",
      "43  26.1538 -2.2958  0.8212   159.5604  1.6652  \n",
      "44  34.9953 -1.2785  1.0000     0.0000  1.8386  \n"
     ]
    }
   ],
   "source": [
    "### get individual frame fitting of radius of gyration\n",
    "%matplotlib widget\n",
    "# specs\n",
    "frame = 2067\n",
    "# verification\n",
    "df = optimize_best_lines(IqBS[frame], qgrid2, Nsplits, LastIdx, StartIdx, print_summary=True, show_plot=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "numeric-medium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>Tpoints-1</th>\n",
       "      <th>qgridL-1</th>\n",
       "      <th>qgridH-1</th>\n",
       "      <th>slope-1</th>\n",
       "      <th>Rxc-1</th>\n",
       "      <th>I(0)-1</th>\n",
       "      <th>rsq-1</th>\n",
       "      <th>std_err-1</th>\n",
       "      <th>Tpoints-2</th>\n",
       "      <th>qgridL-2</th>\n",
       "      <th>qgridH-2</th>\n",
       "      <th>slope-2</th>\n",
       "      <th>Rxc-2</th>\n",
       "      <th>I(0)-2</th>\n",
       "      <th>rsq-2</th>\n",
       "      <th>std_err-2</th>\n",
       "      <th>rsq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-10360.3461</td>\n",
       "      <td>143.9468</td>\n",
       "      <td>1.6805</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>707.4576</td>\n",
       "      <td>44</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-921.5366</td>\n",
       "      <td>42.9310</td>\n",
       "      <td>-0.7508</td>\n",
       "      <td>0.8726</td>\n",
       "      <td>54.3384</td>\n",
       "      <td>1.8634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-9429.4692</td>\n",
       "      <td>137.3279</td>\n",
       "      <td>1.5856</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>626.9592</td>\n",
       "      <td>43</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-893.2780</td>\n",
       "      <td>42.2677</td>\n",
       "      <td>-0.8131</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>50.9652</td>\n",
       "      <td>1.8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-8636.6298</td>\n",
       "      <td>131.4278</td>\n",
       "      <td>1.4986</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>570.7240</td>\n",
       "      <td>42</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-866.6187</td>\n",
       "      <td>41.6322</td>\n",
       "      <td>-0.8723</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>47.8814</td>\n",
       "      <td>1.8740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-7878.8447</td>\n",
       "      <td>125.5296</td>\n",
       "      <td>1.4093</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>551.1112</td>\n",
       "      <td>41</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-840.9667</td>\n",
       "      <td>41.0114</td>\n",
       "      <td>-0.9297</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>44.8855</td>\n",
       "      <td>1.8761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-7300.9062</td>\n",
       "      <td>120.8380</td>\n",
       "      <td>1.3361</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>493.7115</td>\n",
       "      <td>40</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-817.0807</td>\n",
       "      <td>40.4248</td>\n",
       "      <td>-0.9836</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>42.2534</td>\n",
       "      <td>1.8811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-6807.7529</td>\n",
       "      <td>116.6855</td>\n",
       "      <td>1.2693</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>445.6174</td>\n",
       "      <td>39</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-794.8459</td>\n",
       "      <td>39.8709</td>\n",
       "      <td>-1.0342</td>\n",
       "      <td>0.9144</td>\n",
       "      <td>39.9717</td>\n",
       "      <td>1.8853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-6297.4656</td>\n",
       "      <td>112.2271</td>\n",
       "      <td>1.1953</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>429.2031</td>\n",
       "      <td>38</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-772.9985</td>\n",
       "      <td>39.3192</td>\n",
       "      <td>-1.0843</td>\n",
       "      <td>0.9214</td>\n",
       "      <td>37.6173</td>\n",
       "      <td>1.8856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-5884.7404</td>\n",
       "      <td>108.4872</td>\n",
       "      <td>1.1313</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>396.8797</td>\n",
       "      <td>37</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-752.8977</td>\n",
       "      <td>38.8046</td>\n",
       "      <td>-1.1309</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>35.6586</td>\n",
       "      <td>1.8879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-5497.3718</td>\n",
       "      <td>104.8558</td>\n",
       "      <td>1.0673</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>373.3956</td>\n",
       "      <td>36</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-733.6226</td>\n",
       "      <td>38.3046</td>\n",
       "      <td>-1.1760</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>33.8078</td>\n",
       "      <td>1.8886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-5129.8891</td>\n",
       "      <td>101.2906</td>\n",
       "      <td>1.0027</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>355.9882</td>\n",
       "      <td>35</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-714.7376</td>\n",
       "      <td>37.8084</td>\n",
       "      <td>-1.2206</td>\n",
       "      <td>0.9383</td>\n",
       "      <td>31.9132</td>\n",
       "      <td>1.8880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-4833.9374</td>\n",
       "      <td>98.3254</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>329.6247</td>\n",
       "      <td>34</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-698.0548</td>\n",
       "      <td>37.3646</td>\n",
       "      <td>-1.2604</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>30.5975</td>\n",
       "      <td>1.8893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-4551.6071</td>\n",
       "      <td>95.4108</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>309.8308</td>\n",
       "      <td>33</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-682.0476</td>\n",
       "      <td>36.9337</td>\n",
       "      <td>-1.2990</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>29.3996</td>\n",
       "      <td>1.8887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-4299.3684</td>\n",
       "      <td>92.7294</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>0.9399</td>\n",
       "      <td>290.6596</td>\n",
       "      <td>32</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-667.4792</td>\n",
       "      <td>36.5371</td>\n",
       "      <td>-1.3346</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>28.5723</td>\n",
       "      <td>1.8878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-4035.5228</td>\n",
       "      <td>89.8390</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>280.5523</td>\n",
       "      <td>31</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-651.5978</td>\n",
       "      <td>36.0998</td>\n",
       "      <td>-1.3737</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>27.2614</td>\n",
       "      <td>1.8841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-3802.7774</td>\n",
       "      <td>87.2098</td>\n",
       "      <td>0.7248</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>267.6282</td>\n",
       "      <td>30</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-636.6583</td>\n",
       "      <td>35.6836</td>\n",
       "      <td>-1.4109</td>\n",
       "      <td>0.9549</td>\n",
       "      <td>26.1455</td>\n",
       "      <td>1.8815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>19</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-3607.0252</td>\n",
       "      <td>84.9356</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>251.5548</td>\n",
       "      <td>29</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-624.0797</td>\n",
       "      <td>35.3293</td>\n",
       "      <td>-1.4426</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>25.6910</td>\n",
       "      <td>1.8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-3415.0613</td>\n",
       "      <td>82.6446</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>239.2048</td>\n",
       "      <td>28</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-611.0553</td>\n",
       "      <td>34.9587</td>\n",
       "      <td>-1.4758</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>25.0986</td>\n",
       "      <td>1.8769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-3233.6960</td>\n",
       "      <td>80.4201</td>\n",
       "      <td>0.5759</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>228.3190</td>\n",
       "      <td>27</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-597.8430</td>\n",
       "      <td>34.5787</td>\n",
       "      <td>-1.5099</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>24.4195</td>\n",
       "      <td>1.8735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-3061.2786</td>\n",
       "      <td>78.2468</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>218.7434</td>\n",
       "      <td>26</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-583.8328</td>\n",
       "      <td>34.1711</td>\n",
       "      <td>-1.5464</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>23.4159</td>\n",
       "      <td>1.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-2907.2194</td>\n",
       "      <td>76.2525</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>208.4133</td>\n",
       "      <td>25</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-570.6534</td>\n",
       "      <td>33.7832</td>\n",
       "      <td>-1.5813</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>22.5979</td>\n",
       "      <td>1.8678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-2762.8279</td>\n",
       "      <td>74.3348</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>198.9086</td>\n",
       "      <td>24</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-556.9150</td>\n",
       "      <td>33.3741</td>\n",
       "      <td>-1.6180</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>21.4802</td>\n",
       "      <td>1.8659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>52</td>\n",
       "      <td>25</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-2640.9576</td>\n",
       "      <td>72.6768</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>187.9585</td>\n",
       "      <td>23</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-546.5473</td>\n",
       "      <td>33.0620</td>\n",
       "      <td>-1.6462</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>21.3939</td>\n",
       "      <td>1.8645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-2525.2988</td>\n",
       "      <td>71.0676</td>\n",
       "      <td>0.3511</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>178.2830</td>\n",
       "      <td>22</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-536.2734</td>\n",
       "      <td>32.7498</td>\n",
       "      <td>-1.6744</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>21.3790</td>\n",
       "      <td>1.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-2407.8450</td>\n",
       "      <td>69.3952</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>170.8241</td>\n",
       "      <td>21</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-522.4522</td>\n",
       "      <td>32.3250</td>\n",
       "      <td>-1.7128</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>20.1285</td>\n",
       "      <td>1.8608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3  Tpoints-1  qgridL-1  qgridH-1     slope-1     Rxc-1  \\\n",
       "2   4   8   8  52          4     0.009     0.013 -10360.3461  143.9468   \n",
       "3   4   9   9  52          5     0.009     0.014  -9429.4692  137.3279   \n",
       "4   4  10  10  52          6     0.009     0.015  -8636.6298  131.4278   \n",
       "5   4  11  11  52          7     0.009     0.016  -7878.8447  125.5296   \n",
       "6   4  12  12  52          8     0.009     0.017  -7300.9062  120.8380   \n",
       "7   4  13  13  52          9     0.009     0.018  -6807.7529  116.6855   \n",
       "8   4  14  14  52         10     0.009     0.019  -6297.4656  112.2271   \n",
       "9   4  15  15  52         11     0.009     0.020  -5884.7404  108.4872   \n",
       "10  4  16  16  52         12     0.009     0.021  -5497.3718  104.8558   \n",
       "11  4  17  17  52         13     0.009     0.022  -5129.8891  101.2906   \n",
       "12  4  18  18  52         14     0.009     0.023  -4833.9374   98.3254   \n",
       "13  4  19  19  52         15     0.009     0.024  -4551.6071   95.4108   \n",
       "14  4  20  20  52         16     0.009     0.025  -4299.3684   92.7294   \n",
       "15  4  21  21  52         17     0.009     0.026  -4035.5228   89.8390   \n",
       "16  4  22  22  52         18     0.009     0.027  -3802.7774   87.2098   \n",
       "17  4  23  23  52         19     0.009     0.028  -3607.0252   84.9356   \n",
       "18  4  24  24  52         20     0.009     0.029  -3415.0613   82.6446   \n",
       "19  4  25  25  52         21     0.009     0.030  -3233.6960   80.4201   \n",
       "20  4  26  26  52         22     0.009     0.031  -3061.2786   78.2468   \n",
       "21  4  27  27  52         23     0.009     0.032  -2907.2194   76.2525   \n",
       "22  4  28  28  52         24     0.009     0.033  -2762.8279   74.3348   \n",
       "23  4  29  29  52         25     0.009     0.034  -2640.9576   72.6768   \n",
       "24  4  30  30  52         26     0.009     0.035  -2525.2988   71.0676   \n",
       "25  4  31  31  52         27     0.009     0.036  -2407.8450   69.3952   \n",
       "\n",
       "    I(0)-1   rsq-1  std_err-1  Tpoints-2  qgridL-2  qgridH-2   slope-2  \\\n",
       "2   1.6805  0.9908   707.4576         44     0.013     0.064 -921.5366   \n",
       "3   1.5856  0.9869   626.9592         43     0.014     0.064 -893.2780   \n",
       "4   1.4986  0.9828   570.7240         42     0.015     0.064 -866.6187   \n",
       "5   1.4093  0.9761   551.1112         41     0.016     0.064 -840.9667   \n",
       "6   1.3361  0.9733   493.7115         40     0.017     0.064 -817.0807   \n",
       "7   1.2693  0.9709   445.6174         39     0.018     0.064 -794.8459   \n",
       "8   1.1953  0.9642   429.2031         38     0.019     0.064 -772.9985   \n",
       "9   1.1313  0.9607   396.8797         37     0.020     0.064 -752.8977   \n",
       "10  1.0673  0.9559   373.3956         36     0.021     0.064 -733.6226   \n",
       "11  1.0027  0.9497   355.9882         35     0.022     0.064 -714.7376   \n",
       "12  0.9474  0.9472   329.6247         34     0.023     0.064 -698.0548   \n",
       "13  0.8914  0.9432   309.8308         33     0.024     0.064 -682.0476   \n",
       "14  0.8383  0.9399   290.6596         32     0.025     0.064 -667.4792   \n",
       "15  0.7796  0.9324   280.5523         31     0.026     0.064 -651.5978   \n",
       "16  0.7248  0.9266   267.6282         30     0.027     0.064 -636.6583   \n",
       "17  0.6762  0.9236   251.5548         29     0.028     0.064 -624.0797   \n",
       "18  0.6259  0.9189   239.2048         28     0.029     0.064 -611.0553   \n",
       "19  0.5759  0.9135   228.3190         27     0.030     0.064 -597.8430   \n",
       "20  0.5258  0.9073   218.7434         26     0.031     0.064 -583.8328   \n",
       "21  0.4789  0.9026   208.4133         25     0.032     0.064 -570.6534   \n",
       "22  0.4327  0.8976   198.9086         24     0.033     0.064 -556.9150   \n",
       "23  0.3918  0.8957   187.9585         23     0.034     0.064 -546.5473   \n",
       "24  0.3511  0.8932   178.2830         22     0.035     0.064 -536.2734   \n",
       "25  0.3080  0.8882   170.8241         21     0.036     0.064 -522.4522   \n",
       "\n",
       "      Rxc-2  I(0)-2   rsq-2  std_err-2     rsq  \n",
       "2   42.9310 -0.7508  0.8726    54.3384  1.8634  \n",
       "3   42.2677 -0.8131  0.8823    50.9652  1.8692  \n",
       "4   41.6322 -0.8723  0.8912    47.8814  1.8740  \n",
       "5   41.0114 -0.9297  0.9000    44.8855  1.8761  \n",
       "6   40.4248 -0.9836  0.9078    42.2534  1.8811  \n",
       "7   39.8709 -1.0342  0.9144    39.9717  1.8853  \n",
       "8   39.3192 -1.0843  0.9214    37.6173  1.8856  \n",
       "9   38.8046 -1.1309  0.9272    35.6586  1.8879  \n",
       "10  38.3046 -1.1760  0.9327    33.8078  1.8886  \n",
       "11  37.8084 -1.2206  0.9383    31.9132  1.8880  \n",
       "12  37.3646 -1.2604  0.9421    30.5975  1.8893  \n",
       "13  36.9337 -1.2990  0.9455    29.3996  1.8887  \n",
       "14  36.5371 -1.3346  0.9479    28.5723  1.8878  \n",
       "15  36.0998 -1.3737  0.9517    27.2614  1.8841  \n",
       "16  35.6836 -1.4109  0.9549    26.1455  1.8815  \n",
       "17  35.3293 -1.4426  0.9562    25.6910  1.8798  \n",
       "18  34.9587 -1.4758  0.9580    25.0986  1.8769  \n",
       "19  34.5787 -1.5099  0.9600    24.4195  1.8735  \n",
       "20  34.1711 -1.5464  0.9628    23.4159  1.8701  \n",
       "21  33.7832 -1.5813  0.9652    22.5979  1.8678  \n",
       "22  33.3741 -1.6180  0.9683    21.4802  1.8659  \n",
       "23  33.0620 -1.6462  0.9688    21.3939  1.8645  \n",
       "24  32.7498 -1.6744  0.9692    21.3790  1.8624  \n",
       "25  32.3250 -1.7128  0.9726    20.1285  1.8608  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "df.style.background_gradient()\n",
    "df[df['rsq'] > 1.86]                      # Nsplits\n",
    "#df[df['rsq-3'] > 0.99]['Tpoints-3'].idxmax()      # Nsplits\n",
    "#plot_linear_lines(xData, yData, best_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stuffed-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# specs\n",
    "frame = 617    # 2048_B8_masked frame = 617 Rxc_2 = nan\n",
    "QQ  = np.square(qgrid2)                            # squaring q values\n",
    "IqQ = np.log(IqBS[frame]*qgrid2)                         # background subtracted Iq\n",
    "\n",
    "# semi specs\n",
    "xData = QQ\n",
    "yData = IqQ\n",
    "\n",
    "# computation\n",
    "def update_plot(Q1, Q2H):\n",
    "    Q1L, Q1H = Q1\n",
    "    plot_linear_lines(xData=xData, yData=yData, indices=[Q1L,Q1H,Q1H,Q2H])\n",
    "\n",
    "Q1 =  ipywidgets.IntRangeSlider(min=0, max=109, value = [2, 50], step=1)\n",
    "Q2H = ipywidgets.IntSlider(min=0, max=109, value = 109, step=1)\n",
    "\n",
    "ipywidgets.interact(update_plot, Q1=Q1, Q2H=Q2H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "liable-foundation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbbccc8ce28476fb4d3ea5549a83b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### crysol plots\n",
    "%matplotlib widget\n",
    "\n",
    "df1 = pd.read_csv(\"/Users/bashit.a/Documents/Alzheimer/PDB/5OQV/5kpoints/5oqv3deg5k.csv\")\n",
    "df2 = pd.read_csv(\"/Users/bashit.a/Documents/Alzheimer/PDB/5OQV/5oqv3deg.csv\")\n",
    "df3 = pd.read_csv(\"/Users/bashit.a/Documents/Alzheimer/PDB/5OQV/5OQV-3deg-Deepti.csv\")\n",
    "\n",
    "plt.plot(df1['q'], np.log(df1['Iq']),label='5kpoints');\n",
    "plt.plot(df2['q'], np.log(df2['Iq']), label='5OQV');\n",
    "plt.plot(df3['q'], np.log(df3['Iq']), label='5OQV-D');\n",
    "plt.xlabel('q');\n",
    "plt.ylabel('log(Iq)');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "satisfactory-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "idx_l, idx_u, valid_diff_values = valid_idx_search(np.array(df1['q']), np.array([df1['Iq']]), show_q = True)\n",
    "Iq = np.interp(qgrid2, np.array(df1['q']), np.array(df1['Iq']))\n",
    "idx_l, idx_u, valid_diff_values = valid_idx_search(qgrid2, Iq.reshape(1,-1))\n",
    "\n",
    "plt.plot(qgrid2, np.log(Iq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adolescent-cigarette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904220d1cbff41cf8962350c7f8dfa09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16c0a7fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### plot PDB twisted files\n",
    "\n",
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "file = '/Users/bashit.a/Documents/Alzheimer/PDB/CSV/6hrf.csv';\n",
    "df = pd.read_csv(file);\n",
    "plt.plot(df['q'], np.log(df['0']),label='0');\n",
    "plt.plot(df['q'], np.log(df['1']),label='1');\n",
    "plt.plot(df['q'], np.log(df['2']),label='2');\n",
    "plt.plot(df['q'], np.log(df['3']),label='3');\n",
    "plt.plot(df['q'], np.log(df['-1']),label='-1');\n",
    "plt.plot(df['q'], np.log(df['-2']),label='-2');\n",
    "plt.plot(df['q'], np.log(df['-3']),label='-3');\n",
    "plt.title(file)\n",
    "plt.xlabel('q')\n",
    "plt.ylabel('log(I)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "filled-slovenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ab5bb040f742ec9a216fda4d8b7aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=1, description='No. of Frames Category ', layout=Layout(display='flex', flex_flow='row', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a6fcc3047648e28680f9f9cad20755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b519d2c407ba43379f669aefe7616320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Go!', style=ButtonStyle(button_color='green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import mplcursors\n",
    "from matplotlib.widgets import CheckButtons\n",
    "\n",
    "from essential_func import *\n",
    "from ipywidgets import Layout, Button, Box, BoundedIntText, IntText, FloatText, Textarea, Dropdown, Label, FloatSlider, IntSlider, Checkbox\n",
    "\n",
    "### updating list\n",
    "def get_files_list(dropdown_name , seek_strs = ['.h5','.csv', '.xlsx']):\n",
    "    df  = pd.read_csv(os.path.join(csv_and_code_abs_directory,samples_csv))\n",
    "    idx = df[df[\"dropdown-name\"]==dropdown_name].index\n",
    "    directory = df['bnl-scan-sample-dir'][idx].values[0]\n",
    "    files_list = []\n",
    "    for seek_str in seek_strs:\n",
    "#         print(seek_strs)\n",
    "        files_list.append(cwd_files_search_with(seek_str, directory = directory, ))\n",
    "#     print(flatten(files_list))\n",
    "    return directory, flatten(files_list)\n",
    "\n",
    "### general layout\n",
    "form_item_layout = Layout(\n",
    "    display='flex',\n",
    "    flex_flow='row',\n",
    "    justify_content='space-between'\n",
    ")\n",
    "### main menu widgets\n",
    "bkg_sub   = Checkbox(value = False)\n",
    "normalize = Dropdown(options=['min-max', 'No'], value = 'min-max')\n",
    "n_filt    = BoundedIntText(value =4, min=1, max=20, style = {'description_width': 'initial'})\n",
    "y_axis    = Dropdown(options=['Iq', 'log(Iq)', 'qlog(Iq)'])\n",
    "x_axis    = Dropdown(options=['q', 'q^2'])\n",
    "fr_cat    = BoundedIntText(value =1, min=1, max=10, style = {'description_width': 'initial'}, description = 'No. of Frames Category ' , layout=form_item_layout)\n",
    "\n",
    "main_menu = Box(\n",
    "    [\n",
    "    Box([Label(value='Background Subtraction '),bkg_sub], layout=form_item_layout),\n",
    "    Box([Label(value='Normalize '),  normalize], layout=form_item_layout), \n",
    "    Box([Label(value='N-point Filt. '), n_filt], layout=form_item_layout), \n",
    "    Box([Label(value='Y-axis. '),       y_axis], layout=form_item_layout), \n",
    "    Box([Label(value='X-axis. '),       x_axis], layout=form_item_layout),\n",
    "    ], \n",
    "    layout= Layout(\n",
    "        display='flex',\n",
    "        flex_flow='column',\n",
    "        border='solid 2px',\n",
    "        align_items='stretch',\n",
    "        width='30%')\n",
    "    )\n",
    "### create dynamic function name\n",
    "def bindFunction(name):\n",
    "    def func_(*args):\n",
    "        file[name].options = get_files_list(dropdown_name = directory[name].value)[1]\n",
    "    func_.__name__ = 'on_value_change_'+str(name)\n",
    "    return func_\n",
    "\n",
    "def create_form_items(total_categories, bkg_subtraction):\n",
    "    ## form widgets\n",
    "    global directory, file, bkg_fr, frames, form_items, idx_\n",
    "    directory = {}; file = {}; bkg_fr={}; frames={}; form_items = []\n",
    "    for i in range(total_categories):\n",
    "        directory[i] = Dropdown(options = dropdown_name_list)\n",
    "        file[i]      = Dropdown(options = get_files_list(dropdown_name = dropdown_name_list[0] , seek_strs = ['.h5','.csv', '.xlsx'])[1])\n",
    "        bkg_fr[i]    = IntText() if bkg_subtraction else IntText(value = 55555, disabled=True)   ### default back_sub frame means bkg_sub is false\n",
    "        frames[i]    = Textarea()\n",
    "        \n",
    "        directory[i].observe(bindFunction(i), names='value')\n",
    "        \n",
    "        form_items.append([\n",
    "                Box([Label(value='Directory'),        directory[i]],  layout=form_item_layout),\n",
    "                Box([Label(value='File'),             file[i]],       layout=form_item_layout),\n",
    "                Box([Label(value='Background Frame'), bkg_fr[i]],     layout=form_item_layout),\n",
    "                Box([Label(value='Frames'),           frames[i]],     layout=form_item_layout)\n",
    "                ]) #* total_categories\n",
    "\n",
    "    form = Box(flatten(form_items),\n",
    "    layout=Layout(\n",
    "        display='flex',\n",
    "        flex_flow='column',\n",
    "        border='solid 1px',\n",
    "        align_items='stretch',\n",
    "        width='35%')\n",
    "    )\n",
    "    display(main_menu, form)\n",
    "\n",
    "    \n",
    "def on_button_clicked(*args):\n",
    "#     if bkg_sub.value == False:\n",
    "#         saxs_plots, waxs_plots = get_plots(directories = ['/Users/bashit.a/Documents/Alzheimer/July-2021/BNL-Data/sample-6/', \\\n",
    "#                                                          '/Users/bashit.a/Documents/Alzheimer/July-2021/BNL-Data/sample-1/'], \\\n",
    "#                                            files=['2029_Dentate_gyrus-roi0_masked.h5', '2040_FC-roi0.h5'], \\\n",
    "#                                            qgrid=qgrid2, normalize = True, \\\n",
    "#                                            frames = [[6558,981],[150,120]],  x_axis='q' , y_axis='Iq', bkg_fr = [1480, 100 ])\n",
    "    \n",
    "    global directories_arg, files_arg, frames_arg, bkg_fr_arg\n",
    "    directories_arg = []; files_arg=[]; frames_arg = []; bkg_fr_arg = [];\n",
    "\n",
    "    for idx in range(fr_cat.value):\n",
    "        directories_arg.append(get_files_list(dropdown_name = directory[idx].value)[0])\n",
    "        files_arg.append(file[idx].value)\n",
    "        frames_arg.append([int(i) for i in frames[idx].value.split(\",\") if i!=''])\n",
    "        bkg_fr_arg.append(bkg_fr[idx].value)\n",
    "    print(directories_arg, files_arg, frames_arg, bkg_fr_arg)\n",
    "                               \n",
    "button     = ipywidgets.Button(description='Go!');                                      \n",
    "button.style.button_color = \"green\";\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "out = ipywidgets.interactive_output(create_form_items, {'total_categories' : fr_cat, 'bkg_subtraction' : bkg_sub})\n",
    "display(fr_cat, out, button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caroline-prime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9479e73ad144c29c328a49937365cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file ...  /Users/bashit.a/Documents/Alzheimer/Dec-2020/ 2048_B8_masked.h5 [1957, 1958, 1959, 2066, 2067, 2068, 2079, 2080, 2081] 2222\n",
      "reading file ...  /Users/bashit.a/Documents/Alzheimer/July-2021/BNL-Data/sorted/ 1892_EC-roi0_masked.h5 [4069, 4120, 1044, 4434, 4184, 4513, 4103] 7321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75e0df6374b441abe2067d40dc2b8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.widgets.SubplotTool at 0x297643190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-d plot for high intensities\n",
    "%matplotlib widget\n",
    "import mplcursors\n",
    "from matplotlib.widgets import CheckButtons\n",
    "\n",
    "# plot\n",
    "f, ax = plt.subplots(2,2, figsize = (16,8), num=f'data', constrained_layout = False)\n",
    "plt.subplots_adjust(left=0.15)\n",
    "\n",
    "def saxs_waxs_plot_data_from_Iq(xData, yData, waxs_idx_start, waxs_idx_end, saxs_idx_start, saxs_idx_end, n_filt, normalize, y_axis):\n",
    "\n",
    "    if y_axis == 'Iq':\n",
    "        yData = yData;                          ax[0,0].set_ylabel(\"$I$\");                 ax[1,0].set_ylabel(\"$I$\");\n",
    "    elif y_axis == 'log(Iq)':\n",
    "        yData = np.log(yData);             ax[0,0].set_ylabel(\"$log(I)$\");            ax[1,0].set_ylabel(\"$log(I)$\");\n",
    "    elif y_axis == 'qlog(Iq)':\n",
    "        yData = np.log(yData*qgrid);      ax[0,0].set_ylabel(\"$qlog(I)$\");           ax[1,0].set_ylabel(\"$qlog(I)$\");\n",
    "    else:\n",
    "        print('No yData')\n",
    "\n",
    "    # filter output using convolution\n",
    "    ### filter coefficients\n",
    "    b = np.ones((n_filt))/n_filt    # numerator co-effs of filter transfer function\n",
    "    a = np.ones(1)                  # denominator co-effs of filter transfer function\n",
    "    yData = np.convolve(b, yData, mode='same') if n_filt>1 else yData         \n",
    "\n",
    "    # extract saxs and waxs data\n",
    "    yData_waxs = yData[waxs_idx_start : waxs_idx_end]\n",
    "    yData_saxs = yData[saxs_idx_start : saxs_idx_end]\n",
    "\n",
    "    # normalize saxs and waxs data\n",
    "    yData_waxs = yData_waxs/np.nanmax(yData_waxs) if normalize=='min-max' else yData_waxs   # normalized by maximum value\n",
    "    yData_saxs = yData_saxs/np.nanmax(yData_saxs) if normalize=='min-max' else yData_saxs   # normalized by maximum value\n",
    "\n",
    "    return yData_saxs, yData_waxs\n",
    "\n",
    "def get_plots(directories, files, qgrid, frames,  x_axis , y_axis, normalize='min-max', n_filt=1, bkg_fr = False,  saxs_scale = 'linear', waxs_scale = 'linear'):\n",
    "    \n",
    "    ### specs\n",
    "    waxs_idx_start     = 130     # qgrid2[130] = 0.4\n",
    "    waxs_idx_end       = 450     # qgrid2[450] = 2.0\n",
    "    saxs_idx_start     = 5       # qgrid2[2]   = 0.007\n",
    "    saxs_idx_end       = 50      # qgrid2[2]   = 0.06\n",
    "    \n",
    "    ### create empty lists to return\n",
    "    saxs_plots = []    \n",
    "    waxs_plots = []\n",
    "\n",
    "    xData = qgrid if x_axis == 'q' else np.square(qgrid)\n",
    "\n",
    "    bkg_fr = [[] for _ in range(len(files))] if bkg_fr==False else bkg_fr\n",
    "\n",
    "    for idx, (dir_, file_, frame_, bkg_fr_) in enumerate(zip(directories, files, frames, bkg_fr)):    \n",
    "\n",
    "        try:\n",
    "\n",
    "            if file_.endswith('csv') or file_.endswith('xlsx'):\n",
    "                df = pd.read_csv(dir_+file_)\n",
    "                Iq = np.interp(qgrid, np.array(df['q']), np.array(df['Iq']))   # inpterpolation\n",
    "\n",
    "                yData_saxs, yData_waxs = saxs_waxs_plot_data_from_Iq(xData, yData = Iq, waxs_idx_start=waxs_idx_start, waxs_idx_end=waxs_idx_end, saxs_idx_start=saxs_idx_start, saxs_idx_end=saxs_idx_end, \\\n",
    "                                                                     n_filt=n_filt, normalize=normalize, y_axis=y_axis,)\n",
    "\n",
    "                waxs_plots.append(ax[0,0].plot(xData[waxs_idx_start:waxs_idx_end],  yData_waxs, visible=False, label = file_.split(\".\")[0]))   # here dataset has only one frame\n",
    "                saxs_plots.append(ax[1,0].plot(xData[saxs_idx_start:saxs_idx_end] , yData_saxs, visible=False, label = file_.split(\".\")[0]))\n",
    "\n",
    "            else:\n",
    "                print('reading file ... ', dir_, file_, frame_, bkg_fr_)\n",
    "                data = Data_Analysis(file_ , qgrid = qgrid, window_size=1, directory = dir_)\n",
    "\n",
    "                Iq = data.bkg_sub(bkg_frame = bkg_fr_) if bkg_fr_!=55555 else data.Iq\n",
    "\n",
    "                for frame in frame_:\n",
    "                    yData_saxs, yData_waxs = saxs_waxs_plot_data_from_Iq(xData, yData = Iq[frame], waxs_idx_start=waxs_idx_start, waxs_idx_end=waxs_idx_end, saxs_idx_start=saxs_idx_start, saxs_idx_end=saxs_idx_end, \\\n",
    "                                                                     n_filt=n_filt, normalize=normalize, y_axis=y_axis,)\n",
    "\n",
    "                    waxs_plots.append(ax[0,0].plot(xData[waxs_idx_start:waxs_idx_end],  yData_waxs, visible=False, label = f'{idx}#{frame}'))   # here dataset has only one frame\n",
    "                    saxs_plots.append(ax[1,0].plot(xData[saxs_idx_start:saxs_idx_end] , yData_saxs, visible=False, label = f'{idx}#{frame}'))\n",
    "        except:\n",
    "            print('file reading failed : ', {file_})\n",
    "\n",
    "    ax[0,0].set(xlabel = \"$q (\\AA^{-1})$\" if x_axis == 'q' else \"$q^2 (\\AA^{-1})$\" , xscale = 'linear', yscale = waxs_scale)\n",
    "    ax[1,0].set(xlabel = \"$q (\\AA^{-1})$\" if x_axis == 'q' else \"$q^2 (\\AA^{-1})$\" , xscale = 'linear', yscale = saxs_scale)\n",
    "\n",
    "    return saxs_plots, waxs_plots\n",
    "\n",
    "### create SAXS WAXS Plot\n",
    "saxs_plots, waxs_plots = get_plots(directories = directories_arg, files=files_arg, qgrid=qgrid2, normalize=normalize.value, n_filt=n_filt.value, frames = frames_arg,  x_axis=x_axis.value , y_axis=y_axis.value, bkg_fr = bkg_fr_arg)\n",
    "# plot heatmap\n",
    "#plot_heat_map_from_data(img_orig, Width, Height, args = (f, ax[0,1]), cmap='jet')\n",
    "#plt.tight_layout()\n",
    "\n",
    "# Make checkbuttons with all plotted lines with correct visibility\n",
    "rax = plt.axes([0.005, 0.1, 0.05, 0.6])\n",
    "labels = [str(line[0].get_label()) for line in saxs_plots]   #label is a string\n",
    "visibility = [line[0].get_visible() for line in saxs_plots]\n",
    "check = CheckButtons(rax, labels, visibility, )\n",
    "for r,l in zip(check.rectangles, check.lines):\n",
    "    r.set_width(0.1)\n",
    "    r.set_alpha(0.4)\n",
    "    for ll in l:\n",
    "        ll.set_linewidth(8)\n",
    "\n",
    "# [ll.set_linewidth(8) for l in check.lines for ll in l]\n",
    "def func(label):\n",
    "    index = labels.index(label)\n",
    "    saxs_plots[index][0].set_visible(not saxs_plots[index][0].get_visible())\n",
    "    waxs_plots[index][0].set_visible(not waxs_plots[index][0].get_visible())\n",
    "\n",
    "    ax[0,0].legend(loc='upper right', bbox_to_anchor=(1, 1), fontsize='xx-small')\n",
    "    ax[1,0].legend(loc='upper right', bbox_to_anchor=(1, 1), fontsize='xx-small')\n",
    "\n",
    "    plt.draw()\n",
    "\n",
    "check.on_clicked(func)\n",
    "plt.subplot_tool()\n",
    "#mplcursors.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cubic-experience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters =  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Do cluster labeling\n",
    "import cv2\n",
    "from scipy.ndimage import label\n",
    "\n",
    "img_gray = np.asarray(img_orig, dtype=np.uint8)\n",
    "_, thresh_img = cv2.threshold(img_gray, 0, 255,cv2.THRESH_BINARY); #plt.imshow(thresh_img, cmap='gray')\n",
    "labeled_array, num_features = label(thresh_img, np.ones((3,3)))\n",
    "print('Total clusters = ', num_features)\n",
    "\n",
    "Width, Height = labeled_array.shape[1], labeled_array.shape[0]\n",
    "sna = snaking(Width, Height , np.arange(0, Width*Height))\n",
    "\n",
    "[print('label = ', i, sna[labeled_array==i]) for i in np.unique(labeled_array) if i!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acute-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_files import *\n",
    "save_mat('IqBS', ('IqBS', 'qgrid2'), (IqBS, qgrid2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extended-participant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4880 4881 4882 ... 4938 4939 4940]\n",
      " [4879 4878 4877 ... 4821 4820 4819]\n",
      " [4758 4759 4760 ... 4816 4817 4818]\n",
      " ...\n",
      " [ 122  123  124 ...  180  181  182]\n",
      " [ 121  120  119 ...   63   62   61]\n",
      " [   0    1    2 ...   58   59   60]]\n",
      "[[(80, 0) (80, 1) (80, 2) ... (80, 58) (80, 59) (80, 60)]\n",
      " [(79, 0) (79, 1) (79, 2) ... (79, 58) (79, 59) (79, 60)]\n",
      " [(78, 0) (78, 1) (78, 2) ... (78, 58) (78, 59) (78, 60)]\n",
      " ...\n",
      " [(2, 0) (2, 1) (2, 2) ... (2, 58) (2, 59) (2, 60)]\n",
      " [(1, 0) (1, 1) (1, 2) ... (1, 58) (1, 59) (1, 60)]\n",
      " [(0, 0) (0, 1) (0, 2) ... (0, 58) (0, 59) (0, 60)]]\n"
     ]
    }
   ],
   "source": [
    "### Correlation coefficients analysis\n",
    "\n",
    "Width, Height = 61, 81\n",
    "sna = snaking(Width, Height , np.arange(0, Width*Height))\n",
    "print(sna)\n",
    "\n",
    "grid = np.zeros((Height,Width),dtype=object)\n",
    "for i in range(0,Height):\n",
    "    for j in range(0,Width):\n",
    "        grid[i,j]=(i,j)\n",
    "grid = grid[::-1]\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wired-drink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(80, 60)]\n",
      "[[[4940]]]\n",
      "[4940]\n"
     ]
    }
   ],
   "source": [
    "frame = 4940\n",
    "def frame_to_idx(frame):\n",
    "    idx = [i for i in grid[sna==frame]]\n",
    "    return idx\n",
    "\n",
    "def idx_to_frame(l):\n",
    "    idx = []\n",
    "    for i in l:\n",
    "        a, b = i\n",
    "        x = [i==(a,b) for i in grid[Height-a-1]]\n",
    "        idx.append(sna[Height-a-1, np.where(x)].tolist())\n",
    "        print(idx)\n",
    "    return flatten(idx)\n",
    "\n",
    "l = frame_to_idx(frame)\n",
    "print(frame_to_idx(frame))\n",
    "print(idx_to_frame(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "minor-patent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(79, 59), (79, 60), (80, 59)]\n"
     ]
    }
   ],
   "source": [
    "### locating valid neighbor indices 3*3 kernel\n",
    "a, b = 80, 60\n",
    "l = []\n",
    "for i in range(a-1,a+2):\n",
    "    for j in range(b-1,b+2):\n",
    "        if (i,j) !=(a,b) and i>=0 and j>=0 and i<Height and j <Width:\n",
    "            l.append((i,j))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "nearby-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4820, 4819, 4939]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## look for frames gotten from previous indices\n",
    "idx = []\n",
    "for i in l:\n",
    "    a, b = i\n",
    "    x = [i==(a,b) for i in grid[Height-a-1]]\n",
    "    idx.append(sna[Height-a-1, np.where(x)].tolist())\n",
    "flatten(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "under-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "annots = loadmat('2048_B8_Iq.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conditional-heading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5fdf8c7f94485caadd107f61dea34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='File : ', options=('2029_Dentate_gyrus-roi0.h5', '2029_Dentate_gyrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Correlation coefficient calculation on individual frame\n",
    "%matplotlib widget\n",
    "from functools import reduce\n",
    "\n",
    "def coeffs_map(file, ref_frame, thr_coeff, search_q, normalize, L):\n",
    "    b = np.ones((1,L))/L    # numerator co-effs of filter transfer function\n",
    "    a = np.ones(1)          # denominator co-effs of filter transfer function\n",
    "\n",
    "    q_min, q_max = search_q\n",
    "    Width, Height = width_height(file)\n",
    "    Iq = read_Iq(file, 'merged')\n",
    "\n",
    "    Iq = signal.fftconvolve(Iq,b,mode='same',) if L>1 else Iq         # filter output using convolution\n",
    "    Iq = Iq/np.max(Iq,axis=1).reshape(-1,1) if normalize else Iq      # test how normalizing affecing data points print(Iq[0][:10])\n",
    "\n",
    "    q_min_idx, q_max_idx = qgrid_to_indices(qgrid2, q_min), qgrid_to_indices(qgrid2, q_max)\n",
    "    sna = snaking(Width, Height)\n",
    "    global cluster\n",
    "    cluster = []; coeffs = []\n",
    "    for frame in range(Width * Height):\n",
    "        coeff = np.corrcoef(Iq[ref_frame][q_min_idx:q_max_idx], Iq[frame][q_min_idx:q_max_idx])[0,1]\n",
    "        if coeff >= thr_coeff:\n",
    "            cluster.append(frame)\n",
    "            coeffs.append(coeff)\n",
    "    A = np.array([np.zeros((Height,Width)),sna])   # zero values matrix (A[0]=0) with frame numbers depth (A[1]=frames)\n",
    "\n",
    "    A = from_clusterFr_ceffs_to_matrix(A, cluster, coeffs)\n",
    "    \n",
    "    f,ax = plt.subplots()\n",
    "    plot_heat_map_from_data(A[0], Width, Height, args = (f,ax), title= f'Frame {ref_frame} coeffs map', cmap='jet')  # inferno\n",
    "\n",
    "#coeffs_map(file, ref_frame, thr_coeff,  search_q = (q_min, q_max))\n",
    "\n",
    "files = cwd_files_search_with('.h5')\n",
    "dropdown = ipywidgets.Dropdown(options= files, value = files[0], description='File : ', disabled=False)\n",
    "frame = ipywidgets.IntSlider(value=0,                   min=0,           max= 15000, step=1, description='Frame : ', continuous_update=False, layout=ipywidgets.Layout(width='50%')) # reduce(lambda x,y: x*y-1 , width_height(dropdown.value) )\n",
    "thr_coeff = ipywidgets.FloatSlider(value = 0.96 ,       min= 0,       max=1,    step=0.001 , description='THR Coeff:', continuous_update=False, layout=ipywidgets.Layout(width='50%'), readout=True, readout_format='.3f')    \n",
    "search_q = ipywidgets.FloatRangeSlider( value=(1, 2), min=qgrid2[0],   max=qgrid2[-1], step=0.05,   description='q Range:',  disabled=False,  continuous_update=False,  orientation='horizontal',  readout=True, readout_format='.3f',layout=ipywidgets.Layout(width='50%') )\n",
    "normalize = ipywidgets.Checkbox(value=True, description='Normalize', disabled=False, indent=False )\n",
    "n_point = ipywidgets.IntSlider(value=4,                   min=1,         max=10, step=1, description='N-point : ', continuous_update=False, layout=ipywidgets.Layout(width='30%'))\n",
    "\n",
    "\n",
    "ipywidgets.interactive(coeffs_map, file=dropdown, ref_frame=frame, thr_coeff=thr_coeff, search_q= search_q, normalize= normalize, L = n_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "hungarian-conflict",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2 2.2 2.6 3.8 3.4 2.8]]\n",
      "[[1.2 2.2 2.6 3.8 3.4 2.8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6250000000000013"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking convolution funcitons\n",
    "L = 5\n",
    "b = np.ones((1,L))/L\n",
    "x = np.array([1,2,3,5,2,7]).reshape(1,-1)\n",
    "print(signal.convolve(x,b, mode='same'))\n",
    "\n",
    "L=5                        # L-point filter\n",
    "b = (np.ones((1,L)))/L     # numerator co-effs of filter transfer function\n",
    "a = np.ones(1)             # denominator co-effs of filter transfer function\n",
    "y = signal.fftconvolve(x,b,mode='same',)   # filter output using convolution\n",
    "print(y)\n",
    "qgrid2[375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adverse-confirmation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of estimated clusters : 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65305f8119cd498da18e80e611be2fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Mean shift unsupervised clustering algorithm ~ 3 mins to execute\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "# The following bandwidth can be automatically detected using\n",
    "ms = MeanShift(n_jobs=-1)                 # sklearn mean-shift n_jobs = -1 means using all processors\n",
    "ms.fit(X)                        # train mean shift algorithm\n",
    "labels = ms.labels_              # get labels of trained data\n",
    "plot_labels(file, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coordinated-daisy",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b13ceb28549a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_GMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mplot_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mplot_tsne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b13ceb28549a>\u001b[0m in \u001b[0;36mtrain_GMM\u001b[0;34m(n_components)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m               \u001b[0;31m# import package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgaussian_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgaussian_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m                                     \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m                        \u001b[0;31m# assign each data point to a cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "### import package\n",
    "from sklearn.manifold import TSNE, MDS, LocallyLinearEmbedding\n",
    "from functools import partial\n",
    "\n",
    "### GMM model\n",
    "def train_GMM(n_components):\n",
    "    from sklearn.mixture import GaussianMixture               # import package\n",
    "    gaussian_model = GaussianMixture(n_components=n_components)          # define the model\n",
    "    gaussian_model.fit(X)                                     # train the model\n",
    "    labels = gaussian_model.predict(X)                        # assign each data point to a cluster\n",
    "    return labels\n",
    "\n",
    "### t-SNE\n",
    "def plot_tsne(X, labels, perplexity, n_iter):\n",
    "    X_embedded = TSNE(n_components=3, perplexity=perplexity, n_iter=n_iter, init='pca', learning_rate=200, random_state=0, n_jobs=-1).fit_transform(X)\n",
    "    #X_embedded = MDS(n_components=3, max_iter=100, n_init=1).fit_transform(X)\n",
    "    \n",
    "    # Set-up manifold methods\n",
    "#     LLE = partial(LocallyLinearEmbedding, n_neighbors=10, n_components=3, eigen_solver='auto')\n",
    "#     X_embedded = LLE(method='modified').fit_transform(X)\n",
    "    \n",
    "    tsne_data = np.vstack((X_embedded.T, labels)).T    # creating a new data frame which help us in ploting the result data\n",
    "    #tsne_df = pd.DataFrame (data=tsne_data, columns= (\"Dim_1\", \"Dim_2\", \"Dim_3\", \"label\"))\n",
    "    #sns.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2', 'Dim_3', 'label')\n",
    "    fig = plt.figure()\n",
    "    ax  = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(*zip(*tsne_data[:,:3]), c=tsne_data[:,3])\n",
    "    plt.show()\n",
    "\n",
    "labels = train_GMM(n_components=2)\n",
    "plot_labels(file, labels, title='gaussian')\n",
    "plot_tsne(X, labels, perplexity=50, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "victorian-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452106d76e394dfeaad6d8282ca93af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='File : ', options=('2029_Dentate_gyrus-roi0.h5', '2029_Dentate_gyrus-roi0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8e85c3f93f4b159e493dde2893a038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=4, continuous_update=False, description='N-point : ', max=10, min=1), Checkbox(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d60433afac242e5bef90af130a6c97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=4, continuous_update=False, description='clusters', max=20, min=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### GMM and t-SNE plot\n",
    "import functools\n",
    "\n",
    "### figures output widgets\n",
    "out1 = ipywidgets.Output()\n",
    "out2 = ipywidgets.Output()\n",
    "\n",
    "### GMM model\n",
    "def train_GMM(X, n_components):\n",
    "    from sklearn.mixture import GaussianMixture               # import package\n",
    "    gaussian_model = GaussianMixture(n_components=n_components)          # define the model\n",
    "    \n",
    "    from sklearn import cluster\n",
    "    #birch = cluster.Birch(n_clusters=n_components)\n",
    "    \n",
    "    gaussian_model.fit(X)                                     # train the model\n",
    "    labels = gaussian_model.predict(X)                        # assign each data point to a cluster\n",
    "    return labels\n",
    "\n",
    "@out1.capture(clear_output=True)\n",
    "def unsupervised_map(file, labels, clusters):\n",
    "    f1, ax1 = plt.subplots(num=1)\n",
    "    plot_labels(file, labels, title='GMM', args = (f1, ax1), cmap = discrete_cmap( N= len(np.unique(labels)), base_cmap = 'brg') )   # discrete_cmap( N= len(np.unique(labels)), base_cmap = 'brg') 'Pastel1'\n",
    "\n",
    "@out2.capture(clear_output=True)\n",
    "def manifold_plot(X, labels, perplexity, n_iter, animation):\n",
    "    tsne_data = manifold_tsne(X, perplexity, n_iter, dim=3)\n",
    "    print(animation)\n",
    "    f2, ax2 = plt.subplots(num=2)\n",
    "    plot_3d(tsne_data, labels, args = (f2,ax2), cmap = discrete_cmap( N= len(np.unique(labels)), base_cmap = 'brg'))  # discrete_cmap( N= len(np.unique(labels)), base_cmap = 'bwr')   'Pastel1'\n",
    "    if animation: plot_3d_animation(tsne_data, labels, elev=35, azim=60, anim_frames=100, anim_interval=10)\n",
    "\n",
    "def on_button_clicked_params():\n",
    "    return dropdown.value, search_q.value, n_point.value, normalize.value, clusters.value, perplexity.value, n_iter.value, animation.value\n",
    "\n",
    "def on_button_clicked(_):   # \n",
    "    %matplotlib widget\n",
    "    \n",
    "    ### get function arguments\n",
    "    dropdown, search_q, n_point, normalize, clusters, perplexity, n_iter, animation = on_button_clicked_params()\n",
    "    \n",
    "    ### Data preprocessing\n",
    "    q_min, q_max = search_q\n",
    "    X = file_preprocess(file = dropdown, L=n_point, qgrid=qgrid2, q_min=q_min, q_max=q_max, normalize=normalize)\n",
    "    \n",
    "    ### Unsupervised model training and visualizing\n",
    "    labels = train_GMM(X, n_components=clusters)\n",
    "    labels = sort_labels(labels)\n",
    "    unsupervised_map(dropdown, labels, clusters)\n",
    "    manifold_plot(X, labels, perplexity, n_iter, animation)\n",
    "    \n",
    "### file selection and operation widgets  \n",
    "files      = cwd_files_search_with('.h5')\n",
    "dropdown   = ipywidgets.Dropdown(options= files, value = files[0], description='File : ', disabled=False)\n",
    "search_q   = ipywidgets.FloatRangeSlider( value=(1.0, 2.0), min=qgrid2[0],   max=qgrid2[-1], step=0.0001,   description='q Range:',  disabled=False,  continuous_update=False,  layout=ipywidgets.Layout(width='40%'), orientation='horizontal',  readout=True, readout_format='.3f',)\n",
    "n_point    = ipywidgets.IntSlider(value=4,                   min=1,         max=10, step=1, description='N-point : ', continuous_update=False, )\n",
    "normalize  = ipywidgets.Checkbox(value=False, description='Normalize', disabled=False, indent=False )\n",
    "\n",
    "### clustering and manifold widgets\n",
    "clusters   = ipywidgets.IntSlider(value=4, min=1, max=20, step=1, description='clusters', continuous_update=False          )\n",
    "perplexity = ipywidgets.IntSlider(value=30, min=10, max=1000, step=10, description='perplexity', continuous_update=False   )\n",
    "n_iter     = ipywidgets.IntSlider(value=1000, min=500, max=10000, step=500, description='n_iter', continuous_update=False  )\n",
    "button     = ipywidgets.Button(description='Go!');                                      button.style.button_color = \"green\";\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "### animation object\n",
    "animation  = ipywidgets.Checkbox(value=False, description='Animation', disabled=False, indent=False )\n",
    "\n",
    "\n",
    "display(ipywidgets.HBox([dropdown, search_q  ]))\n",
    "display(ipywidgets.HBox([n_point, normalize, animation ]))\n",
    "display(ipywidgets.HBox([ipywidgets.VBox([clusters, perplexity, n_iter, button]), out1, out2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "middle-lincoln",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d55219a30541da95a9523433102af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Click Me!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import functools\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "button = widgets.Button(description=\"Click Me!\")\n",
    "display(button)\n",
    "\n",
    "def fun(a):\n",
    "    print(a)\n",
    "\n",
    "def on_button_clicked(b, rs_=\"some_default_string\"):\n",
    "    fun(rs_)\n",
    "\n",
    "button.on_click(functools.partial(on_button_clicked, rs_=\"abcdefg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loose-constitutional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a3f6c48f9d49419100581f57cadc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='File : ', options=('2029_Dentate_gyrus-roi0.h5', '2029_Dentate_gyrus-roi0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc4602d09764bbda9579527bc11ab42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### difference intensity heatmap\n",
    "out = ipywidgets.Output()\n",
    "\n",
    "@out.capture(clear_output=True)\n",
    "def on_button_clicked(_):   \n",
    "    %matplotlib widget\n",
    "\n",
    "    Width, Height = width_height(file=dropdown.value)\n",
    "    \n",
    "    ### Data preprocessing\n",
    "    q_min, q_max = search_q.value\n",
    "    X = file_preprocess(file = dropdown.value, L=n_point.value, qgrid=qgrid2, q_min=q_min, q_max=q_max, normalize=False)\n",
    "    diff_patterns = find_rep_value(qgrid2, X, method = 'circ')\n",
    "    filtered_diff_patterns = snaking(Width, Height, diff_patterns)\n",
    "    filtered_diff_patterns = filtered_diff_patterns.reshape(Height,Width)\n",
    "\n",
    "    ### original data\n",
    "    Iq = read_Iq(file = dropdown.value, scattering = 'merged')\n",
    "    q_min_idx, q_max_idx = qgrid_to_indices(qgrid2, q_min), qgrid_to_indices(qgrid2, q_max)\n",
    "    Iq = Iq[:,q_min_idx:q_max_idx]\n",
    "    diff_patterns = find_rep_value(qgrid2, Iq, method = 'circ')\n",
    "    img_orig = snaking(Width, Height, diff_patterns)\n",
    "    img_orig = img_orig.reshape(Height,Width)\n",
    "\n",
    "    subtracted = (img_orig-filtered_diff_patterns).reshape(Height,Width)\n",
    "\n",
    "    fig, [ax1, ax2, ax3] = plt.subplots(nrows=1, ncols=3, figsize=(16,3))\n",
    "    \n",
    "    plot_heat_map_from_data(img_orig, Width, Height, args = (fig, ax1), title= 'original', cmap=\"viridis\")\n",
    "    plot_heat_map_from_data(filtered_diff_patterns, Width, Height, args = (fig, ax2), title= 'filtered', cmap=\"viridis\")\n",
    "    plot_heat_map_from_data(subtracted, Width, Height, args = (fig, ax3), title= 'subtracted', cmap=\"viridis\")\n",
    "    \n",
    "    \n",
    "### file selection and operation widgets  \n",
    "files      = cwd_files_search_with('.h5')\n",
    "dropdown   = ipywidgets.Dropdown(options= files, value = files[0], description='File : ', disabled=False)\n",
    "search_q   = ipywidgets.FloatRangeSlider( value=(1, 2), min=qgrid2[0],   max=qgrid2[-1], step=0.1,   description='q Range:',  disabled=False,  continuous_update=False,  orientation='horizontal',  readout=True, readout_format='.2f',)\n",
    "n_point    = ipywidgets.IntSlider(value=4,                   min=1,         max=10, step=1, description='N-point : ', continuous_update=False, layout=ipywidgets.Layout(width='30%'))\n",
    "\n",
    "#### button press event\n",
    "button     = ipywidgets.Button(description='Go!');                                      button.style.button_color = \"green\";\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "display(ipywidgets.HBox([dropdown, search_q, n_point, button ]))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thrown-shore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25396c6ccb914055a92a64016827dce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters =  68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bashit.a/miniforge3/envs/py38/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/bashit.a/miniforge3/envs/py38/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/bashit.a/miniforge3/envs/py38/lib/python3.8/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/bashit.a/miniforge3/envs/py38/lib/python3.8/site-packages/sklearn/utils/extmath.py:689: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b074283cf7d14d68890118b0427006c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c9cb5625a441078c1eabf2718ba500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='index', options=(73, 119, 134, 202, 208, 214, 224, 245, 274â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      plaque-frame  cluster-label  selected-plaque       tissue-frames\n",
      "0             7753              1            False                 NaN\n",
      "1             7754              1            False                 NaN\n",
      "2             7755              1            False                 NaN\n",
      "3             7756              1            False                 NaN\n",
      "4             7757              1            False                 NaN\n",
      "5             7758              1            False                 NaN\n",
      "6             7759              1            False                 NaN\n",
      "7             7744              1            False                 NaN\n",
      "8             7743              1            False                 NaN\n",
      "9             7742              1            False                 NaN\n",
      "10            7741              1            False                 NaN\n",
      "11            7740              1            False                 NaN\n",
      "12            7739              1            False                 NaN\n",
      "13            7738              1            False                 NaN\n",
      "14            7627              1            False                 NaN\n",
      "15            7628              1            False                 NaN\n",
      "16            7629              1            False                 NaN\n",
      "17            7630              1            False                 NaN\n",
      "18            7631              1            False                 NaN\n",
      "19            7632              1            False                 NaN\n",
      "20            7633              1            False                 NaN\n",
      "21            7634              1            False                 NaN\n",
      "22            7618              1            False                 NaN\n",
      "23            7617              1            False                 NaN\n",
      "24            7616              1            False                 NaN\n",
      "25            7615              1            False                 NaN\n",
      "26            7614              1            False                 NaN\n",
      "27            7613              1            False                 NaN\n",
      "28            7612              1            False                 NaN\n",
      "29            7611              1            False                 NaN\n",
      "30            7610              1            False                 NaN\n",
      "31            7609              1            False                 NaN\n",
      "32            7501              1            False                 NaN\n",
      "33            7502              1            False                 NaN\n",
      "34            7503              1            False                 NaN\n",
      "35            7504              1            False                 NaN\n",
      "36            7505              1            False                 NaN\n",
      "37            7506              1            False                 NaN\n",
      "38            7507              1            False                 NaN\n",
      "39            7508              1            False                 NaN\n",
      "40            7509              1            False                 NaN\n",
      "41            7510              1            False                 NaN\n",
      "42            7511              1            False                 NaN\n",
      "43            7512              1            False                 NaN\n",
      "44            7492              1            False                 NaN\n",
      "45            7491              1            False                 NaN\n",
      "46            7490              1            False                 NaN\n",
      "47            7489              1            False                 NaN\n",
      "48            7488              1            False                 NaN\n",
      "49            7487              1            False                 NaN\n",
      "50            7486              1            False                 NaN\n",
      "51            7485              1            False                 NaN\n",
      "52            7484              1            False                 NaN\n",
      "53            7483              1            False                 NaN\n",
      "54            7482              1            False                 NaN\n",
      "55            7481              1            False                 NaN\n",
      "56            7480              1            False                 NaN\n",
      "57            7371              1            False                 NaN\n",
      "58            7372              1            False                 NaN\n",
      "59            7373              1            False                 NaN\n",
      "60            7374              1            False                 NaN\n",
      "61            7375              1            False                 NaN\n",
      "62            7376              1            False                 NaN\n",
      "63            7377              1            False                 NaN\n",
      "64            7380              1            False                 NaN\n",
      "65            7381              1            False                 NaN\n",
      "66            7382              1            False                 NaN\n",
      "67            7383              1            False                 NaN\n",
      "68            7384              1            False                 NaN\n",
      "69            7385              1            False                 NaN\n",
      "70            7386              1            False                 NaN\n",
      "71            7387              1            False                 NaN\n",
      "72            7388              1            False                 NaN\n",
      "73            7389              1             True  [7478, 7514, 7607]\n",
      "74            7390              1            False                 NaN\n",
      "75            7370              1            False                 NaN\n",
      "76            7369              1            False                 NaN\n",
      "77            7368              1            False                 NaN\n",
      "78            7367              1            False                 NaN\n",
      "79            7366              1            False                 NaN\n",
      "80            7365              1            False                 NaN\n",
      "81            7359              1            False                 NaN\n",
      "82            7358              1            False                 NaN\n",
      "83            7357              1            False                 NaN\n",
      "84            7356              1            False                 NaN\n",
      "85            7355              1            False                 NaN\n",
      "86            7354              1            False                 NaN\n",
      "87            7353              1            False                 NaN\n",
      "88            7352              1            False                 NaN\n",
      "89            7351              1            False                 NaN\n",
      "90            7350              1            False                 NaN\n",
      "91            7245              1            False                 NaN\n",
      "92            7246              1            False                 NaN\n",
      "93            7247              1            False                 NaN\n",
      "94            7248              1            False                 NaN\n",
      "95            7249              1            False                 NaN\n",
      "96            7250              1            False                 NaN\n",
      "97            7260              1            False                 NaN\n",
      "98            7261              1            False                 NaN\n",
      "99            7262              1            False                 NaN\n",
      "100           7263              1            False                 NaN\n",
      "101           7264              1            False                 NaN\n",
      "102           7265              1            False                 NaN\n",
      "103           7266              1            False                 NaN\n",
      "104           7244              1            False                 NaN\n",
      "105           7243              1            False                 NaN\n",
      "106           7241              1            False                 NaN\n",
      "107           7240              1            False                 NaN\n",
      "108           7239              1            False                 NaN\n",
      "109           7228              1            False                 NaN\n",
      "110           7227              1            False                 NaN\n",
      "111           7226              1            False                 NaN\n",
      "112           7225              1            False                 NaN\n",
      "113           7224              1            False                 NaN\n",
      "114           7223              1            False                 NaN\n",
      "115           7126              2            False                 NaN\n",
      "116           7127              2            False                 NaN\n",
      "117           7111              2            False                 NaN\n",
      "118           7110              2            False                 NaN\n",
      "119           7001              2             True  [7002, 6982, 7234]\n",
      "120           7002              2            False                 NaN\n",
      "121           6984              2            False                 NaN\n",
      "122           6983              2            False                 NaN\n",
      "123           7095              3            False                 NaN\n",
      "124           7094              3            False                 NaN\n",
      "125           7015              3            False                 NaN\n",
      "126           7016              3            False                 NaN\n",
      "127           7017              3            False                 NaN\n",
      "128           7018              3            False                 NaN\n",
      "129           7019              3            False                 NaN\n",
      "130           6970              3            False                 NaN\n",
      "131           6969              3            False                 NaN\n",
      "132           6968              3            False                 NaN\n",
      "133           6967              3            False                 NaN\n",
      "134           6966              3             True  [7020, 6965, 6891]\n",
      "135           6965              3            False                 NaN\n",
      "136           6964              3            False                 NaN\n",
      "137           6890              3            False                 NaN\n",
      "138           6891              3            False                 NaN\n",
      "139           6892              3            False                 NaN\n",
      "140           6893              3            False                 NaN\n",
      "141           6894              3            False                 NaN\n",
      "142           6895              3            False                 NaN\n",
      "143           6896              3            False                 NaN\n",
      "144           6842              3            False                 NaN\n",
      "145           6841              3            False                 NaN\n",
      "146           6840              3            False                 NaN\n",
      "147           6839              3            False                 NaN\n",
      "148           6838              3            False                 NaN\n",
      "149           6837              3            False                 NaN\n",
      "150           6836              3            False                 NaN\n",
      "151           6764              3            False                 NaN\n",
      "152           6765              3            False                 NaN\n",
      "153           6766              3            False                 NaN\n",
      "154           6767              3            False                 NaN\n",
      "155           6768              3            False                 NaN\n",
      "156           6769              3            False                 NaN\n",
      "157           6770              3            False                 NaN\n",
      "158           6771              3            False                 NaN\n",
      "159           6772              3            False                 NaN\n",
      "160           6717              3            False                 NaN\n",
      "161           6716              3            False                 NaN\n",
      "162           6715              3            False                 NaN\n",
      "163           6714              3            False                 NaN\n",
      "164           6713              3            False                 NaN\n",
      "165           6712              3            False                 NaN\n",
      "166           6711              3            False                 NaN\n",
      "167           6710              3            False                 NaN\n",
      "168           6709              3            False                 NaN\n",
      "169           6708              3            False                 NaN\n",
      "170           6707              3            False                 NaN\n",
      "171           6638              3            False                 NaN\n",
      "172           6639              3            False                 NaN\n",
      "173           6640              3            False                 NaN\n",
      "174           6641              3            False                 NaN\n",
      "175           6642              3            False                 NaN\n",
      "176           6643              3            False                 NaN\n",
      "177           6644              3            False                 NaN\n",
      "178           6645              3            False                 NaN\n",
      "179           6646              3            False                 NaN\n",
      "180           6647              3            False                 NaN\n",
      "181           6648              3            False                 NaN\n",
      "182           6649              3            False                 NaN\n",
      "183           6591              3            False                 NaN\n",
      "184           6590              3            False                 NaN\n",
      "185           6589              3            False                 NaN\n",
      "186           6588              3            False                 NaN\n",
      "187           6587              3            False                 NaN\n",
      "188           6586              3            False                 NaN\n",
      "189           6584              3            False                 NaN\n",
      "190           6583              3            False                 NaN\n",
      "191           6582              3            False                 NaN\n",
      "192           6581              3            False                 NaN\n",
      "193           6580              3            False                 NaN\n",
      "194           6514              3            False                 NaN\n",
      "195           6515              3            False                 NaN\n",
      "196           6516              3            False                 NaN\n",
      "197           6519              3            False                 NaN\n",
      "198           6520              3            False                 NaN\n",
      "199           6521              3            False                 NaN\n",
      "200           6522              3            False                 NaN\n",
      "201           6523              3            False                 NaN\n",
      "202           6867              4             True  [7116, 6989, 6869]\n",
      "203           6868              4            False                 NaN\n",
      "204           6866              4            False                 NaN\n",
      "205           6865              4            False                 NaN\n",
      "206           6883              5            False                 NaN\n",
      "207           6884              5            False                 NaN\n",
      "208           6850              5             True  [7006, 6629, 6973]\n",
      "209           6849              5            False                 NaN\n",
      "210           6757              5            False                 NaN\n",
      "211           6758              5            False                 NaN\n",
      "212           6621              6            False                 NaN\n",
      "213           6622              6            False                 NaN\n",
      "214           6608              6             True  [6498, 6735, 6731]\n",
      "215           6607              6            False                 NaN\n",
      "216           6495              6            False                 NaN\n",
      "217           6496              6            False                 NaN\n",
      "218           6481              6            False                 NaN\n",
      "219           6480              6            False                 NaN\n",
      "220           6479              6            False                 NaN\n",
      "221           6370              6            False                 NaN\n",
      "222           6371              6            False                 NaN\n",
      "223           6372              6            False                 NaN\n",
      "224           6488              7             True  [6240, 6359, 6485]\n",
      "225           6487              7            False                 NaN\n",
      "226           6486              7            False                 NaN\n",
      "227           6363              7            False                 NaN\n",
      "228           6364              7            False                 NaN\n",
      "229           6365              7            False                 NaN\n",
      "230           6362              7            False                 NaN\n",
      "231           6361              7            False                 NaN\n",
      "232           6360              7            False                 NaN\n",
      "233           6237              7            False                 NaN\n",
      "234           6238              7            False                 NaN\n",
      "235           6236              7            False                 NaN\n",
      "236           6235              7            False                 NaN\n",
      "237           6234              7            False                 NaN\n",
      "238           6111              7            False                 NaN\n",
      "239           6112              7            False                 NaN\n",
      "240           6113              7            False                 NaN\n",
      "241           6110              7            False                 NaN\n",
      "242           6109              7            False                 NaN\n",
      "243           6108              7            False                 NaN\n",
      "244           6474              8            False                 NaN\n",
      "245           6473              8             True  [6506, 6629, 6599]\n",
      "246           6377              8            False                 NaN\n",
      "247           6378              8            False                 NaN\n",
      "248           6348              8            False                 NaN\n",
      "249           6347              8            False                 NaN\n",
      "250           6399              9            False                 NaN\n",
      "251           6400              9            False                 NaN\n",
      "252           6401              9            False                 NaN\n",
      "253           6326              9            False                 NaN\n",
      "254           6325              9            False                 NaN\n",
      "255           6324              9            False                 NaN\n",
      "256           6323              9            False                 NaN\n",
      "257           6273              9            False                 NaN\n",
      "258           6274              9            False                 NaN\n",
      "259           6275              9            False                 NaN\n",
      "260           6276              9            False                 NaN\n",
      "261           6277              9            False                 NaN\n",
      "262           6200              9            False                 NaN\n",
      "263           6199              9            False                 NaN\n",
      "264           6198              9            False                 NaN\n",
      "265           6197              9            False                 NaN\n",
      "266           6196              9            False                 NaN\n",
      "267           6195              9            False                 NaN\n",
      "268           6194              9            False                 NaN\n",
      "269           6147              9            False                 NaN\n",
      "270           6148              9            False                 NaN\n",
      "271           6149              9            False                 NaN\n",
      "272           6150              9            False                 NaN\n",
      "273           6151              9            False                 NaN\n",
      "274           6152              9             True  [6278, 6194, 6322]\n",
      "275           6153              9            False                 NaN\n",
      "276           6154              9            False                 NaN\n",
      "277           6072              9            False                 NaN\n",
      "278           6071              9            False                 NaN\n",
      "279           6070              9            False                 NaN\n",
      "280           6069              9            False                 NaN\n",
      "281           6068              9            False                 NaN\n",
      "282           6067              9            False                 NaN\n",
      "283           6024              9            False                 NaN\n",
      "284           6025              9            False                 NaN\n",
      "285           6026              9            False                 NaN\n",
      "286           6027              9            False                 NaN\n",
      "287           6028              9            False                 NaN\n",
      "288           6029              9            False                 NaN\n",
      "289           5944              9            False                 NaN\n",
      "290           5943              9            False                 NaN\n",
      "291           5942              9            False                 NaN\n",
      "292           5941              9            False                 NaN\n",
      "293           5940              9            False                 NaN\n",
      "294           5939              9            False                 NaN\n",
      "295           5938              9            False                 NaN\n",
      "296           5902              9            False                 NaN\n",
      "297           5903              9            False                 NaN\n",
      "298           5904              9            False                 NaN\n",
      "299           5905              9            False                 NaN\n",
      "300           5906              9            False                 NaN\n",
      "301           5813              9            False                 NaN\n",
      "302           5812              9            False                 NaN\n",
      "303           5811              9            False                 NaN\n",
      "304           5810              9            False                 NaN\n",
      "305           5779              9            False                 NaN\n",
      "306           5780              9            False                 NaN\n",
      "307           5781              9            False                 NaN\n",
      "308           5686              9            False                 NaN\n",
      "309           5685              9            False                 NaN\n",
      "310           5684              9            False                 NaN\n",
      "311           5653              9            False                 NaN\n",
      "312           5654              9            False                 NaN\n",
      "313           5655              9            False                 NaN\n",
      "314           5560              9            False                 NaN\n",
      "315           5559              9            False                 NaN\n",
      "316           5558              9            False                 NaN\n",
      "317           5557              9            False                 NaN\n",
      "318           5528              9            False                 NaN\n",
      "319           5529              9            False                 NaN\n",
      "320           5530              9            False                 NaN\n",
      "321           5433              9            False                 NaN\n",
      "322           5432              9            False                 NaN\n",
      "323           5402              9            False                 NaN\n",
      "324           5403              9            False                 NaN\n",
      "325           5405              9            False                 NaN\n",
      "326           5406              9            False                 NaN\n",
      "327           5407              9            False                 NaN\n",
      "328           5307              9            False                 NaN\n",
      "329           5306              9            False                 NaN\n",
      "330           5305              9            False                 NaN\n",
      "331           5304              9            False                 NaN\n",
      "332           5303              9            False                 NaN\n",
      "333           5302              9            False                 NaN\n",
      "334           5277              9            False                 NaN\n",
      "335           5278              9            False                 NaN\n",
      "336           5279              9            False                 NaN\n",
      "337           5280              9            False                 NaN\n",
      "338           5281              9            False                 NaN\n",
      "339           6209             10             True  [6013, 6389, 6141]\n",
      "340           6208             10            False                 NaN\n",
      "341           6138             10            False                 NaN\n",
      "342           6139             10            False                 NaN\n",
      "343           6140             10            False                 NaN\n",
      "344           6084             10            False                 NaN\n",
      "345           6083             10            False                 NaN\n",
      "346           6082             10            False                 NaN\n",
      "347           6081             10            False                 NaN\n",
      "348           6011             10            False                 NaN\n",
      "349           6012             10            False                 NaN\n",
      "350           6013             10            False                 NaN\n",
      "351           6014             10            False                 NaN\n",
      "352           5749             11            False                 NaN\n",
      "353           5750             11            False                 NaN\n",
      "354           5716             11            False                 NaN\n",
      "355           5715             11             True  [5753, 5591, 5496]\n",
      "356           5679             12            False                 NaN\n",
      "357           5678             12            False                 NaN\n",
      "358           5660             12            False                 NaN\n",
      "359           5661             12            False                 NaN\n",
      "360           5662             12            False                 NaN\n",
      "361           5552             12            False                 NaN\n",
      "362           5551             12            False                 NaN\n",
      "363           5550             12            False                 NaN\n",
      "364           5549             12            False                 NaN\n",
      "365           5536             12            False                 NaN\n",
      "366           5537             12            False                 NaN\n",
      "367           5538             12            False                 NaN\n",
      "368           5539             12            False                 NaN\n",
      "369           5540             12            False                 NaN\n",
      "370           5425             12            False                 NaN\n",
      "371           5424             12            False                 NaN\n",
      "372           5423             12            False                 NaN\n",
      "373           5422             12            False                 NaN\n",
      "374           5421             12             True  [5418, 5417, 5663]\n",
      "375           5420             12            False                 NaN\n",
      "376           5410             12            False                 NaN\n",
      "377           5411             12            False                 NaN\n",
      "378           5412             12            False                 NaN\n",
      "379           5413             12            False                 NaN\n",
      "380           5414             12            False                 NaN\n",
      "381           5415             12            False                 NaN\n",
      "382           5416             12            False                 NaN\n",
      "383           5298             12            False                 NaN\n",
      "384           5297             12            False                 NaN\n",
      "385           5296             12            False                 NaN\n",
      "386           5295             12            False                 NaN\n",
      "387           5294             12            False                 NaN\n",
      "388           5293             12            False                 NaN\n",
      "389           5285             12            False                 NaN\n",
      "390           5286             12            False                 NaN\n",
      "391           5287             12            False                 NaN\n",
      "392           5288             12            False                 NaN\n",
      "393           5170             12            False                 NaN\n",
      "394           5169             12            False                 NaN\n",
      "395           5588             13             True  [5711, 5496, 5753]\n",
      "396           5587             13            False                 NaN\n",
      "397           5586             13            False                 NaN\n",
      "398           5499             13            False                 NaN\n",
      "399           5500             13            False                 NaN\n",
      "400           5501             13            False                 NaN\n",
      "401           5492             14             True  [5719, 5617, 5592]\n",
      "402           5493             14            False                 NaN\n",
      "403           5469             14            False                 NaN\n",
      "404           5468             14            False                 NaN\n",
      "405           5467             14            False                 NaN\n",
      "406           5366             14            False                 NaN\n",
      "407           5367             14            False                 NaN\n",
      "408           5368             14            False                 NaN\n",
      "409           5343             14            False                 NaN\n",
      "410           5342             14            False                 NaN\n",
      "411           5524             15            False                 NaN\n",
      "412           5525             15            False                 NaN\n",
      "413           5437             15            False                 NaN\n",
      "414           5436             15            False                 NaN\n",
      "415           5398             15            False                 NaN\n",
      "416           5399             15            False                 NaN\n",
      "417           5400             15            False                 NaN\n",
      "418           5315             15            False                 NaN\n",
      "419           5314             15            False                 NaN\n",
      "420           5313             15            False                 NaN\n",
      "421           5311             15            False                 NaN\n",
      "422           5310             15            False                 NaN\n",
      "423           5309             15            False                 NaN\n",
      "424           5268             15            False                 NaN\n",
      "425           5269             15            False                 NaN\n",
      "426           5270             15             True  [5310, 5185, 5273]\n",
      "427           5271             15            False                 NaN\n",
      "428           5272             15            False                 NaN\n",
      "429           5273             15            False                 NaN\n",
      "430           5274             15            False                 NaN\n",
      "431           5188             15            False                 NaN\n",
      "432           5187             15            False                 NaN\n",
      "433           5186             15            False                 NaN\n",
      "434           5185             15            False                 NaN\n",
      "435           5184             15            False                 NaN\n",
      "436           5183             15            False                 NaN\n",
      "437           5143             15            False                 NaN\n",
      "438           5144             15            False                 NaN\n",
      "439           5145             15            False                 NaN\n",
      "440           5146             15            False                 NaN\n",
      "441           5147             15            False                 NaN\n",
      "442           5058             15            False                 NaN\n",
      "443           5057             15            False                 NaN\n",
      "444           5021             15            False                 NaN\n",
      "445           5022             15            False                 NaN\n",
      "446           5023             15            False                 NaN\n",
      "447           4931             15            False                 NaN\n",
      "448           4930             15            False                 NaN\n",
      "449           5477             16            False                 NaN\n",
      "450           5476             16            False                 NaN\n",
      "451           5357             16            False                 NaN\n",
      "452           5358             16            False                 NaN\n",
      "453           5359             16            False                 NaN\n",
      "454           5360             16            False                 NaN\n",
      "455           5352             16            False                 NaN\n",
      "456           5351             16             True  [5476, 5234, 5356]\n",
      "457           5350             16            False                 NaN\n",
      "458           5349             16            False                 NaN\n",
      "459           5231             16            False                 NaN\n",
      "460           5232             16            False                 NaN\n",
      "461           5233             16            False                 NaN\n",
      "462           5234             16            False                 NaN\n",
      "463           5224             16            False                 NaN\n",
      "464           5223             16            False                 NaN\n",
      "465           5222             16            False                 NaN\n",
      "466           5106             16            False                 NaN\n",
      "467           5107             16            False                 NaN\n",
      "468           5108             16            False                 NaN\n",
      "469           5109             16            False                 NaN\n",
      "470           5099             16            False                 NaN\n",
      "471           5098             16            False                 NaN\n",
      "472           5097             16            False                 NaN\n",
      "473           5246             17             True  [5463, 5120, 5371]\n",
      "474           5247             17            False                 NaN\n",
      "475           5248             17            False                 NaN\n",
      "476           5216             17            False                 NaN\n",
      "477           5215             17            False                 NaN\n",
      "478           5214             17            False                 NaN\n",
      "479           5213             17            False                 NaN\n",
      "480           5212             17            False                 NaN\n",
      "481           5211             17            False                 NaN\n",
      "482           5210             17            False                 NaN\n",
      "483           5209             17            False                 NaN\n",
      "484           5208             17            False                 NaN\n",
      "485           5115             17            False                 NaN\n",
      "486           5116             17            False                 NaN\n",
      "487           5117             17            False                 NaN\n",
      "488           5118             17            False                 NaN\n",
      "489           5119             17            False                 NaN\n",
      "490           5120             17            False                 NaN\n",
      "491           5121             17            False                 NaN\n",
      "492           5122             17            False                 NaN\n",
      "493           5123             17            False                 NaN\n",
      "494           5090             17            False                 NaN\n",
      "495           5089             17            False                 NaN\n",
      "496           5088             17            False                 NaN\n",
      "497           5087             17            False                 NaN\n",
      "498           5085             17            False                 NaN\n",
      "499           5084             17            False                 NaN\n",
      "500           5083             17            False                 NaN\n",
      "501           5082             17            False                 NaN\n",
      "502           5081             17            False                 NaN\n",
      "503           4990             17            False                 NaN\n",
      "504           4991             17            False                 NaN\n",
      "505           4992             17            False                 NaN\n",
      "506           4993             17            False                 NaN\n",
      "507           4994             17            False                 NaN\n",
      "508           4995             17            False                 NaN\n",
      "509           4996             17            False                 NaN\n",
      "510           4997             17            False                 NaN\n",
      "511           4998             17            False                 NaN\n",
      "512           4963             17            False                 NaN\n",
      "513           4962             17            False                 NaN\n",
      "514           4961             17            False                 NaN\n",
      "515           4960             17            False                 NaN\n",
      "516           4873             18             True  [4745, 4999, 4702]\n",
      "517           4874             18            False                 NaN\n",
      "518           4875             18            False                 NaN\n",
      "519           4876             18            False                 NaN\n",
      "520           4877             18            False                 NaN\n",
      "521           4828             18            False                 NaN\n",
      "522           4827             18            False                 NaN\n",
      "523           4826             18            False                 NaN\n",
      "524           4825             18            False                 NaN\n",
      "525           4824             18            False                 NaN\n",
      "526           4747             18            False                 NaN\n",
      "527           4748             18            False                 NaN\n",
      "528           4734             19             True  [4969, 4592, 4735]\n",
      "529           4735             19            False                 NaN\n",
      "530           4715             19            False                 NaN\n",
      "531           4714             19            False                 NaN\n",
      "532           4644             20            False                 NaN\n",
      "533           4645             20            False                 NaN\n",
      "534           4553             20            False                 NaN\n",
      "535           4552             20            False                 NaN\n",
      "536           4551             20            False                 NaN\n",
      "537           4550             20            False                 NaN\n",
      "538           4516             20             True  [4302, 4303, 4391]\n",
      "539           4517             20            False                 NaN\n",
      "540           4518             20            False                 NaN\n",
      "541           4519             20            False                 NaN\n",
      "542           4520             20            False                 NaN\n",
      "543           4521             20            False                 NaN\n",
      "544           4429             20            False                 NaN\n",
      "545           4428             20            False                 NaN\n",
      "546           4427             20            False                 NaN\n",
      "547           4426             20            False                 NaN\n",
      "548           4425             20            False                 NaN\n",
      "549           4424             20            False                 NaN\n",
      "550           4390             20            False                 NaN\n",
      "551           4391             20            False                 NaN\n",
      "552           4392             20            False                 NaN\n",
      "553           4393             20            False                 NaN\n",
      "554           4394             20            False                 NaN\n",
      "555           4302             20            False                 NaN\n",
      "556           4301             20            False                 NaN\n",
      "557           4300             20            False                 NaN\n",
      "558           4299             20            False                 NaN\n",
      "559           4265             20            False                 NaN\n",
      "560           4266             20            False                 NaN\n",
      "561           4511             21            False                 NaN\n",
      "562           4512             21            False                 NaN\n",
      "563           4513             21            False                 NaN\n",
      "564           4436             21            False                 NaN\n",
      "565           4435             21            False                 NaN\n",
      "566           4434             21            False                 NaN\n",
      "567           4433             21            False                 NaN\n",
      "568           4432             21            False                 NaN\n",
      "569           4382             21            False                 NaN\n",
      "570           4383             21            False                 NaN\n",
      "571           4384             21            False                 NaN\n",
      "572           4385             21            False                 NaN\n",
      "573           4386             21            False                 NaN\n",
      "574           4311             21             True  [4435, 4313, 4439]\n",
      "575           4310             21            False                 NaN\n",
      "576           4257             21            False                 NaN\n",
      "577           4258             21            False                 NaN\n",
      "578           4184             21            False                 NaN\n",
      "579           4183             21            False                 NaN\n",
      "580           4182             21            False                 NaN\n",
      "581           4132             21            False                 NaN\n",
      "582           4133             21            False                 NaN\n",
      "583           4445             22             True  [4569, 4442, 4628]\n",
      "584           4444             22            False                 NaN\n",
      "585           4374             22            False                 NaN\n",
      "586           4375             22            False                 NaN\n",
      "587           4319             22            False                 NaN\n",
      "588           4318             22            False                 NaN\n",
      "589           4370             23             True  [4247, 4493, 4369]\n",
      "590           4371             23            False                 NaN\n",
      "591           4323             23            False                 NaN\n",
      "592           4322             23            False                 NaN\n",
      "593           4229             24             True  [4356, 4100, 4227]\n",
      "594           4230             24            False                 NaN\n",
      "595           4212             24            False                 NaN\n",
      "596           4211             24            False                 NaN\n",
      "597           4103             24            False                 NaN\n",
      "598           4104             24            False                 NaN\n",
      "599           4086             24            False                 NaN\n",
      "600           4085             24            False                 NaN\n",
      "601           4196             25            False                 NaN\n",
      "602           4195             25            False                 NaN\n",
      "603           4194             25            False                 NaN\n",
      "604           4119             25            False                 NaN\n",
      "605           4120             25            False                 NaN\n",
      "606           4121             25            False                 NaN\n",
      "607           4070             25            False                 NaN\n",
      "608           4069             25            False                 NaN\n",
      "609           4068             25            False                 NaN\n",
      "610           3993             25            False                 NaN\n",
      "611           3994             25            False                 NaN\n",
      "612           3995             25            False                 NaN\n",
      "613           3944             25            False                 NaN\n",
      "614           3943             25            False                 NaN\n",
      "615           3942             25            False                 NaN\n",
      "616           3941             25            False                 NaN\n",
      "617           3940             25            False                 NaN\n",
      "618           3868             25            False                 NaN\n",
      "619           3869             25            False                 NaN\n",
      "620           3870             25            False                 NaN\n",
      "621           3871             25            False                 NaN\n",
      "622           3872             25             True  [3869, 3937, 3812]\n",
      "623           3873             25            False                 NaN\n",
      "624           3814             25            False                 NaN\n",
      "625           3813             25            False                 NaN\n",
      "626           3812             25            False                 NaN\n",
      "627           3746             25            False                 NaN\n",
      "628           3747             25            False                 NaN\n",
      "629           3748             25            False                 NaN\n",
      "630           3687             25            False                 NaN\n",
      "631           3686             25            False                 NaN\n",
      "632           3685             25            False                 NaN\n",
      "633           4149             26             True  [4165, 4043, 4294]\n",
      "634           4150             26            False                 NaN\n",
      "635           4040             26            False                 NaN\n",
      "636           4039             26            False                 NaN\n",
      "637           4091             27             True  [3974, 4224, 4100]\n",
      "638           4090             27            False                 NaN\n",
      "639           3972             27            False                 NaN\n",
      "640           3973             27            False                 NaN\n",
      "641           3824             28             True  [3698, 3732, 3609]\n",
      "642           3823             28            False                 NaN\n",
      "643           3735             28            False                 NaN\n",
      "644           3736             28            False                 NaN\n",
      "645           3699             28            False                 NaN\n",
      "646           3698             28            False                 NaN\n",
      "647           3697             28            False                 NaN\n",
      "648           3607             28            False                 NaN\n",
      "649           3608             28            False                 NaN\n",
      "650           3609             28            False                 NaN\n",
      "651           3574             28            False                 NaN\n",
      "652           3573             28            False                 NaN\n",
      "653           3572             28            False                 NaN\n",
      "654           3571             28            False                 NaN\n",
      "655           3483             28            False                 NaN\n",
      "656           3484             28            False                 NaN\n",
      "657           3780             29             True  [3782, 3909, 3778]\n",
      "658           3779             29            False                 NaN\n",
      "659           3770             30             True  [3792, 3893, 3660]\n",
      "660           3771             30            False                 NaN\n",
      "661           3663             30            False                 NaN\n",
      "662           3662             30            False                 NaN\n",
      "663           3661             30            False                 NaN\n",
      "664           3645             30            False                 NaN\n",
      "665           3646             30            False                 NaN\n",
      "666           3585             31            False                 NaN\n",
      "667           3584             31            False                 NaN\n",
      "668           3583             31             True  [3711, 3601, 3460]\n",
      "669           3582             31            False                 NaN\n",
      "670           3581             31            False                 NaN\n",
      "671           3470             31            False                 NaN\n",
      "672           3471             31            False                 NaN\n",
      "673           3472             31            False                 NaN\n",
      "674           3473             31            False                 NaN\n",
      "675           3474             31            False                 NaN\n",
      "676           3475             31            False                 NaN\n",
      "677           3458             31            False                 NaN\n",
      "678           3457             31            False                 NaN\n",
      "679           3456             31            False                 NaN\n",
      "680           3455             31            False                 NaN\n",
      "681           3454             31            False                 NaN\n",
      "682           3347             31            False                 NaN\n",
      "683           3348             31            False                 NaN\n",
      "684           3349             31            False                 NaN\n",
      "685           3499             32             True  [3681, 3624, 3559]\n",
      "686           3500             32            False                 NaN\n",
      "687           3430             32            False                 NaN\n",
      "688           3429             32            False                 NaN\n",
      "689           3464             33             True  [3342, 3462, 3338]\n",
      "690           3463             33            False                 NaN\n",
      "691           3339             33            False                 NaN\n",
      "692           3340             33            False                 NaN\n",
      "693           3405             34            False                 NaN\n",
      "694           3404             34            False                 NaN\n",
      "695           3403             34            False                 NaN\n",
      "696           3402             34            False                 NaN\n",
      "697           3398             34            False                 NaN\n",
      "698           3399             34            False                 NaN\n",
      "699           3400             34            False                 NaN\n",
      "700           3401             34            False                 NaN\n",
      "701           3277             34            False                 NaN\n",
      "702           3276             34            False                 NaN\n",
      "703           3274             34            False                 NaN\n",
      "704           3275             34             True  [3146, 3027, 3276]\n",
      "705           3151             34            False                 NaN\n",
      "706           3150             34            False                 NaN\n",
      "707           3148             34            False                 NaN\n",
      "708           3149             34            False                 NaN\n",
      "709           3024             34            False                 NaN\n",
      "710           3314             35            False                 NaN\n",
      "711           3313             35            False                 NaN\n",
      "712           3237             35            False                 NaN\n",
      "713           3238             35            False                 NaN\n",
      "714           3239             35            False                 NaN\n",
      "715           3240             35            False                 NaN\n",
      "716           3186             35            False                 NaN\n",
      "717           3185             35             True  [3309, 2991, 3111]\n",
      "718           3184             35            False                 NaN\n",
      "719           3114             35            False                 NaN\n",
      "720           3115             35            False                 NaN\n",
      "721           3254             36             True  [3422, 3420, 3126]\n",
      "722           3255             36            False                 NaN\n",
      "723           3256             36            False                 NaN\n",
      "724           3171             36            False                 NaN\n",
      "725           3170             36            False                 NaN\n",
      "726           3169             36            False                 NaN\n",
      "727           3160             37            False                 NaN\n",
      "728           3159             37            False                 NaN\n",
      "729           3158             37            False                 NaN\n",
      "730           3139             37            False                 NaN\n",
      "731           3140             37            False                 NaN\n",
      "732           3141             37             True  [3269, 3284, 2909]\n",
      "733           3142             37            False                 NaN\n",
      "734           3032             37            False                 NaN\n",
      "735           3031             37            False                 NaN\n",
      "736           3015             37            False                 NaN\n",
      "737           3016             37            False                 NaN\n",
      "738           2953             38            False                 NaN\n",
      "739           2952             38            False                 NaN\n",
      "740           2951             38            False                 NaN\n",
      "741           2842             38            False                 NaN\n",
      "742           2843             38            False                 NaN\n",
      "743           2844             38            False                 NaN\n",
      "744           2845             38            False                 NaN\n",
      "745           2826             38            False                 NaN\n",
      "746           2825             38            False                 NaN\n",
      "747           2824             38            False                 NaN\n",
      "748           2716             38            False                 NaN\n",
      "749           2717             38            False                 NaN\n",
      "750           2718             38            False                 NaN\n",
      "751           2719             38            False                 NaN\n",
      "752           2701             38             True  [2587, 2574, 2589]\n",
      "753           2700             38            False                 NaN\n",
      "754           2699             38            False                 NaN\n",
      "755           2698             38            False                 NaN\n",
      "756           2590             38            False                 NaN\n",
      "757           2591             38            False                 NaN\n",
      "758           2592             38            False                 NaN\n",
      "759           2593             38            False                 NaN\n",
      "760           2575             38            False                 NaN\n",
      "761           2574             38            False                 NaN\n",
      "762           2573             38            False                 NaN\n",
      "763           2464             38            False                 NaN\n",
      "764           2465             38            False                 NaN\n",
      "765           2466             38            False                 NaN\n",
      "766           2449             38            False                 NaN\n",
      "767           2448             38            False                 NaN\n",
      "768           2338             38            False                 NaN\n",
      "769           2339             38            False                 NaN\n",
      "770           2323             38            False                 NaN\n",
      "771           2322             38            False                 NaN\n",
      "772           2790             39             True  [3002, 2914, 2627]\n",
      "773           2789             39            False                 NaN\n",
      "774           2753             39            False                 NaN\n",
      "775           2754             39            False                 NaN\n",
      "776           2755             39            False                 NaN\n",
      "777           2664             39            False                 NaN\n",
      "778           2663             39            False                 NaN\n",
      "779           2662             39            False                 NaN\n",
      "780           2658             40            False                 NaN\n",
      "781           2657             40            False                 NaN\n",
      "782           2633             40            False                 NaN\n",
      "783           2634             40            False                 NaN\n",
      "784           2636             40            False                 NaN\n",
      "785           2637             40            False                 NaN\n",
      "786           2532             40            False                 NaN\n",
      "787           2531             40            False                 NaN\n",
      "788           2530             40            False                 NaN\n",
      "789           2529             40            False                 NaN\n",
      "790           2528             40             True  [2404, 2761, 2527]\n",
      "791           2527             40            False                 NaN\n",
      "792           2509             40            False                 NaN\n",
      "793           2510             40            False                 NaN\n",
      "794           2511             40            False                 NaN\n",
      "795           2512             40            False                 NaN\n",
      "796           2513             40            False                 NaN\n",
      "797           2402             40            False                 NaN\n",
      "798           2401             40            False                 NaN\n",
      "799           2400             40            False                 NaN\n",
      "800           2385             40            False                 NaN\n",
      "801           2386             40            False                 NaN\n",
      "802           2387             40            False                 NaN\n",
      "803           2460             41            False                 NaN\n",
      "804           2461             41            False                 NaN\n",
      "805           2453             41             True  [2587, 2208, 2334]\n",
      "806           2452             41            False                 NaN\n",
      "807           2334             41            False                 NaN\n",
      "808           2335             41            False                 NaN\n",
      "809           2477             42            False                 NaN\n",
      "810           2478             42             True  [2434, 2353, 2602]\n",
      "811           2479             42            False                 NaN\n",
      "812           2436             42            False                 NaN\n",
      "813           2435             42            False                 NaN\n",
      "814           2434             42            False                 NaN\n",
      "815           2352             42            False                 NaN\n",
      "816           2353             42            False                 NaN\n",
      "817           2485             43             True  [2554, 2303, 2302]\n",
      "818           2486             43            False                 NaN\n",
      "819           2428             43            False                 NaN\n",
      "820           2427             43            False                 NaN\n",
      "821           2492             44            False                 NaN\n",
      "822           2493             44            False                 NaN\n",
      "823           2421             44            False                 NaN\n",
      "824           2420             44            False                 NaN\n",
      "825           2419             44            False                 NaN\n",
      "826           2366             44            False                 NaN\n",
      "827           2367             44            False                 NaN\n",
      "828           2368             44            False                 NaN\n",
      "829           2295             44            False                 NaN\n",
      "830           2294             44            False                 NaN\n",
      "831           2293             44            False                 NaN\n",
      "832           2292             44            False                 NaN\n",
      "833           2291             44            False                 NaN\n",
      "834           2290             44            False                 NaN\n",
      "835           2240             44            False                 NaN\n",
      "836           2241             44            False                 NaN\n",
      "837           2242             44            False                 NaN\n",
      "838           2243             44            False                 NaN\n",
      "839           2244             44            False                 NaN\n",
      "840           2245             44            False                 NaN\n",
      "841           2178             44            False                 NaN\n",
      "842           2177             44             True  [2303, 2103, 2302]\n",
      "843           2176             44            False                 NaN\n",
      "844           2175             44            False                 NaN\n",
      "845           2173             44            False                 NaN\n",
      "846           2172             44            False                 NaN\n",
      "847           2170             44            False                 NaN\n",
      "848           2169             44            False                 NaN\n",
      "849           2168             44            False                 NaN\n",
      "850           2167             44            False                 NaN\n",
      "851           2166             44            False                 NaN\n",
      "852           2165             44            False                 NaN\n",
      "853           2164             44            False                 NaN\n",
      "854           2105             44            False                 NaN\n",
      "855           2106             44            False                 NaN\n",
      "856           2107             44            False                 NaN\n",
      "857           2108             44            False                 NaN\n",
      "858           2109             44            False                 NaN\n",
      "859           2110             44            False                 NaN\n",
      "860           2111             44            False                 NaN\n",
      "861           2112             44            False                 NaN\n",
      "862           2113             44            False                 NaN\n",
      "863           2114             44            False                 NaN\n",
      "864           2115             44            False                 NaN\n",
      "865           2050             44            False                 NaN\n",
      "866           2049             44            False                 NaN\n",
      "867           2048             44            False                 NaN\n",
      "868           2047             44            False                 NaN\n",
      "869           2046             44            False                 NaN\n",
      "870           2045             44            False                 NaN\n",
      "871           2044             44            False                 NaN\n",
      "872           2043             44            False                 NaN\n",
      "873           2042             44            False                 NaN\n",
      "874           2190             45             True  [2090, 2094, 2217]\n",
      "875           2189             45            False                 NaN\n",
      "876           2093             45            False                 NaN\n",
      "877           2094             45            False                 NaN\n",
      "878           2162             46            False                 NaN\n",
      "879           2161             46            False                 NaN\n",
      "880           2160             46            False                 NaN\n",
      "881           2159             46            False                 NaN\n",
      "882           2121             46             True  [2163, 2119, 2246]\n",
      "883           2122             46            False                 NaN\n",
      "884           2123             46            False                 NaN\n",
      "885           2124             46            False                 NaN\n",
      "886           2036             46            False                 NaN\n",
      "887           2035             46            False                 NaN\n",
      "888           2034             46            False                 NaN\n",
      "889           2033             46            False                 NaN\n",
      "890           1996             46            False                 NaN\n",
      "891           1997             46            False                 NaN\n",
      "892           2056             47             True  [1850, 2103, 2098]\n",
      "893           2055             47            False                 NaN\n",
      "894           1975             47            False                 NaN\n",
      "895           1976             47            False                 NaN\n",
      "896           1930             47            False                 NaN\n",
      "897           1929             47            False                 NaN\n",
      "898           1849             47            False                 NaN\n",
      "899           1850             47            False                 NaN\n",
      "900           1902             48             True  [2027, 1778, 1748]\n",
      "901           1901             48            False                 NaN\n",
      "902           1877             48            False                 NaN\n",
      "903           1878             48            False                 NaN\n",
      "904           1824             49             True  [1956, 1958, 1947]\n",
      "905           1823             49            False                 NaN\n",
      "906           1703             49            False                 NaN\n",
      "907           1704             49            False                 NaN\n",
      "908           1710             50             True  [1566, 1583, 1712]\n",
      "909           1711             50            False                 NaN\n",
      "910           1691             50            False                 NaN\n",
      "911           1690             50            False                 NaN\n",
      "912           1584             50            False                 NaN\n",
      "913           1585             50            False                 NaN\n",
      "914           1687             51            False                 NaN\n",
      "915           1686             51            False                 NaN\n",
      "916           1588             51            False                 NaN\n",
      "917           1589             51             True  [1712, 1810, 1713]\n",
      "918           1590             51            False                 NaN\n",
      "919           1591             51            False                 NaN\n",
      "920           1592             51            False                 NaN\n",
      "921           1561             51            False                 NaN\n",
      "922           1560             51            False                 NaN\n",
      "923           1559             51            False                 NaN\n",
      "924           1558             51            False                 NaN\n",
      "925           1557             51            False                 NaN\n",
      "926           1556             51            False                 NaN\n",
      "927           1555             51            False                 NaN\n",
      "928           1462             51            False                 NaN\n",
      "929           1463             51            False                 NaN\n",
      "930           1464             51            False                 NaN\n",
      "931           1465             51            False                 NaN\n",
      "932           1466             51            False                 NaN\n",
      "933           1467             51            False                 NaN\n",
      "934           1468             51            False                 NaN\n",
      "935           1433             51            False                 NaN\n",
      "936           1432             51            False                 NaN\n",
      "937           1431             51            False                 NaN\n",
      "938           1430             51            False                 NaN\n",
      "939           1339             51            False                 NaN\n",
      "940           1340             51            False                 NaN\n",
      "941           1341             51            False                 NaN\n",
      "942           1650             52            False                 NaN\n",
      "943           1649             52            False                 NaN\n",
      "944           1625             52            False                 NaN\n",
      "945           1626             52             True  [1623, 1624, 1628]\n",
      "946           1627             52            False                 NaN\n",
      "947           1524             52            False                 NaN\n",
      "948           1523             52            False                 NaN\n",
      "949           1522             52            False                 NaN\n",
      "950           1550             53             True  [1552, 1597, 1596]\n",
      "951           1549             53            False                 NaN\n",
      "952           1473             53            False                 NaN\n",
      "953           1474             53            False                 NaN\n",
      "954           1475             53            False                 NaN\n",
      "955           1423             53            False                 NaN\n",
      "956           1422             53            False                 NaN\n",
      "957           1348             53            False                 NaN\n",
      "958           1349             53            False                 NaN\n",
      "959           1383             54             True  [1265, 1516, 1264]\n",
      "960           1384             54            False                 NaN\n",
      "961           1262             54            False                 NaN\n",
      "962           1261             54            False                 NaN\n",
      "963           1257             54            False                 NaN\n",
      "964           1258             54            False                 NaN\n",
      "965           1139             54            False                 NaN\n",
      "966           1138             54            False                 NaN\n",
      "967           1137             54            False                 NaN\n",
      "968           1136             54            False                 NaN\n",
      "969           1135             54            False                 NaN\n",
      "970           1128             54            False                 NaN\n",
      "971           1129             54            False                 NaN\n",
      "972           1130             54            False                 NaN\n",
      "973           1236             55             True  [1406, 1109, 1028]\n",
      "974           1237             55            False                 NaN\n",
      "975           1157             55            False                 NaN\n",
      "976           1156             55            False                 NaN\n",
      "977           1110             55            False                 NaN\n",
      "978           1111             55            False                 NaN\n",
      "979           1029             55            False                 NaN\n",
      "980           1028             55            False                 NaN\n",
      "981            986             55            False                 NaN\n",
      "982            987             55            False                 NaN\n",
      "983           1170             56             True   [970, 1293, 1095]\n",
      "984           1169             56            False                 NaN\n",
      "985           1096             56            False                 NaN\n",
      "986           1097             56            False                 NaN\n",
      "987           1098             56            False                 NaN\n",
      "988           1045             56            False                 NaN\n",
      "989           1044             56            False                 NaN\n",
      "990           1043             56            False                 NaN\n",
      "991            970             56            False                 NaN\n",
      "992            971             56            False                 NaN\n",
      "993            972             56            False                 NaN\n",
      "994           1056             57            False                 NaN\n",
      "995           1055             57            False                 NaN\n",
      "996            957             57            False                 NaN\n",
      "997            958             57            False                 NaN\n",
      "998            959             57            False                 NaN\n",
      "999            960             57            False                 NaN\n",
      "1000           932             57            False                 NaN\n",
      "1001           931             57            False                 NaN\n",
      "1002           930             57            False                 NaN\n",
      "1003           831             57            False                 NaN\n",
      "1004           832             57             True     [929, 960, 835]\n",
      "1005           833             57            False                 NaN\n",
      "1006           806             57            False                 NaN\n",
      "1007           805             57            False                 NaN\n",
      "1008           804             57            False                 NaN\n",
      "1009           706             57            False                 NaN\n",
      "1010           707             57            False                 NaN\n",
      "1011           708             57            False                 NaN\n",
      "1012           678             57            False                 NaN\n",
      "1013           677             57            False                 NaN\n",
      "1014           945             58            False                 NaN\n",
      "1015           946             58            False                 NaN\n",
      "1016           947             58             True    [820, 819, 1193]\n",
      "1017           948             58            False                 NaN\n",
      "1018           944             58            False                 NaN\n",
      "1019           943             58            False                 NaN\n",
      "1020           942             58            False                 NaN\n",
      "1021           941             58            False                 NaN\n",
      "1022           940             58            False                 NaN\n",
      "1023           939             58            False                 NaN\n",
      "1024           819             58            False                 NaN\n",
      "1025           820             58            False                 NaN\n",
      "1026           821             58            False                 NaN\n",
      "1027           822             58            False                 NaN\n",
      "1028           823             58            False                 NaN\n",
      "1029           824             58            False                 NaN\n",
      "1030           815             58            False                 NaN\n",
      "1031           814             58            False                 NaN\n",
      "1032           813             58            False                 NaN\n",
      "1033           696             58            False                 NaN\n",
      "1034           697             58            False                 NaN\n",
      "1035           698             58            False                 NaN\n",
      "1036           998             59            False                 NaN\n",
      "1037           999             59            False                 NaN\n",
      "1038           893             59            False                 NaN\n",
      "1039           892             59            False                 NaN\n",
      "1040           891             59             True    [746, 745, 1014]\n",
      "1041           890             59            False                 NaN\n",
      "1042           870             59            False                 NaN\n",
      "1043           871             59            False                 NaN\n",
      "1044           872             59            False                 NaN\n",
      "1045           873             59            False                 NaN\n",
      "1046           874             59            False                 NaN\n",
      "1047           764             59            False                 NaN\n",
      "1048           763             59            False                 NaN\n",
      "1049           857             60            False                 NaN\n",
      "1050           858             60            False                 NaN\n",
      "1051           780             60            False                 NaN\n",
      "1052           779             60            False                 NaN\n",
      "1053           778             60            False                 NaN\n",
      "1054           777             60            False                 NaN\n",
      "1055           776             60            False                 NaN\n",
      "1056           733             60            False                 NaN\n",
      "1057           734             60             True     [862, 863, 861]\n",
      "1058           735             60            False                 NaN\n",
      "1059           736             60            False                 NaN\n",
      "1060           652             60            False                 NaN\n",
      "1061           651             60            False                 NaN\n",
      "1062           650             60            False                 NaN\n",
      "1063           649             60            False                 NaN\n",
      "1064           608             60            False                 NaN\n",
      "1065           609             60            False                 NaN\n",
      "1066           610             60            False                 NaN\n",
      "1067           524             60            False                 NaN\n",
      "1068           523             60            False                 NaN\n",
      "1069           718             61            False                 NaN\n",
      "1070           719             61            False                 NaN\n",
      "1071           667             61            False                 NaN\n",
      "1072           666             61            False                 NaN\n",
      "1073           591             61            False                 NaN\n",
      "1074           592             61            False                 NaN\n",
      "1075           593             61            False                 NaN\n",
      "1076           542             61            False                 NaN\n",
      "1077           541             61            False                 NaN\n",
      "1078           540             61            False                 NaN\n",
      "1079           466             61            False                 NaN\n",
      "1080           467             61            False                 NaN\n",
      "1081           421             61            False                 NaN\n",
      "1082           420             61            False                 NaN\n",
      "1083           419             61            False                 NaN\n",
      "1084           415             61            False                 NaN\n",
      "1085           414             61            False                 NaN\n",
      "1086           334             61            False                 NaN\n",
      "1087           335             61             True     [461, 459, 421]\n",
      "1088           336             61            False                 NaN\n",
      "1089           337             61            False                 NaN\n",
      "1090           340             61            False                 NaN\n",
      "1091           341             61            False                 NaN\n",
      "1092           294             61            False                 NaN\n",
      "1093           293             61            False                 NaN\n",
      "1094           292             61            False                 NaN\n",
      "1095           291             61            False                 NaN\n",
      "1096           290             61            False                 NaN\n",
      "1097           288             61            False                 NaN\n",
      "1098           287             61            False                 NaN\n",
      "1099           211             61            False                 NaN\n",
      "1100           212             61            False                 NaN\n",
      "1101           213             61            False                 NaN\n",
      "1102           214             61            False                 NaN\n",
      "1103           215             61            False                 NaN\n",
      "1104           216             61            False                 NaN\n",
      "1105           217             61            False                 NaN\n",
      "1106           163             61            False                 NaN\n",
      "1107           162             61            False                 NaN\n",
      "1108           161             61            False                 NaN\n",
      "1109           160             61            False                 NaN\n",
      "1110           159             61            False                 NaN\n",
      "1111           158             61            False                 NaN\n",
      "1112            91             61            False                 NaN\n",
      "1113            92             61            False                 NaN\n",
      "1114            93             61            False                 NaN\n",
      "1115            33             61            False                 NaN\n",
      "1116            32             61            False                 NaN\n",
      "1117           622             62            False                 NaN\n",
      "1118           623             62            False                 NaN\n",
      "1119           513             62            False                 NaN\n",
      "1120           512             62             True     [619, 639, 514]\n",
      "1121           511             62            False                 NaN\n",
      "1122           510             62            False                 NaN\n",
      "1123           494             62            False                 NaN\n",
      "1124           495             62            False                 NaN\n",
      "1125           496             62            False                 NaN\n",
      "1126           556             63            False                 NaN\n",
      "1127           555             63            False                 NaN\n",
      "1128           451             63            False                 NaN\n",
      "1129           452             63            False                 NaN\n",
      "1130           431             63            False                 NaN\n",
      "1131           430             63            False                 NaN\n",
      "1132           429             63            False                 NaN\n",
      "1133           324             63             True     [323, 180, 196]\n",
      "1134           325             63            False                 NaN\n",
      "1135           326             63            False                 NaN\n",
      "1136           304             63            False                 NaN\n",
      "1137           303             63            False                 NaN\n",
      "1138           199             63            False                 NaN\n",
      "1139           200             63            False                 NaN\n",
      "1140           201             63            False                 NaN\n",
      "1141           177             63            False                 NaN\n",
      "1142           176             63            False                 NaN\n",
      "1143            74             63            False                 NaN\n",
      "1144            75             63            False                 NaN\n",
      "1145           347             64            False                 NaN\n",
      "1146           348             64            False                 NaN\n",
      "1147           349             64            False                 NaN\n",
      "1148           282             64            False                 NaN\n",
      "1149           281             64            False                 NaN\n",
      "1150           280             64            False                 NaN\n",
      "1151           279             64            False                 NaN\n",
      "1152           222             64            False                 NaN\n",
      "1153           223             64            False                 NaN\n",
      "1154           224             64            False                 NaN\n",
      "1155           155             64            False                 NaN\n",
      "1156           154             64             True      [279, 95, 156]\n",
      "1157           153             64            False                 NaN\n",
      "1158            96             64            False                 NaN\n",
      "1159            97             64            False                 NaN\n",
      "1160            98             64            False                 NaN\n",
      "1161            29             64            False                 NaN\n",
      "1162            28             64            False                 NaN\n",
      "1163            27             64            False                 NaN\n",
      "1164           237             65             True     [390, 263, 265]\n",
      "1165           238             65            False                 NaN\n",
      "1166           140             65            False                 NaN\n",
      "1167           139             65            False                 NaN\n",
      "1168           143             66            False                 NaN\n",
      "1169           142             66             True     [235, 270, 107]\n",
      "1170           108             66            False                 NaN\n",
      "1171           109             66            False                 NaN\n",
      "1172            78             67            False                 NaN\n",
      "1173            79             67            False                 NaN\n",
      "1174            80             67            False                 NaN\n",
      "1175            81             67            False                 NaN\n",
      "1176            47             67            False                 NaN\n",
      "1177            46             67            False                 NaN\n",
      "1178            45             67             True        [83, 77, 79]\n",
      "1179            44             67            False                 NaN\n",
      "1180            43             67            False                 NaN\n",
      "1181           122             68             True     [253, 257, 252]\n",
      "1182           123             68            False                 NaN\n",
      "1183             3             68            False                 NaN\n",
      "1184             2             68            False                 NaN\n",
      "csv file generated in  /Users/bashit.a/Documents/Alzheimer/July-2021/BNL-Data/sorted\n",
      "finished in 3875.0 minutes and 57.95636154100066 seconds\n"
     ]
    }
   ],
   "source": [
    "### find heatmap using (I_p - I_avg) -- MultiThreating Processing\n",
    "%matplotlib widget\n",
    "import concurrent.futures\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "#### specs - plaques search\n",
    "file = '1892_EC-roi0_masked.h5' # '2048_B8_masked.h5' # '2109_EC-roi0_masked.h5' # '1892_EC-roi0_masked.h5' # '2512_EC-roi1_masked.h5' # '2029_Dentate_gyrus-roi0_masked.h5'    # '2029_EC-roi0.h5'    '2029_Dentate_gyrus-roi0_masked.h5'  '2048_B8_masked.h5'\n",
    "bkg_frame                  = [7321, 7042] # [7045,7046] # 973        [3684, 3685]      # background frame\n",
    "\n",
    "window_size    = 4     # 4 point averaging\n",
    "normalize_at_q = 1.34  # normalizing at this q\n",
    "peak_q         = 1.34  # Ipeak at q\n",
    "first_avg_q    = 1.15  # left q from Ipeak to be averaged\n",
    "second_avg_q   = 1.47  # right q from Ipeak to be averaged\n",
    "n_calc_frames  = 1600   # get the highest 500 frames\n",
    "opening_kernel = 2     # 2x2 kernel for morphological operation\n",
    "n_tissue_frms  = 3     # kernal outputs best 3 potential tissue frames\n",
    "mf_max = 2.5           # mf must be less than this value\n",
    "mf_min = 1.0           # mf must be greater than this value\n",
    "\n",
    "#### specs - tissues search\n",
    "QSearchStart, QSearchEnd   = 1.55, 1.8                      # scaling regions 295,310 or may be 290,370    1.55, 1.8 \n",
    "seek_mf                    = (-12,12,0.01)                  # mf goes from -8 to +8 by 0.01\n",
    "kernal_size                = 7;                             # kernal 7 - 48 frames surrounded by plaque frame\n",
    "area_minQ = 1.0                                             # min area to search q\n",
    "area_maxQ = 1.45                                            # max area to search q\n",
    "cmap = \"jet\"\n",
    "tissue_frs_find_alg = 'one-fr-one-cluster'    # 'one-fr-one-cluster'   'all-frs-one-cluster'\n",
    "\n",
    "### computations\n",
    "### Ipeak - (Iq1+Iq2)/2 calcuations for potential frames\n",
    "data = Data_Analysis(file, qgrid2, window_size=4, normalize=False, normalize_at_q=normalize_at_q ,directory=os.getcwd())\n",
    "Iq   = data.bkg_sub(bkg_frame = bkg_frame)\n",
    "\n",
    "npatterns = Iq.shape[0]\n",
    "result = {}; result['diff'] = np.zeros(npatterns) # result['diff'].shape - (7812,)\n",
    "for frame in range(npatterns):\n",
    "    result['diff'][frame] = Iq[frame, qgrid_to_indices(qgrid2, peak_q)] - (Iq[frame, qgrid_to_indices(qgrid2, first_avg_q)]+Iq[frame, qgrid_to_indices(qgrid2, second_avg_q)])/2\n",
    "potential_plaques = np.argsort(result['diff'],axis= None, kind='stable')[::-1][:n_calc_frames]\n",
    "\n",
    "### morpholocal operations\n",
    "Width, Height = width_height(file)\n",
    "sna = snaking(Width, Height)\n",
    "A_MAT = np.array([np.zeros((Height,Width)),sna])   # zero values matrix (A[0]=0) with frame numbers depth (A[1]=frames)\n",
    "A = from_clusterFr_ceffs_to_matrix(A_MAT, potential_plaques, np.ones(len(potential_plaques)))\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(nrows=1, ncols=3, figsize=(17,6))\n",
    "plot_heat_map_from_data(A[0], Width, Height, args = (fig, ax1), title= f'original - frames-{n_calc_frames}', cmap=cmap)\n",
    "mask,_ = global_thresholding(A[0], thr=1, binary_inv = False)\n",
    "_, mask = cv2.threshold(A[0], 0, 255, cv2.THRESH_BINARY)\n",
    "kernal = np.ones((opening_kernel,opening_kernel), np.uint8)\n",
    "opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernal)\n",
    "\n",
    "### clustering variable declarations\n",
    "labeled_array, num_features = label(opening, np.ones((3,3)))\n",
    "print('Total clusters = ', num_features)\n",
    "\n",
    "#### get clusters --> len(clusters)=175\n",
    "clusters = []\n",
    "cluster_label = []\n",
    "for i in np.arange(1,num_features+1,1):  # zero label is for background, rest labels are for clusters\n",
    "    _ = sna[labeled_array==i]\n",
    "    clusters.append(_.tolist())\n",
    "    cluster_label.append(len(_)*[i])\n",
    "clusters = flatten(clusters)\n",
    "cluster_label = flatten(cluster_label)\n",
    "\n",
    "### pandas setting to ignore warning\n",
    "pd.options.display.max_columns  = None\n",
    "pd.options.display.max_rows     = None\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "### declaring variable\n",
    "df = pd.DataFrame(columns=['plaque-frame', 'cluster-label' ,'selected-plaque', \\\n",
    "                           'tissue-frames', 'tissue-frames-all', 'tissue-frames-mf', 'tissue-frames-area', \\\n",
    "                           'IqBSTF', 'IqBSTS'], index=np.arange(0,len(clusters),1))\n",
    "df['plaque-frame'] = clusters\n",
    "df['cluster-label'] = cluster_label\n",
    "\n",
    "### find the representative frame from each cluster\n",
    "df['selected-plaque'] = False                           # initilizing to False\n",
    "for i in np.arange(1, num_features+1,1):\n",
    "    cluster_frames = df['plaque-frame'][df['cluster-label']==i].values   # frames in each cluster\n",
    "    cluster_max_frame = cluster_frames[np.argmax(result['diff'][cluster_frames])]\n",
    "    df.loc[df.index[df['plaque-frame'] == cluster_max_frame],'selected-plaque'] = True # True only if the frame is the maximum in a cluster\n",
    "# print(df.loc[df.index[df['selected-plaque']==True], 'plaque-frame'])\n",
    "\n",
    "### kernal sliding and getting background frames\n",
    "fr_idx = Snaking_frames_search(Width, Height)   # kernal frame search class\n",
    "\n",
    "# def kernal_mp(idx, frame):                                  #### uncomment to parallelize\n",
    "# frames_to_look_for_tissue = df.loc[df.index[df['selected-plaque'] == True], \"plaque-frame\"].values;  ### peak frames in clusters only - 30 frames for 30 clusters\n",
    "frames_to_look_for_tissue = df[\"plaque-frame\"].values                                                ### all frames in a cluster\n",
    "for idx, frame in enumerate(frames_to_look_for_tissue):       #### comment out to parallelize\n",
    "\n",
    "    if tissue_frs_find_alg == 'one-fr-one-cluster' and df['selected-plaque'][idx] == False:\n",
    "        continue;\n",
    "    elif tissue_frs_find_alg == 'all-frs-one-cluster':\n",
    "        pass;\n",
    "\n",
    "    ### kernal sliding and getting tissue frames\n",
    "    tissue_frames = np.array(fr_idx.frame_idx_to_kernal_frames(kernal_size, frame))  # kernal tissue frames\n",
    "\n",
    "    ### declare variable\n",
    "    mf   = np.full(npatterns,np.nan);   # do not trust mf - nearby mf (two cluster same frame) is overwritten\n",
    "    area = np.full(npatterns,np.nan);   # do not trust area - nearby area (two cluster same frame) is overwritten\n",
    "\n",
    "    ### get tissues\n",
    "    area_temp = np.zeros(len(tissue_frames))\n",
    "    for i,tissue_frame in enumerate(tissue_frames):\n",
    "        mf[tissue_frame], area_temp[i],_,_ = data.tissue_sub(frame, tissue_frame, scale_method = 'MSE', return_alg = 'one_tissue-fr' , \\\n",
    "                                                            area_minQ= area_minQ, area_maxQ = area_maxQ, mf_Qindices = (QSearchStart, QSearchEnd), \\\n",
    "                                                            seek_mf = seek_mf, mf_min=mf_min, mf_max=mf_max , \\\n",
    "                                                            window_size=None, show_result=False);\n",
    "        area[tissue_frame] = area_temp[i]\n",
    "\n",
    "    tissue_frames_sorted = tissue_frames[np.argsort(area_temp, axis= None, kind='stable')[::-1] ] # descending order\n",
    "    tissue_pot = []\n",
    "    for pot_tissue in tissue_frames_sorted :\n",
    "        if mf[pot_tissue] <mf_max and mf[pot_tissue] > mf_min :\n",
    "            tissue_pot.append(pot_tissue)\n",
    "        if len(tissue_pot)==n_tissue_frms:\n",
    "            break\n",
    "    if len(tissue_pot) == 0:\n",
    "        print('no tissue found for frame - ',frame, ' ; thus dropping this frame ->', np.array(tissue_pot))\n",
    "        df.drop(index=idx, inplace=True)\n",
    "        continue;\n",
    "    df['tissue-frames-all'][idx]  = tissue_frames_sorted\n",
    "    df['tissue-frames'][idx]      = np.array(tissue_pot)  \n",
    "    df['tissue-frames-mf'][idx]   = [mf[tissue_frame]   for tissue_frame in df['tissue-frames'][idx]]\n",
    "    df['tissue-frames-area'][idx] = [area[tissue_frame] for tissue_frame in df['tissue-frames'][idx]]\n",
    "    \n",
    "    df['IqBSTF'][idx], df['IqBSTS'][idx] = data.tissue_sub(frame, df['tissue-frames'][idx], scale_method = 'MSE', return_alg = 'multi_tissue-fr' , \\\n",
    "                                                    area_minQ= area_minQ, area_maxQ = area_maxQ, mf_Qindices = (QSearchStart, QSearchEnd), \\\n",
    "                                                    seek_mf = seek_mf, mf_min=mf_min, mf_max=mf_max , \\\n",
    "                                                    window_size=window_size, show_result=False);\n",
    "    df['IqBSTS'][idx] = df['IqBSTS'][idx].flatten()\n",
    "    df['IqBSTF'][idx] = df['IqBSTF'][idx].flatten()\n",
    "\n",
    "#### uncomment to parallelize\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=None) as executor:\n",
    "#     results = executor.map(kernal_mp, np.arange(len(df[\"plaque-frame\"].values)), df[\"plaque-frame\"].values)\n",
    "\n",
    "### resetting indices as some frames might have dropped\n",
    "df.reset_index(drop=True,inplace=True)  # drop parameter to avoid the old index being added as a column\n",
    "\n",
    "### plot truncated tissues on top of opening images - (clustering results same as opening)\n",
    "A_MAT = np.array([np.zeros((Height,Width)),sna])   # zero values matrix (A[0]=0) with frame numbers depth (A[1]=frames)\n",
    "B = from_clusterFr_ceffs_to_matrix(A_MAT, cluster=df['plaque-frame'], coeffs=np.full_like(df['plaque-frame'], 255, dtype=int))\n",
    "plot_heat_map_from_data(B[0], Width, Height, args = (fig, ax2), title= f'clustered total frames-{len(df[\"plaque-frame\"])}', cmap=cmap)\n",
    "\n",
    "tissues = []\n",
    "[tissues.append(i.tolist()) for i in df['tissue-frames'].values.tolist() if np.any(np.isnan(i)) == False]  ### for selctive case run only NOT nan frames\n",
    "tissues = np.unique(flatten(tissues))\n",
    "A_MAT = np.array([np.zeros((Height,Width)),sna])   # zero values matrix (A[0]=0) with frame numbers depth (A[1]=frames)\n",
    "C = from_clusterFr_ceffs_to_matrix(A_MAT, cluster= tissues, coeffs=np.full_like(tissues, 127, dtype=int))\n",
    "plot_heat_map_from_data(B[0]+C[0], Width, Height, args = (fig, ax3), title= f'norm. and peak find at q{peak_q}', cmap=cmap)\n",
    "\n",
    "plt.suptitle(file)\n",
    "plt.tight_layout()\n",
    "\n",
    "#### Scroll through frames\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "start, end = 130, 490                                       # ipywidget plot and classifer\n",
    "\n",
    "### X array-like of shape (n_samples, n_features)\n",
    "X = np.zeros((len(df), len(qgrid2)))\n",
    "for idx in range(len(df)):\n",
    "    X[idx,:] = df['IqBSTF'][idx]\n",
    "X = StandardScaler().fit_transform(X)  # Standard Scalar\n",
    "X = X[:,start:end]                     # X is what you see on plt\n",
    "\n",
    "### ipywidget plot\n",
    "plt.figure(num=file)\n",
    "def plaque_bkg_plots(index):\n",
    "    plaque = df['plaque-frame'].loc[index]\n",
    "    plt.cla()\n",
    "    plt.plot(data.qgrid[start:end], data.Iq[plaque][start:end],          label = 'Iq'    )\n",
    "    plt.plot(data.qgrid[start:end], data.IqBS[plaque][start:end],        label = 'IqBS'  )\n",
    "    plt.plot(data.qgrid[start:end], df['IqBSTF'].loc[index][start:end],  label = 'IqBSTF')\n",
    "    plt.plot(data.qgrid[start:end], df['IqBSTS'].loc[index][start:end],  label = 'IqBSTS')\n",
    "    plt.legend()\n",
    "    plt.title(f'plaque-fr-{plaque}, group-{df[\"cluster-label\"][index]}, index:{index}')\n",
    "    #plt.axis([None,None,None,0.12*10**6])\n",
    "\n",
    "plt.tight_layout()\n",
    "    \n",
    "if tissue_frs_find_alg == 'one-fr-one-cluster' :\n",
    "    scroll_frames = df.index[df['selected-plaque'] == True]   # df.index[df['selected-plaque'] == True]    # df.index.values\n",
    "elif tissue_frs_find_alg == 'all-frs-one-cluster' :\n",
    "    scroll_frames = df.index.values   # df.index[df['selected-plaque'] == True]    # df.index.values\n",
    "\n",
    "index = ipywidgets.SelectionSlider(value = scroll_frames[0], options = scroll_frames)\n",
    "ipywidgets.interact(plaque_bkg_plots, index=index)\n",
    "\n",
    "#### display dataframe\n",
    "print(df.iloc[:,:4])\n",
    "\n",
    "### create csv file\n",
    "print('csv file generated in ',os.getcwd())\n",
    "df.to_csv('result.csv')\n",
    "\n",
    "finish = time.perf_counter();    print(f'finished in {(finish-start)//60} minutes and {(finish-start)%60} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "loved-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing two duplicate dataframe, result is empty table\n",
    "df1 = pd.read_csv('result.csv')\n",
    "df2 = pd.read_csv('result-now.csv')\n",
    "pd.concat([df1,df2]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "terminal-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>plaque-frame</th>\n",
       "      <th>cluster-label</th>\n",
       "      <th>selected-plaque</th>\n",
       "      <th>tissue-frames</th>\n",
       "      <th>tissue-frames-mf</th>\n",
       "      <th>tissue-frames-area</th>\n",
       "      <th>IqBSTF</th>\n",
       "      <th>IqBSTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, plaque-frame, cluster-label, selected-plaque, tissue-frames, tissue-frames-mf, tissue-frames-area, IqBSTF, IqBSTS]\n",
       "Index: []"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = 21\n",
    "\n",
    "\n",
    "cluster_frames = df['plaque-frame'][df['cluster-label']==4434].values   # frames in each cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "found-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7388 7373 6895 6068 5422 5271 4517 3993 3275 2177 1710 1589 1097  832\n",
      "  734  420   45]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd8422b046d4c0a8b1113026f32ca81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61c45caffe24d1e8ef2b950be007c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='frame', options=(6068, 6895, 7388, 5422, 1710, 2177, 4517, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40000000000000024 2.200000000000002\n"
     ]
    }
   ],
   "source": [
    "#### 1d plot for peak frames in each cluster\n",
    "%matplotlib widget\n",
    "\n",
    "peak_fr_in_cluster = df.iloc[df.index[df['selected-plaque']==True]]['plaque-frame'].values\n",
    "print(peak_fr_in_cluster)\n",
    "# print(peak_fr_in_cluster )\n",
    "sorted_peak_fr_in_cluster = peak_fr_in_cluster[np.argsort(np.nanmax(Iq[peak_fr_in_cluster,start:end], axis=1))[::-1]]  #hightest to lowest\n",
    "\n",
    "plt.figure()\n",
    "def plot(frame):\n",
    "    plt.cla()\n",
    "    plt.plot(qgrid2[start:end], Iq[frame,start:end])\n",
    "\n",
    "slider = ipywidgets.SelectionSlider(value=sorted_peak_fr_in_cluster[0], options=sorted_peak_fr_in_cluster)\n",
    "ipywidgets.interact(plot, frame = slider)\n",
    "print(qgrid2[start], qgrid2[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cutting-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/39767612/what-is-the-equivalent-of-matlabs-imadjust-in-python\n",
    "def imadjust(x,a,b,c,d,gamma=1):\n",
    "    # Similar to imadjust in MATLAB.\n",
    "    # Converts an image range from [a,b] to [c,d].\n",
    "    # The Equation of a line can be used for this transformation:\n",
    "    #   y=((d-c)/(b-a))*(x-a)+c\n",
    "    # However, it is better to use a more generalized equation:\n",
    "    #   y=((x-a)/(b-a))^gamma*(d-c)+c\n",
    "    # If gamma is equal to 1, then the line equation is used.\n",
    "    # When gamma is not equal to 1, then the transformation is not linear.\n",
    "\n",
    "    y = (((x - a) / (b - a)) ** gamma) * (d - c) + c\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "completed-smart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file generated in  /Users/bashit.a/Documents/Alzheimer/July-2021/BNL-Data/sample-6\n"
     ]
    }
   ],
   "source": [
    "### KMeans model\n",
    "def train_KMeans(X,n_clusters):\n",
    "    kmeans = KMeans(init=\"k-means++\", n_clusters=n_clusters, n_init=4)\n",
    "    kmeans.fit(X)\n",
    "    labels = kmeans.predict(X)\n",
    "    return labels\n",
    "labels = train_KMeans(X, n_clusters=2)\n",
    "df['KMeans'] = labels\n",
    "\n",
    "### GMM model\n",
    "def train_GMM(X, n_components):\n",
    "    from sklearn.mixture import GaussianMixture               # import package\n",
    "    gaussian_model = GaussianMixture(n_components=n_components)          # define the model\n",
    "    gaussian_model.fit(X)                                     # train the model\n",
    "    labels = gaussian_model.predict(X)                        # assign each data point to a cluster\n",
    "    return labels\n",
    "\n",
    "# labels = train_GMM(X, n_components=2)\n",
    "# df['GMM'] = labels\n",
    "\n",
    "### Affinity Model\n",
    "def train_Affinity(X):\n",
    "    af = AffinityPropagation(preference=-20000, random_state=0).fit(X)\n",
    "    cluster_centers_indices = af.cluster_centers_indices_\n",
    "    print('number of clusters - ', len(cluster_centers_indices))\n",
    "    labels = af.labels_\n",
    "    return labels\n",
    "\n",
    "# labels = train_Affinity(X)\n",
    "# df = df.assign(Affinity=labels)\n",
    "\n",
    "print('csv file generated in ',os.getcwd())\n",
    "df.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "southeast-trout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e890608fc1d4902be4fec48dbdb69d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "plot_heat_map_from_data(B[0], Width, Height, args = (fig, ax1), title= f'clustered - frames-{len(df[\"plaque-frame\"])}', cmap=cmap)\n",
    "\n",
    "A_MAT = np.array([np.zeros((Height,Width)),sna])   # zero values matrix (A[0]=0) with frame numbers depth (A[1]=frames)\n",
    "D = from_clusterFr_ceffs_to_matrix(A_MAT, cluster=df['plaque-frame'].values.astype(np.uint32), coeffs=np.uint8(imadjust(labels,labels.min(),labels.max(),0,255)))\n",
    "plot_heat_map_from_data(D[0], Width, Height, args = (fig, ax2), title= f'classifier categories-{len(np.unique(labels))}', cmap=cmap)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dominant-sitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7749, 7750, 7751, ..., 7809, 7810, 7811],\n",
       "       [7748, 7747, 7746, ..., 7688, 7687, 7686],\n",
       "       [7623, 7624, 7625, ..., 7683, 7684, 7685],\n",
       "       ...,\n",
       "       [ 188,  187,  186, ...,  128,  127,  126],\n",
       "       [  63,   64,   65, ...,  123,  124,  125],\n",
       "       [  62,   61,   60, ...,    2,    1,    0]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "reasonable-awareness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb6d8a79c4c4de9a9fbc2f8c3ddd562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAHPNtZGF0AAACsAYF//+s\n",
       "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MSByMzAzME0gOGJkNmQyOCAtIEguMjY0L01Q\n",
       "RUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMjAgLSBodHRwOi8vd3d3LnZpZGVvbGFu\n",
       "Lm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5h\n",
       "bHlzZT0weDM6MHgxMTMgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhl\n",
       "ZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTEgY3FtPTAg\n",
       "ZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9LTIgdGhyZWFkcz0x\n",
       "MiBsb29rYWhlYWRfdGhyZWFkcz0yIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGlu\n",
       "dGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMg\n",
       "Yl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dv\n",
       "cD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MTAgc2NlbmVjdXQ9NDAgaW50cmFf\n",
       "cmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9\n",
       "MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAA\n",
       "AAm2ZYiEABH//veIHzLLafk613IR560urR9Q7kZxXqS9/iAAAAMAAAMAAGVA3ylQf3lw3OAAAATw\n",
       "ALu6VJo7BbAY+IAq1v+UCCw8ArMC4BdPZZaVyddhj40bRKyG7Yc1ViK+eKVMrjzwmwr6H1yL6U/B\n",
       "Iaml+VIqUnMd14BLOmylRL33+BmOIb90GeMcxhW9Y5DH4x3/zMU91dOVx5sObMmhm1FnllISoPKF\n",
       "h/DVUPQMXDjVCE0qxy1vk6QpUhPpoLGJnS/XI6ZXclS6K0aFTJ+BgMsvTkaL9mEn8mW+JZR9W/lf\n",
       "Dg7ZS/oKFT2siAHj3lBIRmuOO8RFJmUOFi71gOyM0au/m0ZdnLvVfeSGtfyTifVWWUmdVJ2R9SZZ\n",
       "h4JdBFJi0kPq1TZ9c0HxulWghVFw8jhAYaaxOSx8HH9SHj0qAkGBZF0Lvzb14Ps2LBDw1nhR9JB6\n",
       "sJUEg4S0mtz16Gja3J4UpIWYOgz17HB+tvCHY8wZ6OCxea3jjGr8GaVNIVfZckfWLAq2un4VSCFo\n",
       "ZNTjx6sSZBGtgg2B1cTE+laS9H0d6JwIpawZu/LHZYof+ZXuGsCC5icwNLjNPinrVQCuyDAFLq55\n",
       "jxIxKuWu7vSRttivGrjjmVwHk45aJchza66cryAAsKF3Jmtog7Xd69PhJY3KKcrfQf6zWXB9q/i7\n",
       "tCxbeJaqInxZHXK5zosaqacWWqT3DvnpJyijntIG/H0KKYBKqoVdcieDb39KJZh4d1PrfMrX/A6v\n",
       "Rwnscy7+W7QRDs8Phg2oFlw4+07jdB0UKdaXVxHhljH1MreUBRHjPFL5MgM9ViCeo4ijiu8IornU\n",
       "7sHMW85tWw4gqqsaViULObb7MBuVU91B3IQgVffJrp7Bo+axnP0ZWELbn66FsaFehzxMljoDcoPP\n",
       "eoR8mgzG/iO250sWqnl43H+2Fc9OpTQpCJo8DbuaAGBpFJAh1m6v5sipVstvot/QT1I0sDrZYem8\n",
       "VBf9A2sGP0ev0MuEq83yUfwvF/pIsE8PheVmbxzw01JV9gzwUVpnBoP+h0wR0rt5AA7alqU5ZKvC\n",
       "Tb8+AZEdHCz4ciVkS5DSV+nqSVcRyrjN/ik7xQesiZQJt47Ht9Gv3tNBbxr/wxlFX8dnfVsziERc\n",
       "2soYC4LYGiJzshWNETnHbKQJSyy04203uTdQKiACxA44ZitS9FgH5Jfe7ESEBE9fmTkO5ZuBZTYg\n",
       "E5R5M1M12eiuyiao7oRjlM/N3umyZ+kWpl4iV1bbd+KUUc6coLO/C+PzKRmiANiVmCWVKLLmT+vk\n",
       "MQetT8UYTGdq7Eo0XpPiPlThajWU+5Aaqx4at9o6otp0sS5ZQLdyc2sPVGDNYhm6Rki+729VJkZY\n",
       "wjKyPXczAM1Mq5/JVxVhsx6Bg5WrBAfsw+k9m0S7Xc3/yGBPY2EY+Rhv2U+xWpx9MjMmkeriC/if\n",
       "y/y26fWat1dz878ngVfSQBidR9VZlZ677wRrVa+RhcMv4V+IyCwNWb1SUhQQImgFwB0eHz+maJxw\n",
       "JggANc2SNwZjMaep74RfLWUX5UsNRAiXx8ixhdeTjssiGQ+qRtsOd9ym+ta7knXDXYAdRSRCCcfk\n",
       "ledfvC1EbFqprGyN1nMzVUMlSnjWsu73UwGwyS48HPh9q63R8O0DcXRzbhBgjnDPwxefwjVCWhvh\n",
       "ts308MnsN9oEjtGjwswlGdq5/vG56ffHuht9pbh54tkH2wkxfaablWaAAPpcAIoorVqisDnyXZoP\n",
       "gFzEMa/xNaxr/tt6XRGY5GNr42mVA1caXIeYBPQV7RHBV7wYKtQ7SyVKvZ/qw5CIAAAGKhwAsj1A\n",
       "8mZzPHetmylS+hupvS3n9qsETXot3t8eMsNY6YRBQLKtdMTE1EYqd2GCpM7PF2QHjlwJAABZEw4a\n",
       "s8ejrDIAG8mBnUvJsSPH0q492yI3PrtnjVbtzpV6svOzfvFwUNSHhlRVN/9cbitXqiIh7DKFZE0m\n",
       "GOHy92lrw92aL11ao50iLey3rHxSHkcHiP4SZF3gX0n3kEjLOR6XLhNnZRVYebWVDVyqcVBepILz\n",
       "DO8ECrvmTmTvlJHXg/SCxSAAAHiGg+4mO00s89VGSqZsTa3m+Jl3Vl9nO4ETIwZJc9LxJ65wcW8l\n",
       "odGcbL1n6SMBLab6Vu/gfFgj5XOj3az2N1oDCXFJaCCsRTsKujB1zUrcKdykcJV3nPCkxyMyEuRi\n",
       "UpwRVOyUEB0SjTfeNm/KcGeZCnasgz+vlrvgaLbfCjQZIcl0F3qXLHORASoMmr23BrxqS9kHxCRj\n",
       "rTHrDZBDQAAdk3t8TMuAceJij1mTXjabUGSo94qIt6nIHCaS1SliyvE/BDRBmoO3FpkS67onUj3d\n",
       "Ga9v0+MYHCCiYwnGYDycZaqH17ES7brHuMY8ac2MIyJfADIhHWobEK8BYAMXwtz9xNFxXTs+exKF\n",
       "bND+pAcmDl7cMWh5K1VJQ8zy5KUfXWNwnT2w8k4OOt6gRT7hx7Fg+OXETZjDyZYE6SgDAueOOFak\n",
       "CJwFHo6qNMPEalDQcPKoaSa8qBs5ue+TVAM2rmBjLqTHWVhXeG15HE+XKS7DLtkfMpzs1aCaskga\n",
       "dXaQ+cWwnwG0cZuI9PsP7LY6aTYQS4L/ZCs75V61WrUX0JaoxSGcO6mtq3q+FPhRmoJI+xBXTzkc\n",
       "tWABrLeWPtjzXsSB3vyov14zKi/EkOvt2wBZTPzDwj3pegXa1fBsVqqaFQAq26J1vAr8MGGUS09K\n",
       "gLYO8Fc9/+NISQKpArO8nhdOiyHWjA3NEu4OE72Ddq+2mw9i3wic0LSQZAoLF8aTFgtceXM6rX8+\n",
       "3Au1IP+W/SOQEF3qdrlPdDi3sarLzLh4bTOLaGLxZ3sG79rOTscypWOMPBbJBXk0GB4xWlOm+RRB\n",
       "CsyySsAAH2+k1TKKRQqw8YK1TE2O2dY35C4epAPRoV4f59G5WF06Tc/Hc8/S9mn9jKiPmPibxB0F\n",
       "CF2vGxeIdBZTtfGplzxfZCQ+tNrcmOWuGX1DRivTpd5Xnxk7eU7a6/+1W41vnr7brZ2auIgMTaf2\n",
       "tiYsNzx+tpOZ+EShcDd+xXko7cfNo9UCs7AD86b33tWWPs3OtlCUTAtikSPpX9jRquABJsiAfq/b\n",
       "DOokf55tSPtjmWTEJuJ0jv4BjCjvorfJoSYGE4VAQbDgRzosrMZ1kzvNb/OHMroaJDBsMIkvQMED\n",
       "gAXtai3dD0Xlo2tnMLbUVaIoryg2FbLBmrUF9NiEnhpmlbAYUM+MWwAQc8rfnnj7mQEikN/WGN5a\n",
       "IE1ueT00KOPTUCtsdF3TLa/8Q6z5PW/QRK1IAABbXySiU8AAA4sAAABJQZokbEEf/rUqgAAAAwAB\n",
       "nsjqAGsRrNplm3An+pc42HRYTnlCMlNCJ3MEryFHOjoGuDgIPxmi0hMpCZpuYRwE15p4jZqRpuBn\n",
       "IAAAABlBnkJ4h38AAAMAAAZTaW3c+Szg3WpiVFdhAAAAFAGeYXRDfwAAAwAAAwABm+qpf8qgAAAA\n",
       "EgGeY2pDfwAAAwAAAwABnC7AKwAAAFBBmmhJqEFomUwII//+tSqAAAADAAADAlPFLf4cEsADhHMm\n",
       "eK+xE/tX0dQ4vplL0k7CU3aKI9E0+GYxy5ayHrfu3Q+jASloG/2h31ag6tBhtwAAABpBnoZFESw7\n",
       "/wAAAwAAAwAJBAQ5w3U1De2EwQAAABUBnqV0Q38AAAMAAAMADOIVFWFqQmEAAAAWAZ6nakN/AAAD\n",
       "AAADAAzgvZIJtmdCYAAAAE1BmqxJqEFsmUwII//+tSqAAAADAAADAlNc+qrfsAR8af+Plytxu8lI\n",
       "S8BszxhvgV+47TK/cUdTuut3gR8eZyyz2GLcQY9vE1/xKFnB4AAAABlBnspFFSw7/wAAAwAAAwAJ\n",
       "AUYyYfyQlQJxAAAAFwGe6XRDfwAAAwAAAwAM3h1XfKCbGtAmAAAAGAGe62pDfwAAAwAAAwAMz3oM\n",
       "qts0zpaEwAAAADtBmu5JqEFsmUwUTBH//rUqgAAAAwAAAwJQWeW8CpiKgGXAHCfvIJ2bfouUKd/H\n",
       "0jTF1KW6ahRKgQP6YQAAABgBnw1qQ38AAAMAAAMADN4dK2ihVqcqKYEAAABQQZsSSeEKUmUwII//\n",
       "/rUqgAAAAwAABn7t/PyKJAAiEFzXjSCt94Jv57zKppOFlFv24u+OakC6zV8KkE+pneJr+HOZP+H8\n",
       "T8sscOpXcC2TsMsAAAAcQZ8wRTRMO/8AAAMAAAMAGT2NuNcUJQoWznYnwAAAABkBn090Q38AAAMA\n",
       "AAMAI6yx5aJ7az0c3JPgAAAAFwGfUWpDfwAAAwAAAwAjrLHlooIlORoTAAAAQ0GbVkmoQWiZTAgj\n",
       "//61KoAAAAMAAAZ+1ZpYV0AIBk4M9Qt9WweWx8nkzizy92A+S3TX9xn4SqrrP0g0kzi+U3N3UXAA\n",
       "AAAbQZ90RREsO/8AAAMAAAMAGP7eeqAfKRKd/KfAAAAAFwGfk3RDfwAAAwAAAwAjOWx4f0u8SSgn\n",
       "AAAAFwGflWpDfwAAAwAAAwAjOZ4SSPp5FzhMAAAAWUGbmkmoQWyZTAgj//61KoAAAAMAABIG6lgA\n",
       "1874NdRZJgI62shKnMfwhdHh3cm9buAqTYMpHd1XzR5OMNhhA5EM6ZvsMKxy20VuPB+SvkDvHQgt\n",
       "8yQ+qXzBAAAAI0GfuEUVLDv/AAADAAADAEYEXv/KgAh32XKpqUl86F0fNI2BAAAAIAGf13RDfwAA\n",
       "AwAAAwBkvuQAbRjVyeLlbfXCcucXL4FgAAAAGgGf2WpDfwAAAwAAAwBkD6BUS2xGMOpTHctfAAAA\n",
       "VkGb3kmoQWyZTAgj//61KoAAAAMAABIUG+2zQAhNjjgN5w+3ZNhdALxRbS4H1AbE7dqboU9kPT+P\n",
       "2oDNt8S5l9kGo7ZmF7Gc/ohUVgJouRVXWpqRDx3QAAAAHUGf/EUVLDv/AAADAAADAEUvOqfvQvEL\n",
       "sfZdyM09AAAAGAGeG3RDfwAAAwAAAwBkV+CMP79h/Rd3gQAAABoBnh1qQ38AAAMAAAMAY9enJ+qE\n",
       "Q5GU2ttrwAAAAGtBmgJJqEFsmUwII//+tSqAAAADAAAy2rs/+5UEEAGu1ZYcqcDyyHVU4T0SX5v4\n",
       "McKb2KmrcLLsJd9VzOgc2wYipB6Qk99+tdHEAMyX1nZc5GdLnK5ltOpLj3PxLQcn14exOzmpmNYa\n",
       "maS2gAAAACVBniBFFSw7/wAAAwAAAwDFLwxvdQATo8X3OayxvBgZJkHmbnuPAAAAJQGeX3RDfwAA\n",
       "AwAAAwEVvEXDp44AISlmaENhOZfV82fW1EBexmwAAAAdAZ5BakN/AAADAAADARR2bA8qDHZkfLp8\n",
       "1Bh16PEAAABEQZpGSahBbJlMCCP//rUqgAAAAwAAMr7qZxiaAEJqnIVAnMciNst3gmFZ1qedZdBh\n",
       "hLmHpIsJ/BhEB421BxKeW051ctoAAAAdQZ5kRRUsO/8AAAMAAAMAxT3sflFohpQwQmFaj0EAAAAa\n",
       "AZ6DdEN/AAADAAADARVljy+M60R6JxSy49EAAAAaAZ6FakN/AAADAAADARQKhrhKakjHfcUsyPUA\n",
       "AABLQZqISahBbJlMFEwR//61KoAAAAMAADKcQ+QBbypymRf2z0QwH3V2WspKDh6bEzwHR12GO6OH\n",
       "v3ATcPQglzEExuXEjvaeJU6VQA6ZAAAAGwGep2pDfwAAAwAAAwETriKxBU2crKBxaTmPQAAAAEVB\n",
       "mqxJ4QpSZTAgj//+tSqAAAADAACMoU+aRyEAR+UX0raK5MlXPHDErlg9Zms7Hb1W5QImXc58bsHQ\n",
       "Lp0AvecISP24YnYAAAAkQZ7KRTRMO/8AAAMAAAMCH1tlNwASABtU/0WU9pxQ8j8ZhFe/AAAAGwGe\n",
       "6XRDfwAAAwAAAwMPccz16FAQIl8ZOJVp4AAAABoBnutqQ38AAAMAAAMDDdnJZW2aX0sRbILv3gAA\n",
       "AEBBmvBJqEFomUwII//+tSqAAAADAACMFlVeTYNCCALLM+jibjwpz6LWg61EhPgi2o+AQ32z9f4N\n",
       "CFHD3x1PugZ9AAAAJUGfDkURLDv/AAADAAADAhl2wrm40WAE1M6VqwPFaFE2KcQnbTcAAAAbAZ8t\n",
       "dEN/AAADAAADAw7EaqCMkT0+B+gnMbvBAAAAHAGfL2pDfwAAAwAAAwMFv7JycVepE+WXosLbv3gA\n",
       "AABoQZs0SahBbJlMCCH//qpVAAADAAADAxVCbwArqlrapV4jlDdKDzRzojrA4LHpgNfVGLOr2P8d\n",
       "Tz9x3t4l3Dkf1a6KdFhHSJ5XnGmL/9UxOtJ6xHdlNJnm5Yladd36GebgtX9xgA1gFDAAAAAeQZ9S\n",
       "RRUsO/8AAAMAAAYBeGHkfuHHnE2pRw5oskLBAAAAGQGfcXRDfwAAAwAACGgsIEvRO46ciJUb68AA\n",
       "AAAaAZ9zakN/AAADAAAIYf8KiU2tHeC+wiXeXvAAAAA+QZt1SahBbJlMCCP//rUqgAAAAwABioZO\n",
       "+85gBxb5t/m6SaYxHch4kNMIw1GKDXm6LwE6+/Dcg+PjYGXIDKkAAAByQZuZSeEKUmUwII///rUq\n",
       "gAAAAwAER4pb/EJzkEh6j5OVzIGmakNlVqvfk70o/Zaf27awPkXWElKE9gf0zQjYuO++weIYrtkL\n",
       "EI9/gsO0o/vv1W5xyJwbNDf5/cY+a6msT/EvYme3Ve3QRp3GT7EMkgXkAAAAH0Gft0U0TDv/AAAD\n",
       "AAAF+R/xsIYnqfWiQxcKUTF6KvEAAAAcAZ/WdEN/AAADAAAIZQK4o6ZnwqOUmydOKWKPeQAAABsB\n",
       "n9hqQ38AAAMAAAhdcl4NIJ/1fSbhD0YEo+8AAABmQZvdSahBaJlMCCP//rUqgAAAAwAERC9uTIAQ\n",
       "RBes5BbGtw0PcWu0vrt9ZNqGT6kpWUWVy1U9UtQHVHpFDjgD5hr91hmqrJBDCRQ5utxVfbFHPKmp\n",
       "t1jgeroSAsnxveJF5epSwKGBAAAAK0Gf+0URLDv/AAADAAAQUKYxogAfyKSYqpOjd5XbGrK1oMrt\n",
       "+hZ1I4XOKyAAAAAaAZ4adEN/AAADAAAX5VG1MXEXRaCYef11CTkAAAAVAZ4cakN/AAADAAAXQuqR\n",
       "7VbReKDhAAAAOUGaAUmoQWyZTAgj//61KoAAAAMABCb0+ft9X1yMUAFAkisEArVY5JG6/pmIDUKF\n",
       "ijr7+tmI0AAsoAAAABxBnj9FFSw7/wAAAwAAEAArhNr48hBuraIQ0M08AAAAGAGeXnRDfwAAAwAA\n",
       "Fz36gA9qsjrRLdFmwQAAABgBnkBqQ38AAAMAABc9yj4PariTaJjfDeAAAAAtQZpFSahBbJlMCCP/\n",
       "/rUqgAAAAwALxHnzS1NAAqTzkiPLYKCusz4s2o/jfAIfAAAAI0GeY0UVLDv/AAADAAAtzeJlNhbA\n",
       "ERsqimzJlDeWJOkYAmHeAAAAGAGegnRDfwAAAwAAP4fHLmbynYn4Ri5p4QAAABkBnoRqQ38AAAMA\n",
       "AD91dV3yeqSORiLmhd+9AAAALkGaiUmoQWyZTAgj//61KoAAAAMAC8FbvET3/YoAEPE70Kr+tUXF\n",
       "LGugNUAAPmEAAAAcQZ6nRRUsO/8AAAMAAC21Rlm18eJtjwZiY/RfvQAAAB8BnsZ0Q38AAAMAAD98\n",
       "NHzoAFg92PiKSOgVZJ36AB68AAAAGQGeyGpDfwAAAwAAPyTQtyA9UkcjEYEAM2AAAAA7QZrNSahB\n",
       "bJlMCCP//rUqgAAAAwAgH083Tc/AAOOxrE9VWp8PMVnOqvSddg7QXv/hO9X1Xrzed9IAi4EAAAAb\n",
       "QZ7rRRUsO/8AAAMAAHz9YpPIvRKY3FomShK8AAAAIAGfCnRDfwAAAwAAtcSvFuWAD4m9ayBc2SPh\n",
       "PJIldWJ4AAAAFwGfDGpDfwAAAwAAtbkGe0dZe7UU1V83AAAAJ0GbEUmoQWyZTAgj//61KoAAAAMA\n",
       "ICmDQRxZ3cYABDmcbbFweACDgQAAABtBny9FFSw7/wAAAwABZVX95A4k8xzpxTea+8EAAAAZAZ9O\n",
       "dEN/AAADAAC1jdBV3qHWUuQi/M83gAAAABoBn1BqQ38AAAMAAfEocDPyuaOctnbH6KQa8AAAADJB\n",
       "m1VJqEFsmUwII//+tSqAAAADAFuXe8RQmWEAONAG9HDtS54HScob0SGQshSZvgAi4QAAAClBn3NF\n",
       "FSw7/wAAAwABZXC/Fs5+MXleAC5QD6Cj1b3tvyTyxe7FJ7Q7wAAAABsBn5J0Q38AAAMAAfDTsI0a\n",
       "DXF55X+79BmXpPAAAAAhAZ+UakN/AAADAAHwcbxKpAEerYTeGptjzzE0qJjeXJPBAAAAKEGbmUmo\n",
       "QWyZTAgh//6qVQAAAwAAt7xv/p2QDShAgARlYR/a94HAAQ8AAAAqQZ+3RRUsO/8AAAMAAWTw6Im1\n",
       "gTwAsv8AbkJOalYIzFiDPMdndEwecNp5AAAAGQGf1nRDfwAAAwAB8KulbRQDPL1BorywTT0AAAAY\n",
       "AZ/YakN/AAADAAHwXzI00Z5j84ivPBNPAAAAL0Gb3EmoQWyZTAgh//6qVQAAAwAB8zwObdev+aiq\n",
       "THasX6Xkd8gMCmAl1oDNAALbAAAAHEGf+kUVLDf/AAADAAHwOT8L0swZ5mKzRCHgmngAAAAZAZ4b\n",
       "akN/AAADAAHuJpyVgekzhyMRgQAzYQAAACpBmgBJqEFsmUwIf//+qZYAAAMAB6hRRm0nwAIxmdUG\n",
       "NyvPE8Wg2Q0AAj8AAAAoQZ4+RRUsO/8AAAMAA9DZaEyv188AOOGpjYQt9o3jJpElqNsimmd+8AAA\n",
       "ABgBnl10Q38AAAMABYfe9UPSJLInUV+25p4AAAAZAZ5fakN/AAADAAWIbpW0UAxYoIYi5oXfvQAA\n",
       "ACVBmkNJqEFsmUwIb//+p4QAAAMADypNQwKYACWuefGh+WJBAAH+AAAAG0GeYUUVLDf/AAADAAWG\n",
       "yiJKYMWKoRiK88E08QAAABgBnoJqQ38AAAMABYgUo4JoxYolYjA8Q3gAAAfSbW9vdgAAAGxtdmhk\n",
       "AAAAAAAAAAAAAAAAAAAD6AAAJxAAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAA\n",
       "AAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAABvx0cmFrAAAAXHRr\n",
       "aGQAAAADAAAAAAAAAAAAAAABAAAAAAAAJxAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAA\n",
       "AAABAAAAAAAAAAAAAAAAAABAAAAAAoAAAAHgAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAACcQ\n",
       "AAAIAAABAAAAAAZ0bWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAoAAABkABVxAAAAAAALWhkbHIA\n",
       "AAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAGH21pbmYAAAAUdm1oZAAAAAEA\n",
       "AAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAABd9zdGJsAAAAt3N0\n",
       "c2QAAAAAAAAAAQAAAKdhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAoAB4ABIAAAASAAAAAAA\n",
       "AAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAANWF2Y0MBZAAW/+EAGGdk\n",
       "ABas2UCgPaEAAAMAAQAAAwAUDxYtlgEABmjr48siwP34+AAAAAAcdXVpZGtoQPJfJE/FujmlG88D\n",
       "I/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAAGQAAAQAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAMgY3R0\n",
       "cwAAAAAAAABiAAAAAQAACAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQA\n",
       "AAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAA\n",
       "AAABAAAMAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAA\n",
       "AAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAA\n",
       "AQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAAB\n",
       "AAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAADAAAAAABAAAEAAAAAAEA\n",
       "ABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAA\n",
       "BAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAAAgAAAAAAQAAFAAAAAABAAAI\n",
       "AAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQA\n",
       "AAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAA\n",
       "AAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAA\n",
       "AAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAA\n",
       "AQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAEAAAAAAC\n",
       "AAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAEAAAAAACAAAEAAAAABxz\n",
       "dHNjAAAAAAAAAAEAAAABAAAAZAAAAAEAAAGkc3RzegAAAAAAAAAAAAAAZAAADG4AAABNAAAAHQAA\n",
       "ABgAAAAWAAAAVAAAAB4AAAAZAAAAGgAAAFEAAAAdAAAAGwAAABwAAAA/AAAAHAAAAFQAAAAgAAAA\n",
       "HQAAABsAAABHAAAAHwAAABsAAAAbAAAAXQAAACcAAAAkAAAAHgAAAFoAAAAhAAAAHAAAAB4AAABv\n",
       "AAAAKQAAACkAAAAhAAAASAAAACEAAAAeAAAAHgAAAE8AAAAfAAAASQAAACgAAAAfAAAAHgAAAEQA\n",
       "AAApAAAAHwAAACAAAABsAAAAIgAAAB0AAAAeAAAAQgAAAHYAAAAjAAAAIAAAAB8AAABqAAAALwAA\n",
       "AB4AAAAZAAAAPQAAACAAAAAcAAAAHAAAADEAAAAnAAAAHAAAAB0AAAAyAAAAIAAAACMAAAAdAAAA\n",
       "PwAAAB8AAAAkAAAAGwAAACsAAAAfAAAAHQAAAB4AAAA2AAAALQAAAB8AAAAlAAAALAAAAC4AAAAd\n",
       "AAAAHAAAADMAAAAgAAAAHQAAAC4AAAAsAAAAHAAAAB0AAAApAAAAHwAAABwAAAAUc3RjbwAAAAAA\n",
       "AAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAA\n",
       "AAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguNDUuMTAw\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 2-d plot animation\n",
    "%matplotlib widget\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython import display\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "# Plot setups\n",
    "fig, ax = plt.subplots()\n",
    "plt.axis('scaled')   # making both x and y axis scaled\n",
    "ax.set_xlim(0,20)\n",
    "ax.set_ylim(0,200)\n",
    "line, = ax.plot([])\n",
    "\n",
    "# things that are going to change in every frame\n",
    "def animate(frame):\n",
    "    \n",
    "    # append new data/update plot \n",
    "    x_data.append(frame)\n",
    "    y_data.append(frame*10)\n",
    "    \n",
    "    # plot new data\n",
    "#     line.set_xdata(x_data)\n",
    "#     line.set_ydata(y_data)\n",
    "    line.set_data((x_data,y_data))\n",
    "\n",
    "    return line, # return plotting object for each frame call\n",
    "\n",
    "anim = FuncAnimation(fig, func=animate, frames=np.arange(0,10,0.1), interval=100)   # smooth --> interval = 20, frames =100 big changes --> interval = 100\n",
    "video = anim.to_html5_video()   # visualize in jupyter-lab\n",
    "html = display.HTML(video)      # convert to html\n",
    "display.display(html)           # display HTML file\n",
    "plt.close()                     # close plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "certified-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3-d plot animation\n",
    "\n",
    "%matplotlib widget\n",
    "X = np.array([[1,1,1], [2,2,3],[10,9,8]])\n",
    "labels = np.array([1,2,10])\n",
    "plot_3d_animation(X, labels,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extraordinary-syndrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba57c63101dd41f2b754314323e6b024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5ffb7e44f240b5ba41f6b4f69154de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1625, description='wave_number', max=4000, min=750), IntSlider(value=670â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.ftir_heatmap(wave_number, frame, tissue, mica)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FTIR data import\n",
    "%matplotlib widget\n",
    "\n",
    "mat_fname = '/Users/bashit.a/Documents/Alzheimer/FTIR/300x300Test.mat'\n",
    "Width, Height = 48, 48\n",
    "\n",
    "window_size = 4  # 4 point average\n",
    "f = h5py.File(mat_fname, 'r')\n",
    "wn = np.array(f['vicD']['wn'])\n",
    "wn = wn[0]\n",
    "# filtering\n",
    "window      = np.ones(window_size)/window_size                                    # window_size = 4 --> 0.25,0.25,0.25,0.225\n",
    "ftir = np.array(f['vicD']['r'])\n",
    "ftir = np.transpose(np.array([np.convolve(window, ftir[:,idx], mode='same') for idx in range(ftir.shape[1])  ])) if window_size>1 else ftir   # filter output using convolution\n",
    "\n",
    "f, axs = plt.subplots(nrows=4, ncols=3, figsize = (16,8))\n",
    "frame_cor = np.arange(0,Width*Height).reshape(Width, Height)                  # indices for heat map\n",
    "\n",
    "def ftir_heatmap(wave_number, frame, tissue, mica):\n",
    "    \n",
    "    ########## --------- matplotlib mouse hovering function for snaking --------- ##########\n",
    "    numrows, numcols = Height, Width                  # format_coord function requires this global variables\n",
    "    def format_coord(x, y):\n",
    "        col = int(x)                                  # truncate x values\n",
    "        row = int(y)                                  # truncate y values\n",
    "        if 0 <= col < numcols and 0 <= row < numrows:\n",
    "            z = frame_cor[row, col]        # flipping to get correct value of z     \n",
    "            return 'x=%1.2f, y=%1.2f, FRAME=%d' % (x, y, z)\n",
    "        else:\n",
    "            return 'x=%1.2f, y=%1.2f' % (x, y)        # outside the plotting range, no need \n",
    "    \n",
    "    axs[0,:2] = plt.subplot(4, 2, 1)\n",
    "    axs[0,0].imshow(ftir[wn==wave_number,:].reshape(Width, Height), cmap='jet')\n",
    "    axs[0,0].format_coord = format_coord\n",
    "    axs[0,0].set(title='Heatmap FTIR')\n",
    "\n",
    "    stds = np.zeros(len(wn))\n",
    "    for wn_ in range(len(wn)):\n",
    "        stds[wn_] = np.std(ftir[wn_,:])\n",
    "    \n",
    "    axs[0,2].clear()\n",
    "    axs[0,2].plot(wn, stds,'blue')\n",
    "    axs[0,2].scatter(wn[wn==wave_number], stds[wn==wave_number],color='red', marker = 'o')\n",
    "    axs[0,2].set(xlabel = \"wn\", ylabel = \"std\")\n",
    "    \n",
    "    axs[1,0].cla()\n",
    "    axs[1,0].plot(wn,ftir[:, frame], label=f'fr-{frame}')\n",
    "    axs[1,0].set(xlabel = \"wn\", ylabel = \"absorbtion\")\n",
    "    axs[1,0].legend()\n",
    "    \n",
    "    axs[1,1].cla()\n",
    "    axs[1,1].plot(wn,ftir[:, tissue], label=f'tissue-{tissue}')\n",
    "    axs[1,1].set(xlabel = \"wn\", ylabel = \"absorbtion\")\n",
    "    axs[1,1].legend()\n",
    "    \n",
    "    axs[1,2].cla()\n",
    "    axs[1,2].plot(wn,ftir[:, mica], label=f'mica-{mica}')\n",
    "    axs[1,2].set(xlabel = \"wn\", ylabel = \"absorbtion\")\n",
    "    axs[1,2].legend()\n",
    "    \n",
    "    axs[2,:] = plt.subplot(4, 1, 3)\n",
    "    axs[2,0].cla()\n",
    "    axs[2,0].plot(wn,ftir[:, frame] -ftir[:, mica], label=f'fr-{frame}-mica-{mica}')\n",
    "    axs[2,0].plot(wn,ftir[:, tissue]-ftir[:, mica], label=f'tissue-{tissue}-mica-{mica}')\n",
    "    axs[2,0].set(xlabel = \"wn\", ylabel = \"absorbtion\")\n",
    "    axs[2,0].legend()\n",
    "    \n",
    "    axs[3,:] = plt.subplot(4, 1, 4)\n",
    "    axs[3,0].cla()\n",
    "    axs[3,0].plot(wn,(ftir[:, frame] -ftir[:, mica]) - (ftir[:, tissue]-ftir[:, mica]), label=f'fr-{frame}-tissue-{tissue}-2*mica-{mica}')\n",
    "    axs[3,0].set(xlabel = \"wn\", ylabel = \"absorbtion\")\n",
    "    axs[3,0].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "frame = ipywidgets.IntSlider(min=frame_cor.min(), max=frame_cor.max(), value = 670, continuous=False)   # value = int(frame_cor.mean())\n",
    "tissue = ipywidgets.IntSlider(min=frame_cor.min(), max=frame_cor.max(), value = 899, continuous=False)\n",
    "mica = ipywidgets.IntSlider(min=frame_cor.min(), max=frame_cor.max(), value = 521, continuous=False)\n",
    "\n",
    "wave_number = ipywidgets.IntSlider(min=np.min(wn), max=np.max(wn), value = 1625, continuous=False)\n",
    "ipywidgets.interact(ftir_heatmap, wave_number=wave_number, frame=frame, tissue=tissue, mica=mica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-provincial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
